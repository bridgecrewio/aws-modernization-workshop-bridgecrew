[
{
	"uri": "/aws.html",
	"title": "AWS Workshop",
	"tags": [],
	"description": "",
	"content": " Welcome! In this workshop, you’ll learn how to leverage infrastructure as code (IaC) and DevSecOps to automate your cloud security efforts. If you’re interested in making cloud security more efficient, proactive, and accessible to developers, this workshop is for you!\nUsing Bridgecrew, GitHub, AWS CodeBuild, and AWS CodePipeline, you’ll get hands-on experience implementing an automated CloudFormation security and compliance workflow.\nLearning Objectives  Overview of DevSecOps and CloudFormation infrastructure as code (IaC) Getting started with Bridgecrew to scan for CloudFormation misconfigurations Setting up your CI/CD pipeline to automate security scanning and policy enforcement Fixing IaC security errors and AWS resource misconfigurations with Bridgecrew  Before we dive in, let’s go through a refresher on the core concepts explored in this workshop.\n"
},
{
	"uri": "/",
	"title": "Cloud DevSecOps with Bridgecrew",
	"tags": [],
	"description": "",
	"content": "  a { color: inherit; text-decoration: none; } \nWelcome! \nCloudFormation workshop Learn about securing CloudFormation templates from code to cloud using Bridgecrew\u0026rsquo;s integrations with VS Code, CodeBuild, CodePipeline, GitHub and AWS runtime.\n     Terraform workshop Learn about securing Terraform templates from code to cloud using Bridgecrew\u0026rsquo;s integrations with VS Code, GitHub, Terraform Cloud, and AWS runtime.\n     Kubernetes workshop Try your hand at securing Kubernetes from manifest to cluster through DevOps tools integrations.\n    \n \u0026lt;div class=\u0026#34;col-lg-6 col-sm-6 mb-4\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;card text-center\u0026#34;\u0026gt; \u0026lt;a href=\u0026#34;./azure.html\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;card-body p-lg-5 px-3 py-4\u0026#34;\u0026gt; \u0026lt;a href=\u0026#34;./azure.html\u0026#34;\u0026gt; \u0026lt;img src=\u0026#34;images/terraform_azure_logo.png\u0026#34;\u0026gt; \u0026lt;h4 class=\u0026#34;card-title mb-3\u0026#34;\u0026gt;Terraform + Azure workshop\u0026lt;/h4\u0026gt; \u0026lt;p class=\u0026#34;card-text\u0026#34;\u0026gt;Learn about securing Terraform templates and Azure from code to cloud using Bridgecrew\u0026#39;s integrations with VS Code, GitHub, Terraform Cloud, and Azure runtime.\u0026lt;/p\u0026gt; \u0026lt;/a\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/a\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \n"
},
{
	"uri": "/kubernetes.html",
	"title": "Kubernetes Workshop",
	"tags": [],
	"description": "",
	"content": " Welcome! In this workshop, you’ll learn how to leverage infrastructure as code (IaC) and DevSecOps to automate, scale, and improve the security posture of your cloud infrastructure. We’ll create a pipeline that provides frequent, easy-to-digest improvements to ensure our configurations are secure and compliant from build-time to runtime.\nUsing Bridgecrew, Checkov, VS Code, GitHub, Kubernetes, ArgoCD and AWS, we’ll get hands-on experience implementing an automated Kubernetes security and compliance workflow.\nLearning Objectives  Get an overview of DevSecOps and Kubernetes infrastructure as code (IaC) Scan IaC files for misconfigurations locally Set up CI/CD pipelines to automate security scanning and policy enforcement Fix IaC security errors and AWS resource misconfigurations with Bridgecrew  Let’s start with a few core concepts!\n"
},
{
	"uri": "/azure.html",
	"title": "Terraform + Azure Workshop",
	"tags": [],
	"description": "",
	"content": " Welcome! In this workshop, you’ll learn how to leverage infrastructure as code (IaC) and DevSecOps to automate, scale, and improve the security posture of your cloud infrastructure. We’ll create a pipeline that provides frequent, easy-to-digest improvements to ensure our configurations are secure and compliant from the build-time to runtime.\nUsing Bridgecrew, Checkov, VS Code, GitHub, Terraform Cloud, and Azure, we’ll get hands-on experience implementing an automated Terraform security and compliance workflow.\nLearning Objectives  Get an overview of DevSecOps and Terraform infrastructure as code (IaC) Scan IaC files for misconfigurations locally Set up CI/CD pipelines to automate security scanning and policy enforcement Fix IaC security errors and Azure resource misconfigurations with Bridgecrew  Let’s start with a few core concepts!\n"
},
{
	"uri": "/terraform.html",
	"title": "Terraform Workshop",
	"tags": [],
	"description": "",
	"content": " Welcome! In this workshop, you’ll learn how to leverage infrastructure as code (IaC) and DevSecOps to automate, scale, and improve the security posture of your cloud infrastructure. We’ll create a pipeline that provides frequent, easy-to-digest improvements to ensure our configurations are secure and compliant from the build-time to runtime.\nUsing Bridgecrew, Checkov, VS Code, GitHub, Terraform Cloud, and AWS, we’ll get hands-on experience implementing an automated Terraform security and compliance workflow.\nLearning Objectives  Get an overview of DevSecOps and Terraform infrastructure as code (IaC) Scan IaC files for misconfigurations locally Set up CI/CD pipelines to automate security scanning and policy enforcement Fix IaC security errors and AWS resource misconfigurations with Bridgecrew  Let’s start with a few core concepts!\n"
},
{
	"uri": "/aws/5_getting_started.html",
	"title": "DevSecWhat?",
	"tags": [],
	"description": "",
	"content": " DevSecWhat? The foundation of DevSecOps lies in the DevOps movement, wherein development and operations functions have merged to make deployments faster, safer, and more repeatable. Common DevOps practices include automated infrastructure build pipelines (CI/CD) and version-controlled manifests (GitOps) to make it easier to control cloud deployments. By baking software and infrastructure quality requirements into the release lifecycle, teams save time manually reviewing code, allowing them to focus more on shipping features.\nAs deployments to production speed up, however, many traditional cloud security concepts break down. With the rise of containerized technologies, serverless functions, and IaC frameworks (which we’ll dig into in the next section), it’s harder to maintain cloud security posture visibility.\nBy leveraging DevOps foundations, security and development teams can build security scanning and policy enforcement into automated pipelines. The ultimate goal with DevSecOps is to “shift cloud security left.” That means automating it and embedding it earlier into the development lifecycle so that actions can be taken earlier. Proactively preventing risky deployments avoids slowing down development teams with deployment rollbacks and disruptive fixes later in the software development lifecycle.\nFor DevSecOps to be successful for teams working to build and secure infrastructure, embracing existing tools and workflows is critical. At Bridgecrew, we’re committed to making it as simple, effective, and painless as possible to automate cloud security and integrate it seamlessly into release lifecycles.\nThe examples and sample code provided in this workshop are intended to be consumed as instructional content. These will help you understand how various Bridgecrew and AWS services can be architected to build a solution while demonstrating best practices along the way. These examples, especially the intentionally vulnerable \"CFNGoat\" repository, are not intended for use in production environments.  "
},
{
	"uri": "/azure/00_getting_started.html",
	"title": "DevSecWhat?",
	"tags": [],
	"description": "",
	"content": "The foundation of DevSecOps lies in the DevOps movement, wherein development and operations functions are creating tighter coupling with more collaboration. DevOps tooling usually includes codifying every aspect of an application stack, version controlling all the code (GitOps), and automating the build and deployment process (CI/CD).\nDevSecOps is when we embed security into each of those steps.\nModern development processes have sped up the innovation process. Traditional security can’t keep pace with DevOps unless there are fundamental changes in security reviews. Security is still essential in agile development, and cloud security posture needs to be improved.\nThe solution is to “shift left” your cloud security efforts. That is to bring security in an automated, scalable way earlier in the development process—planning, development, and build-time. The result is higher patch rates with faster time-to-fix. With the “shift left” approach, development teams are happy because they’re making security fixes in their development cycle, and security teams are happy because security posture improves.\nWith cloud deployments, we have an opportunity to secure infrastructure from code to cloud. By securing infrastructure as code (IaC) templates at every stage of development, production infrastructure has the best possible chance to be secure and compliant. Bridgecrew is committed to making this as easy and seamless as possible with developer-friendly integrations and workflows.\nThe examples and sample code provided in this workshop are intended to be consumed as instructional content. These will help you understand how various services can be architected to build a solution while demonstrating best practices along the way. These examples, especially the intentionally vulnerable \"TerraGoat\" repository, are not intended for use in production environments.  "
},
{
	"uri": "/kubernetes/10_getting_started.html",
	"title": "DevSecWhat?",
	"tags": [],
	"description": "",
	"content": "The foundation of DevSecOps lies in the DevOps movement, wherein development and operations functions are creating tighter coupling with more collaboration. DevOps tooling usually includes codifying every aspect of an application stack, version controlling all the code (GitOps), and automating the build and deployment process (CI/CD).\nDevSecOps is when we embed security into each of those steps.\nModern development processes have sped up the innovation process. Traditional security can’t keep pace with DevOps unless there are fundamental changes in security reviews. Security is still essential in agile development, and cloud security posture needs to be improved.\nThe solution is to “shift left” your cloud security efforts. That is to bring security in an automated, scalable way earlier in the development process—planning, development, and build-time. The result is higher patch rates with faster time-to-fix. With the “shift left” approach, development teams are happy because they’re making security fixes in their development cycle, and security teams are happy because security posture improves.\nWith cloud deployments, we have an opportunity to secure infrastructure from code to cloud. By securing infrastructure as code (IaC) templates at every stage of development, production infrastructure has the best possible chance to be secure and compliant. Bridgecrew is committed to making this as easy and seamless as possible with developer-friendly integrations and workflows.\nThe examples and sample code provided in this workshop are intended to be consumed as instructional content. These will help you understand how various services can be architected to build a solution while demonstrating best practices along the way. These examples, especially the intentionally vulnerable \"KustomizeGoat\" repository, are not intended for use in production environments.  "
},
{
	"uri": "/terraform/00_getting_started.html",
	"title": "DevSecWhat?",
	"tags": [],
	"description": "",
	"content": "The foundation of DevSecOps lies in the DevOps movement, wherein development and operations functions are creating tighter coupling with more collaboration. DevOps tooling usually includes codifying every aspect of an application stack, version controlling all the code (GitOps), and automating the build and deployment process (CI/CD).\nDevSecOps is when we embed security into each of those steps.\nModern development processes have sped up the innovation process. Traditional security can’t keep pace with DevOps unless there are fundamental changes in security reviews. Security is still essential in agile development, and cloud security posture needs to be improved.\nThe solution is to “shift left” your cloud security efforts. That is to bring security in an automated, scalable way earlier in the development process—planning, development, and build-time. The result is higher patch rates with faster time-to-fix. With the “shift left” approach, development teams are happy because they’re making security fixes in their development cycle, and security teams are happy because security posture improves.\nWith cloud deployments, we have an opportunity to secure infrastructure from code to cloud. By securing infrastructure as code (IaC) templates at every stage of development, production infrastructure has the best possible chance to be secure and compliant. Bridgecrew is committed to making this as easy and seamless as possible with developer-friendly integrations and workflows.\nThe examples and sample code provided in this workshop are intended to be consumed as instructional content. These will help you understand how various services can be architected to build a solution while demonstrating best practices along the way. These examples, especially the intentionally vulnerable \"TerraGoat\" repository, are not intended for use in production environments.  "
},
{
	"uri": "/kubernetes/20_prerequisites/aws_setup.html",
	"title": "AWS Environment",
	"tags": [],
	"description": "",
	"content": " AWS Environment Setup To start the workshop, select one of the following, depending on whether you are\u0026hellip;\n \u0026hellip;attending an AWS hosted event, or \u0026hellip;running the workshop on your own AWS account  "
},
{
	"uri": "/aws/5b_what_cloudformation.html",
	"title": "CloudFormation Overview",
	"tags": [],
	"description": "",
	"content": " How do CloudFormation and infrastructure as code work? Infrastructure as code (IaC) frameworks such as AWS CloudFormation, Terraform, and Pulumi make cloud provisioning simple and scalable by leveraging automation and code. Defining your cloud infrastructure in code simplifies repetitive DevOps tasks and gives you a single source of truth for your app and environment configuration.\nAWS CloudFormation enables you to define your AWS infrastructure with templates, which you can check into version control or store in S3 buckets. CloudFormation templates are JSON or YAML files. For instance, the following template defines an S3 bucket:\n{   \u0026#34;AWSTemplateFormatVersion\u0026#34; : \u0026#34;2010-09-09\u0026#34;,  \u0026#34;Description\u0026#34; : \u0026#34;AWS CloudFormation Sample Template: Sample template showing how to create a publicly accessible S3 bucket.\u0026#34;,  \u0026#34;Resources\u0026#34; : {  \u0026#34;S3Bucket\u0026#34; : {  \u0026#34;Type\u0026#34; : \u0026#34;AWS::S3::Bucket\u0026#34;,  \u0026#34;Properties\u0026#34; : {  \u0026#34;AccessControl\u0026#34; : \u0026#34;PublicRead\u0026#34;,  \u0026#34;WebsiteConfiguration\u0026#34; : {  \u0026#34;IndexDocument\u0026#34; : \u0026#34;index.html\u0026#34;,  \u0026#34;ErrorDocument\u0026#34; : \u0026#34;error.html\u0026#34;  }  },  \u0026#34;DeletionPolicy\u0026#34; : \u0026#34;Retain\u0026#34;  }  },  \u0026#34;Outputs\u0026#34; : {  \u0026#34;WebsiteURL\u0026#34; : {  \u0026#34;Value\u0026#34; : { \u0026#34;Fn::GetAtt\u0026#34; : [ \u0026#34;S3Bucket\u0026#34;, \u0026#34;WebsiteURL\u0026#34; ] },  \u0026#34;Description\u0026#34; : \u0026#34;URL for website hosted on S3\u0026#34;  },  \u0026#34;S3BucketSecureURL\u0026#34; : {  \u0026#34;Value\u0026#34; : { \u0026#34;Fn::Join\u0026#34; : [ \u0026#34;\u0026#34;, [ \u0026#34;https://\u0026#34;, { \u0026#34;Fn::GetAtt\u0026#34; : [ \u0026#34;S3Bucket\u0026#34;, \u0026#34;DomainName\u0026#34; ] } ] ] },  \u0026#34;Description\u0026#34; : \u0026#34;Name of S3 bucket to hold website content\u0026#34;  }  } } Using the AWS CLI, you can provision the above bucket in seconds: (This is an example, not required for the workshop)\naws cloudformation create-stack --stack-name myexamplestack --template-body file:///home/example/mytemplate.json Security and CloudFormation IaC The benefit of using CloudFormation to define your AWS infrastructure is that it allows you to audit templates before they’re deployed. That will enable you to bake security best practices into your development and deployment lifecycle and finding potential security and compliance issues before the infrastructure becomes real.\nCloudFormation gives us total control to create, change, and delete resources in AWS. With CloudFormation, it’s easy to pick and deploy any of the hundreds of templates readily available from the AWS sample templates. Because these templates are built solely with functionality in mind, it’s also easy to forget important security configuration and end up having an insecure service running in production.\nThat’s why scanning your CloudFormation templates for vulnerable infrastructure before deployment is so important. With Bridgecrew, you can automate the scanning of your IaC codebase and cloud resources to both find and fix misconfigurations.\nIn this workshop, we’re doing exactly that. So let’s get started!\n"
},
{
	"uri": "/azure/10_what_is_terraform.html",
	"title": "Infrastructure as Code using Terraform",
	"tags": [],
	"description": "",
	"content": " What is infrastructure as code anyway? Infrastructure as code (IaC) frameworks such as ARM and HashiCorp Terraform make cloud provisioning scalable and straightforward by leveraging automation and code. Defining our cloud infrastructure in code simplifies repetitive DevOps tasks and gives us a versioned, auditable single source of truth for our environment configurations.\nHashiCorp Terraform is a multi-cloud IaC tool that allows us to define how we want our infrastructure to look, and it will generate all of the commands to make that happen. Any changes we want to make, such as adding more instances with the same configurations, Terraform will handle for us after we define the changes in our template.\nFor strictly demonstration purposes, the following Terraform resource block creates an Azure Storage Account without any CLI or GUI commands:\nresource \u0026#34;azurerm_storage_account\u0026#34; \u0026#34;example\u0026#34; {  name = \u0026#34;storageaccountname\u0026#34;  resource_group_name = \u0026#34;resourcegroup\u0026#34;  location = \u0026#34;West US\u0026#34;  account_tier = \u0026#34;Standard\u0026#34;  account_replication_type = \u0026#34;LRS\u0026#34; } After performing terraform init, we can provision a Storage Account with the following command:\nterraform apply Any changes we make to that file, such as adding tagging or changing the networking rules, will just require another terraform apply command to update our bucket.\nSecurity and Terraform Another benefit of using Terraform to define our infrastructure is that we can audit the code for misconfigurations before any infrastructure is created. That enables us to bake security into development processes and prevent infrastructure issues before they open an S3 bucket to the world.\nThat’s why we scan our Terraform templates for vulnerabilities before deployment. With Bridgecrew, we can automate this whole process, from finding the bugs to fixing them.\nIn this workshop, we’re doing exactly that. So let’s get started!\n"
},
{
	"uri": "/terraform/10_what_is_terraform.html",
	"title": "Infrastructure as Code using Terraform",
	"tags": [],
	"description": "",
	"content": " What is infrastructure as code anyway? Infrastructure as code (IaC) frameworks such as AWS CloudFormation, HashiCorp Terraform, and Pulumi make cloud provisioning scalable and straightforward by leveraging automation and code. Defining our cloud infrastructure in code simplifies repetitive DevOps tasks and gives us a versioned, auditable single source of truth for our environment configurations.\nHashiCorp Terraform is a multi-cloud IaC tool that allows us to define how we want our infrastructure to look, and it will generate all of the commands to make that happen. Any changes we want to make, such as adding more instances with the same configurations, Terraform will handle for us after we define the changes in our template.\nFor strictly demonstration purposes, the following Terraform resource block creates an S3 bucket without any CLI or GUI commands:\nresource \u0026#34;aws_s3_bucket\u0026#34; \u0026#34;data\u0026#34; {  bucket = \u0026#34;my_bucket_name\u0026#34;  acl = \u0026#34;public-read-write\u0026#34; } After performing terraform init, we can provision an S3 bucket with the following command:\nterraform apply Any changes we make to that file, such as adding tagging or changing the acl, will just require another terraform apply command to update our bucket.\nSecurity and Terraform Another benefit of using Terraform to define our infrastructure is that we can audit the code for misconfigurations before any infrastructure is created. That enables us to bake security into development processes and prevent infrastructure issues before they open an S3 bucket to the world.\nThat’s why we scan our Terraform templates for vulnerabilities before deployment. With Bridgecrew, we can automate this whole process, from finding the bugs to fixing them.\nIn this workshop, we’re doing exactly that. So let’s get started!\n"
},
{
	"uri": "/kubernetes/20_prerequisites.html",
	"title": "Prerequisites",
	"tags": [],
	"description": "",
	"content": "Before you get started, we will check the workshop pre-requisites.\nThe workshop environment will drop you into an example development team, at the start of their journey through the DevSecOps world!\nThey already use ‘Infrastructure as Code’ to define their environments, and the deployment target is a Kubernetes cluster, which is also setup.\nTo get the most out of this workshop, it will also be helpful to have a basic understanding of git, Kubernetes, AWS core concepts (IAM, regions, UI, CLI, APIs), and CI/CD principles.\nNext we\u0026rsquo;ll ensure we have all the items needed:\n An AWS account to run the workshop (a personal account or one provided via AWS Event Engine for AWS events) A Bridgecrew Account A GitHub Account The Automation to setup our Kubernetes, CI/CD and workshop scenarios (we\u0026rsquo;ll provide that coming up)  "
},
{
	"uri": "/kubernetes/20_prerequisites/aws_setup/2001_event_engine_setup.html",
	"title": "At an AWS Event",
	"tags": [],
	"description": "",
	"content": " Using AWS Event engine To complete this workshop, you are provided with an AWS account via the AWS Event Engine service. A 12-digit hash will be provided to you by event staff - this is your unique access code. eg:\ne8476example Create AWS Account 1 . Connect to the portal by clicking the button or browsing to https://dashboard.eventengine.run/. The following screen shows up. Enter the provided hash in the text box. The button on the bottom right corner changes to Accept Terms \u0026amp; Login. Click on that button to continue.\n2 . Choose AWS Console, then Open AWS Console. This account will expire at the end of the workshop and the all the resources created will be automatically deprovisioned. You will not be able to access this account after today.\n3 . Use a single region for the duration of this workshop. This workshop supports the following regions:\n us-west-2 (US West - Oregon)  Please select US West (Oregon) in the top right corner.\n"
},
{
	"uri": "/aws/6_prerequisites.html",
	"title": "Prerequisites",
	"tags": [],
	"description": "",
	"content": " Before we get started, make sure you have the following prerequisites. To get the most out of this tutorial, it will also be helpful to have a basic understanding of git, AWS core concepts (IAM, regions, UI, CLI, APIs), and CI/CD principles.\nGit git --version If you don’t have git installed, do so here.\nGitHub account If you don’t have a GitHub account, please sign up for one here.\nThe examples and sample code provided in this workshop are intended to be consumed as instructional content. These will help you understand how various Bridgecrew and AWS services can be architected to build a solution while demonstrating best practices along the way. These examples, especially the intentionally vulnerable \"CFNGoat\" repository, are not intended for use in production environments.  "
},
{
	"uri": "/azure/20_prerequisites.html",
	"title": "Prerequisites",
	"tags": [],
	"description": "",
	"content": " Before you get started, make sure you have the following prerequisites. To get the most out of this tutorial, it will also be helpful to have a basic understanding of git, Terraform, Azure core concepts (IAM, UI, CLI, APIs), and CI/CD principles.\nGit git --version If you don’t have git installed, do so here.\nGitHub account If you don’t have a GitHub account, please sign up for one here.\nVS Code If you don’t have Visual Studio Code installed, download and install it here.\n"
},
{
	"uri": "/terraform/20_prerequisites.html",
	"title": "Prerequisites",
	"tags": [],
	"description": "",
	"content": " Before you get started, make sure you have the following prerequisites. To get the most out of this tutorial, it will also be helpful to have a basic understanding of git, Terraform, AWS core concepts (IAM, regions, UI, CLI, APIs), and CI/CD principles.\nGit git --version If you don’t have git installed, do so here.\nGitHub account If you don’t have a GitHub account, please sign up for one here.\nVS Code If you don’t have Visual Studio Code installed, download and install it here.\n"
},
{
	"uri": "/kubernetes/20_prerequisites/aws_setup/2002_own_aws_setup.html",
	"title": "Own AWS environment",
	"tags": [],
	"description": "",
	"content": " Disclaimer: We will be using an AWS account to show Bridgecrew’s runtime capabilities and drift detection. If you follow along, remember to shut down any AWS services to avoid additional fees.\n AWS Environment setup Your account must have the ability to create new IAM roles and scope other IAM permissions.\n  If you don\u0026rsquo;t already have an AWS account with Administrator access: create one now by clicking here\n Once you have an AWS account, ensure you are following the remaining workshop steps as an IAM user with administrator access to the AWS account: Create a new IAM user to use for the workshop\n Enter the user details:  Attach the AdministratorAccess IAM Policy:  Click to create the new user:  Take note of the login URL and save:   "
},
{
	"uri": "/azure/20_prerequisites/2001_terraform_setup.html",
	"title": "Terraform Environment",
	"tags": [],
	"description": "",
	"content": " Terraform Environment Setup You’ll use the Terraform CLI locally as well as optionally Terraform Cloud. If you don’t have the Terraform CLI installed on your computer, see the instructions here.\nTerraform Cloud (TFC) is a self-service SaaS platform that extends the capabilities of the open source Terraform CLI. It’s free for basic usage, but we’ll be leveraging advanced features, such as Sentinel, that will require a paid subscription or trial. Sign up for Terraform Cloud here and log in using your CLI.\nterraform login"
},
{
	"uri": "/terraform/20_prerequisites/2001_terraform_setup.html",
	"title": "Terraform Environment",
	"tags": [],
	"description": "",
	"content": " Terraform Environment Setup You’ll use the Terraform CLI locally as well as optionally Terraform Cloud. If you don’t have the Terraform CLI installed on your computer, see the instructions here.\nTerraform Cloud (TFC) is a self-service SaaS platform that extends the capabilities of the open source Terraform CLI. It’s free for basic usage, but we’ll be leveraging advanced features, such as Sentinel, that will require a paid subscription or trial. Sign up for Terraform Cloud here and log in using your CLI.\nterraform login"
},
{
	"uri": "/kubernetes/20_prerequisites/2003_account_setup.html",
	"title": "Account Setup",
	"tags": [],
	"description": "",
	"content": " A free Bridgecrew account The Bridgecrew platform will give us visibility, solutions, and alerts from the first line of Kubernetes manifest all the way through to checking the running cluster’s security posture. Sign up or log in to an existing account at https://bridgecrew.cloud\nGenerate a Bridgecrew API key Throughout this tutorial, you’ll need to use the Bridgecrew API token. You can access it here or in your Bridgecrew account by navigating to the Integrations tab and selecting API Token. Add a token for the workshop and save it in your notes for later use.\nA free GitHub account You will need a GitHub account to fork and edit our example infrastructure as code (IaC) so that you can automate and fix any Kubernetes issues!\nGitHub discourages individuals from having more than one account. If you already have a GitHub account you can follow along with this workshop without worrying about conflict with your private repositories.\nFork KustomizeGgoat This workshop uses our vulnerable-by-design Kubernetes \u0026amp; Kustomize project, KustomizeGoat., This project gives us a base set of deployments we can explore, edit, and remediate without needing to integrate your own code.\nFork the KustomizeGgoat repository on GitHub To set up your demo environment, we’re going to fork the KustomizeGoat repository.\nHead over to the KustomizeGoat repository and fork it using the button in the upper right corner.\nIf you have multiple organizations, GitHub will ask which of your orgs to fork into. Choose your personal account by selecting your GitHub username from the list. This will fork the repo.\nNote down the URL for this new copy of the repository, also known as the “git clone address”, select “code” and copy the HTTPS address that is shown. The HTTPS address format is:\nhttps://github.com/\u0026lt;your-github-user\u0026gt;/kustomizegoat.git Verify Cloud9 environment access Finally, lets check on the environment that CloudFormation has built for us. Click here: https://us-east-2.console.aws.amazon.com/cloud9/home/shared?region=us-east-2 to load the Cloud9 Environments within your AWS account. You will see a single bridgecrew-workshop environment which our automation has created!\nClick Open IDE. You will be taken to an environment which we will use for the rest of the workshop.\n The file browser down the left hand side already has your fork of KustomizeGoat available. The terminal window along the bottom of the browser tab is within our kubernetes cluster, kubectl, checkov and other commands needed for the workshop will work out of the box. You can open/edit files by double clicking on a file within the file browser from the left, just like a locally installed IDE.  If you have any issues accessing this environment, let your workshop host know.\n"
},
{
	"uri": "/aws/6_prerequisites/7_aws_setup.html",
	"title": "AWS Environment",
	"tags": [],
	"description": "",
	"content": " AWS Environment Setup To start the workshop, select one of the following, depending on whether you are\u0026hellip;\n \u0026hellip;running the workshop on your own AWS account, or \u0026hellip;attending an AWS hosted event  "
},
{
	"uri": "/terraform/20_prerequisites/aws_setup.html",
	"title": "AWS Environment",
	"tags": [],
	"description": "",
	"content": " AWS Environment Setup To start the workshop, select one of the following, depending on whether you are\u0026hellip;\n \u0026hellip;attending an AWS hosted event, or \u0026hellip;running the workshop on your own AWS account  "
},
{
	"uri": "/azure/20_prerequisites/azure_setup.html",
	"title": "Azure Environment",
	"tags": [],
	"description": "",
	"content": " Disclaimer: We will be using an Azure account to show Bridgecrew’s runtime capabilities and drift detection. If you follow along, remember to shut down any Azure services at the end of the workshop to avoid additional fees.\n Azure Environment setup Your account must have the ability to create new AD roles and scope other IAM permissions.\n  If you don\u0026rsquo;t already have an Azure account with Administrator access: create one now by clicking here\n From your local terminal, make sure to install the Azure CLI and log in with az login\n We need a service principle account for part of this workshop. Check that you are logged in as an AD user with administrator access to the Azure account: View permissions for your user.\n From your terminal run az account list to list your connected accounts. Grab your id from that output and set your subscription with az account set --subscription=\u0026quot;\u0026lt;your_subscription_id\u0026gt;\u0026quot;.\n Generate a Service Principle with az ad sp create-for-rbac --role=\u0026quot;Contributor\u0026quot; --scopes=\u0026quot;/subscriptions/\u0026lt;your_subscription_id\u0026gt;\u0026quot;. Save the output for later steps in the workshop.\n  "
},
{
	"uri": "/terraform/20_prerequisites/aws_setup/aws_event.html",
	"title": "At an AWS Event",
	"tags": [],
	"description": "",
	"content": " Using AWS Event engine To complete this workshop, you are provided with an AWS account via the AWS Event Engine service. A 12-digit hash will be provided to you by event staff - this is your unique access code. eg:\ne8476example Create AWS Account 1 . Connect to the portal by clicking the button or browsing to https://dashboard.eventengine.run/. The following screen shows up. Enter the provided hash in the text box. The button on the bottom right corner changes to Accept Terms \u0026amp; Login. Click on that button to continue.\n2 . Choose AWS Console, then Open AWS Console. This account will expire at the end of the workshop and the all the resources created will be automatically deprovisioned. You will not be able to access this account after today.\n3 . Use a single region for the duration of this workshop. This workshop supports the following regions:\n us-west-2 (US West - Oregon)  Please select US West (Oregon) in the top right corner.\n"
},
{
	"uri": "/kubernetes/20_prerequisites/2002_create_our_scenario.html",
	"title": "Create our Scenario",
	"tags": [],
	"description": "",
	"content": " The Automated AWS Workshop Environment Your workshop environment will drop you into an example development team, at the start of their journey through the DevSecOps world!\nThey already use ‘Infrastructure as Code’ to define their environments, and the deployment target is a Kubernetes cluster, which is also setup.\nTo pre-build this environment for each workshop attendee, we\u0026rsquo;ll run some CloudFormation within our AWS account.\nAn introduction to “kind” kind, or “Kubernetes in Docker” is a simple way to create local Kubernetes clusters for testing, experimentation and development.\nAs the name suggests, kind nests a Kubernetes cluster inside containers on your existing (Docker, Podman, ContainerD, etc) system.\nWe’ll be using KIND to ensure everyone has the same, repeatable Kubernetes configuration for this workshop, regardless of deployment location.\nSetting up the workshop environment via CloudFormation  Clicking the following link will open CloudFormation and pre-fill the template source from Amazon S3: https://us-east-2.console.aws.amazon.com/cloudformation/home?region=us-east-2\u0026amp;skipRegion=true#/stacks/create/review?templateURL=https://kubernetes-workshop-cloudformation.s3.us-east-2.amazonaws.com/workshop-init-cloudformation.yaml\u0026amp;stackName=bridgecrew-workshop\n Fill out the required parameters described below. these will enable CloudFormation to set up the environment without manual steps later in the workshop!\n  Fill in your git clone address for your fork of https://github.com/bridgecrewio/kustomizegoat in the KustomizeForkURL field.\nEnter your Bridgecrew API key from your free Bridgecrew account in the UserBridgecrewAPI field.\nEnter any public SSH key you wish to use (for which you own the private key). You will use this to log into the KIND machine. Paste this in full into the UserSSHKey field.\nFinally, enter your current public IP address from wherever you are attending this workshop. We will lock down certain public service access to this IP for security. You can edit this later if needed.\nAdd this IP into the ‘YourPublicIP’ field:\n5. Select “NEXT”. There are no further configuration options needed, select the checkbox to confirm IAM roles will be created through this automation, then select Create stack Click through to create the stack.\nVSCode We will also demonstrate security plugins for VSCode during this workshop. Security plugins for VSCode will help your development teams spot misconfigurations much earlier in the development process. To download VSCode for free, visit https://code.visualstudio.com/download.\n"
},
{
	"uri": "/kubernetes/20_prerequisites/2010_optional_local_setup.html",
	"title": "Optional local Setup",
	"tags": [],
	"description": "",
	"content": " Go it alone (Local setup) This option is strongly discouraged because we will be unable to provide the same level of support throughout the live workshops. Every local environment is different and we cannot guarantee that these instructions will work flawlessly in every environment.\nHowever, we’d like to provide Option Three so that you can see the steps needed to install all the needed dependencies for the workshop.\nThese steps are intended for a Linux X64 Ubuntu 20.04 machine, as our automated workshop environments run in Containers on these OS images.\nDocker / PodMan / Rancher Desktop / ContainerD Your machine must be able to run containers. The examples below all use Docker Desktop to spin up containerized dependencies, but all dependencies should work with other local ContainerD-based container tooling.\nSee See this page to install Docker Desktop.\nInstall the KIND CLI tool  curl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.11.1/kind-linux-amd64 chmod +x ./kind mv ./kind /usr/bin/kind Build the KIND Kubernetes cluster  /usr/bin/kind create cluster --name bridgecrew-workshop Install the Kubectl CLI tool  curl -LO \u0026#34;https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl\u0026#34; chmod +x ./kubectl mv ./kubectl /usr/bin/kubectl Set up a ‘pipenv’ for our Python dependencies. This is optional, but is a and good practice for compartmentalizing Ppython dependencies and libraries from each other when you’re on a system where you may be working with multiple projects. In this example, we’ll be installing our Checkov.io scanning tool into the pipenv, but you can alsocould just as well install Ccheckov globally with pip install checkov instead.\n apt install -y pipenv pipenv --python 3.8 Install Bridgecrews’ Checkov.io scanning tool  pipenv install checkov || pip install checkov Install Bridgecrews’ Yor.io infrastructure tag and trace tool  docker pull bridgecrew/yor Clone the “KustomizeGoat” sample repository  git clone https://github.com/bridgecrewio/kustomizegoat.git Test your installed dependencies If all of the dependencies are correctly installed, the following commands should all run without errors or failures:\n kubectl cluster-info --context kind-bridgecrew-workshop checkov --version docker run --tty --volume /root:/root bridgecrew/yor --version cd kustomizegoat \u0026amp;\u0026amp; git status"
},
{
	"uri": "/terraform/20_prerequisites/aws_setup/2002b_own_aws_setup.html",
	"title": "Own AWS environment",
	"tags": [],
	"description": "",
	"content": " Disclaimer: We will be using an AWS account to show Bridgecrew’s runtime capabilities and drift detection. If you follow along, remember to shut down any AWS services to avoid additional fees.\n AWS Environment setup Your account must have the ability to create new IAM roles and scope other IAM permissions.\n  If you don\u0026rsquo;t already have an AWS account with Administrator access: create one now by clicking here\n Once you have an AWS account, ensure you are following the remaining workshop steps as an IAM user with administrator access to the AWS account: Create a new IAM user to use for the workshop\n Enter the user details:  Attach the AdministratorAccess IAM Policy:  Click to create the new user:  Take note of the login URL and save:   "
},
{
	"uri": "/aws/6_prerequisites/7_aws_setup/8_aws_eventengine.html",
	"title": "At an AWS Event",
	"tags": [],
	"description": "",
	"content": " Using AWS Event engine To complete this workshop, you are provided with an AWS account via the AWS Event Engine service. A 12-digit hash will be provided to you by event staff - this is your unique access code. eg:\ne8476543c00e Create AWS Account 1 . Connect to the portal by clicking the button or browsing to https://dashboard.eventengine.run/. The following screen shows up. Enter the provided hash in the text box. The button on the bottom right corner changes to Accept Terms \u0026amp; Login. Click on that button to continue.\n2 . Choose AWS Console, then Open AWS Console. This account will expire at the end of the workshop and the all the resources created will be automatically deprovisioned. You will not be able to access this account after today.\n3 . Use a single region for the duration of this workshop. This workshop supports the following regions:\n us-west-2 (US West - Oregon)  Please select US West (Oregon) in the top right corner.\n"
},
{
	"uri": "/azure/20_prerequisites/2003_bc_setup.html",
	"title": "Bridgecrew setup",
	"tags": [],
	"description": "",
	"content": " You’ll need to sign up for a free Bridgecrew account to follow along with this tutorial. You can sign up for a free account here.\nCheckov In this tutorial, we’re also going to use Checkov. Checkov works on Windows, Mac, and Linux. You can install it with pip:\npip3 install checkov If installing globally on your system (not in a python venv or pipenv) you may need to have permissions to write the libraries to the necessary locations, ie:\nsudo pip3 install checkov If you run into problems, try the alternate install instructions.\nBridgecrew API token Throughout the tutorial, you’ll need to use a Bridgecrew API token. You can create one here or in your Bridgecrew account by navigating to the Integrations tab and selecting API Token. Add a token for the workshop and make sure to copy it before closing out.\nWe\u0026rsquo;ll use the API token in a few places with the environment variable YOUR_BC_API_KEY. To make following along easier, set this variable to equal your API token using the following command in your terminal:\nYOUR_BC_API_KEY=\u0026lt;paste-bc-api-key-here\u0026gt;"
},
{
	"uri": "/terraform/20_prerequisites/2003_bc_setup.html",
	"title": "Bridgecrew setup",
	"tags": [],
	"description": "",
	"content": " You’ll need to sign up for a free Bridgecrew account to follow along with this tutorial. You can sign up for a free account here.\nCheckov In this tutorial, we’re also going to use Checkov. Checkov works on Windows, Mac, and Linux. You can install it with pip:\npip3 install checkov If installing globally on your system (not in a python venv or pipenv) you may need to have permissions to write the libraries to the necessary locations, ie:\nsudo pip3 install checkov If you run into problems, try the alternate install instructions.\nBridgecrew API token Throughout the tutorial, you’ll need to use a Bridgecrew API token. You can create one here or in your Bridgecrew account by navigating to the Integrations tab and selecting API Token. Add a token for the workshop and make sure to copy it before closing out.\nWe\u0026rsquo;ll use the API token in a few places with the environment variable YOUR_BC_API_KEY. To make following along easier, set this variable to equal your API token using the following command in your terminal:\nYOUR_BC_API_KEY=\u0026lt;paste-bc-api-key-here\u0026gt;"
},
{
	"uri": "/kubernetes/30_scenario_walkthrough.html",
	"title": "Scenario Introduction",
	"tags": [],
	"description": "",
	"content": " The Scenario Your workshop drops you into an example development team, at the start of their journey through the DevSecOps world!\nThey already use ‘Infrastructure as Code’ to define their environments, and the deployment target is a Kubernetes cluster, which is also setup.\nTheir continuous deployment (CD) tool is ArgoCD, which is configured to take any changes to in their main infrastructure GitHub branch, and apply those changes to the cluster, for both the Prod and Dev environments! You have already briefly met the infrastructure as code repository holding these deployments, it’s the KustomizeGoat repository we all forked as part of the workshop setup, your fork is the thing powering these deployments into your cluster, so you can make your own changes as we dig deeper into this workshop.\nLet’s take a look around Kubectl You should already have access to your \u0026ldquo;kind\u0026rdquo; Kubernetes cluster for this workshop, confirm that with the following command, showing our Kubenetes cluster nodes:\nkubectl get nodes We can also take a look at the existing Namespaces running on our cluster:\nkubectl get ns  Here we can see a number of namespaces including one for our ArgoCD continuous deployment system, which itself is running on our cluster and monitoring our git repo for changes to our infrastructure configuration.\nLet\u0026rsquo;s take a look at the pods and services in that namespace.\nkubectl get po --namespace argocd Looks like ArgoCD is up and running. Let\u0026rsquo;s have a look at the services for ArgoCD:\nkubectl get svc --namespace argocd It seems the web interface “argo-server” has a NodePort configuration, which means we should be able to use the public IP of our KIND host on either HTTP port 32080 or HTTPS port 32443 to access the interface.\nAccess to these ports have been locked down to your public IP address provided during cloudformation setup, if your public IP has changed or if you cannot access the interface based on the details given in the workshop setup, please reach out to your workshop host.  In the next step, we’ll go ahead and explore the ArgoCD setup.\n"
},
{
	"uri": "/kubernetes/30_scenario_walkthrough/3001_argo_cd.html",
	"title": "ArgoCD",
	"tags": [],
	"description": "",
	"content": " In order to access the ArgoCD web interface within our Kubernetes cluster, we\u0026rsquo;ll need to know the public IP address of our workshop environment.\nClicking the link below, will load the CloudFormation stacks page. Select bridgecrew-workshop and select the Outputs tab, where we will see the public IP and ArgoCD URL.\nhttps://us-east-2.console.aws.amazon.com/cloudformation/home?region=us-east-2#/stacks?filteringStatus=active\u0026amp;filteringText=\u0026amp;viewNested=true\u0026amp;hideStacks=false\nThe URL will be in the form https://\u0026lt;CLUSTER IP\u0026gt;:32443 click this link and you will be prompted with the ArgoCD login screen.\nYou can cat .bcworkshop/.argo-password within our Cloud9 terminal to reveal the password for login. The username is admin.\nLog into the ArgoCD web interface to see the current state of our environment.\nWe can see that one of our environments, kustomizegoat-prod is healthy, it is “synced” between what we’ve declared in our infrastructure-as-code configuration, and what is running on our cluster.\nLets take a look at the healthy prod environment in this visual manor, rather than digging through the kubernetes manifests for now.\nClick anywhere on the “kustomizegoat-prod” box for a deeper look.\nkustomizegoat-prod In this view, we can see a pretty simple deployment, a Kubernetes deployment, with a single ReplicaSet, running two Pods. Then a Service loadbalancer linking to the pods, great!\nNow we’ll do the same with the dev environment to see what is going on there!\nkustomizegoat-dev In dev, we see a different story, the service loadbalancer is created, but the Deployment has no children, no ReplicaSet and no Pods, we also see an error in the ArgoCD interface:\nClicking on the “App Conditions: 1 Error” message, we see why this deployment hasn’t been successful.\nIt looks like the deployment was blocked from running on the cluster due to a number of security issues found by Bridgecrew’s Kubernetes admission controller, which the dev team had just installed. But thats not the nicest way to view the error.\nFollow the complete details link at the bottom of the error message for a clearer view.\n"
},
{
	"uri": "/aws/6_prerequisites/7_aws_setup/8_aws_eventengine/workspace.html",
	"title": "Create a workspace",
	"tags": [],
	"description": "",
	"content": " The Cloud9 workspace should be built by an IAM user with Administrator privileges, not the root account user. Please ensure you are logged in as an IAM user, not the root account user.\n This workshop was designed to run in the Oregon (us-west-2) region. Please don\u0026rsquo;t run in any other region. Future versions of this workshop will expand region availability, and this message will be removed.\n Ad blockers, javascript disablers, and tracking blockers should be disabled for the cloud9 domain, or connecting to the workspace might be impacted. Cloud9 requires third-party-cookies. You can whitelist the specific domains.\n Launch Cloud9: Create a Cloud9 Environment: https://us-west-2.console.aws.amazon.com/cloud9/home?region=us-west-2\nMake sure you are naming your Cloud9 environment Bridgecrew-Workshop, otherwise things will break later.\n  Select Create environment Name it Bridgecrew-Workshop and hit next. Select a t3.medium instance type  Leave all the default selections.\n When it comes up, customize the environment by closing the welcome tab and lower work area, and opening a new terminal tab in the main work area:  Your workspace should now look like this:  If you like this theme, you can choose it yourself by selecting View / Themes / Solarized / Solarized Dark in the Cloud9 workspace menu.\n  "
},
{
	"uri": "/terraform/20_prerequisites/aws_setup/aws_event/workspace.html",
	"title": "Create a workspace",
	"tags": [],
	"description": "",
	"content": " The Cloud9 workspace should be built by an IAM user with Administrator privileges, not the root account user. Please ensure you are logged in as an IAM user, not the root account user.\n This workshop was designed to run in the Oregon (us-west-2) region. Please don\u0026rsquo;t run in any other region. Future versions of this workshop will expand region availability, and this message will be removed.\n Ad blockers, javascript disablers, and tracking blockers should be disabled for the cloud9 domain, or connecting to the workspace might be impacted. Cloud9 requires third-party-cookies. You can whitelist the specific domains.\n Launch Cloud9: Create a Cloud9 Environment: https://us-west-2.console.aws.amazon.com/cloud9/home?region=us-west-2\nMake sure you are naming your Cloud9 environment Bridgecrew-Workshop, otherwise things will break later.\n  Select Create environment Name it Bridgecrew-Workshop and hit next. Select a t3 medium instance  Leave all the default selections.\n When it comes up, customize the environment by closing the welcome tab and lower work area, and opening a new terminal tab in the main work area:  Your workspace should now look like this:  If you like this theme, you can choose it yourself by selecting View / Themes / Solarized / Solarized Dark in the Cloud9 workspace menu.\n  "
},
{
	"uri": "/kubernetes/30_scenario_walkthrough/3002_bridgecrew_code_review.html",
	"title": "Bridgecrew Code Reviews",
	"tags": [],
	"description": "",
	"content": "Every time ArgoCD had tried to deploy our Dev environment to the Kubernetes cluster, the cluster had been instructed to check the security posture of incoming kubernetes manifests with the Bridgecrew admission controller.\nDetails of all the issues found with the dev deployment can be seen in this view, with filters for severity, tags, etc.\nIt seems we have 17 detected issues on our Deployment object, and none on the Service object, which explains why this was successfully deployed in the dev environment, but the Deployment wasn\u0026rsquo;t.\nAt the bottom of each item, we’ll see information as to which security issue caused the deployment not to make it into the cluster.\nFor example, one of the issues here is that we have no SecurityContext settings on our Pods or Containers within the Deployment.\nWe can bring up more information about the issue and guidance for each issue with the lightbulb symbol on the header of each issue.\nGuidelines (in this case, linking to https://docs.bridgecrew.io/docs/bc_k8s_28) provide extra context for dev teams on each issue.\n"
},
{
	"uri": "/aws/6_prerequisites/7_aws_setup/9_own_account.html",
	"title": "Own AWS Account",
	"tags": [],
	"description": "",
	"content": " Using your own AWS Account Your account must have the ability to create new IAM roles and scope other IAM permissions.\n  If you don\u0026rsquo;t already have an AWS account with Administrator access: create one now by clicking here\n Once you have an AWS account, ensure you are following the remaining workshop steps as an IAM user with administrator access to the AWS account: Create a new IAM user to use for the workshop\n Enter the user details:  Attach the AdministratorAccess IAM Policy:  Click to create the new user:  Take note of the login URL and save:   "
},
{
	"uri": "/kubernetes/30_scenario_walkthrough/3003_automation_deepdive.html",
	"title": "Automation Deepdive",
	"tags": [],
	"description": "",
	"content": " While doing things manually is NOT what we want for a DevSecOps pipeline, for the sake of understanding the current setup a little more, lets see what it looks like if the developer was to try and apply the dev environment directly to the kubernetes cluster using the CLI, kubectl.\nThis will render the kustomize template and pass it to the kubernetes API, we should see the same results from the API as we saw through Argo, with our admission controller rejecting the deployment…\nkubectl create namespace kustomizegoat kubectl apply -k ./kustomizegoat/kustomize/overlays/dev Unwrapping the Admission Controller: Checkov As the admission controller is powered by our open source Infra-as-code scanning tool, checkov.io, we can simulate the failure even without having a kubernetes cluster, by having Checkov scan the local kustomize manifests.\nTo do this, try running checkov -d ./kustomizegoat --framework kustomize in the kustomize directory, you will see output on the CLI very similar to what we have already seen in Bridgecrew from the admission controller.\nHere you will see all the policy results from Checkov for all of our overlays and base directories. The Admission controller has a configurable list of specific policies it rejects (high severity) where as this checkov output will show all severities!\n"
},
{
	"uri": "/aws/6_prerequisites/7_aws_setup/9_own_account/workspace.html",
	"title": "Create a workspace",
	"tags": [],
	"description": "",
	"content": " The Cloud9 workspace should be built by an IAM user with Administrator privileges, not the root account user. Please ensure you are logged in as an IAM user, not the root account user.\n This workshop was designed to run in the Oregon (us-west-2) region. Please don\u0026rsquo;t run in any other region. Future versions of this workshop will expand region availability, and this message will be removed.\n Ad blockers, javascript disablers, and tracking blockers should be disabled for the cloud9 domain, or connecting to the workspace might be impacted. Cloud9 requires third-party-cookies. You can whitelist the specific domains.\n Launch Cloud9: You can skip this step and use the VS Code Plugin instead to get more Bridgecrew benefits\n Create a Cloud9 Environment: https://us-west-2.console.aws.amazon.com/cloud9/home?region=us-west-2\n Select Create environment Name it Bridgecrew-Workshop, and take all other defaults Select t3.medium as the instance type When it comes up, customize the environment by closing the welcome tab and lower work area, and opening a new terminal tab in the main work area:  Your workspace should now look like this:  If you like this theme, you can choose it yourself by selecting View / Themes / Solarized / Solarized Dark in the Cloud9 workspace menu.\n  "
},
{
	"uri": "/aws/6_prerequisites/601_setting_up_bridgecrew_account.html",
	"title": "Bridgecrew Setup",
	"tags": [],
	"description": "",
	"content": " You’ll need to sign up for a free Bridgecrew account to follow along with this tutorial. You can sign up for a free account here.\nBridgecrew CLI In this tutorial, we’re also going to use Bridgecrew CLI. The CLI works on Windows, Mac, and Linux. You can install it with pip:\npip3 install bridgecrew If installing globally on your system (not in a python venv or pipenv) you may need to have permissions to write the libraries to the necessary locations, ie:\nsudo pip3 install bridgecrew If you run into problems, try the alternate install instructions.\nBridgecrew API token Throughout the tutorial, you’ll need to use the Bridgecrew API token. You can get an API key by going to Integrations -\u0026gt; API Tokens -\u0026gt; Add Token. Give it a name like workshop and save it for the rest of the workshop.\n"
},
{
	"uri": "/kubernetes/30_scenario_walkthrough/3004_scenario_summary.html",
	"title": "Scenario Summary",
	"tags": [],
	"description": "",
	"content": " You are here! This is all well and good, there’s a free Admission controller that our Dev team have installed into our Kubernetes cluster to prevent bad things being deployed, however, lets look where in the development cycle this is currently happening:\nWe’ve blocked this deployment in the red oval, a lot of developers time, commands, processing time on code testing, and other processes have already happened before this point. I’m sure we can make it easier for issues to be spotted earlier in the pipeline!\nPlus, by the time we’re at the Kubernetes cluster, our alerts look like this: That random filename is the internals of the Kubernetes admission controller rendering our template and checking it for errors, not very developer friendly as a security output! We’ve lost the context of the original code repository, let\u0026rsquo;s see what else we can do to improve developer experience here!\n"
},
{
	"uri": "/kubernetes/40_pull_requests_and_ci.html",
	"title": "Pull Requests and CI",
	"tags": [],
	"description": "",
	"content": " The new scenario Our Dev team is happy we’ve blocked issues from reaching the cluster, but lets try and make that feedback loop better, and our errors more readable and easier to fix!\nWe already know our infrastructure code is stored in a GitHub repository, it’s time to take a look at adding some extra layers of defense!\nPull requests as security gates Following GitOps principals, our “production/main” branches of our git repository should reflect exactly what is in production at this point in time, changes should be reconciled so that the Kubernetes cluster (or any other runtime resource for that matter) reflects the changes in our Git “source of truth”.\nIt’s important then, that changes to our main branches are made carefully, with engineers given the abilities to run tests on changes before they are considered for inclusion!\nAutomation is key here, just as in Continuous Deployment, as otherwise each small change would carry a huge amount of wasted time in manual testing (which commonly leads to mistakes through human error or lack of team morale through dull repetitive tasks).\nBy integrating Bridgecrew directly with our GitHub repository, we can enable pull request scanning and automatic annotation of security issues in the Pull Request, providing a much earlier, cleaner developer experience and keeping our security issues even further away from Prod!\n"
},
{
	"uri": "/kubernetes/40_pull_requests_and_ci/4001_integrate_bridgecrew_github.html",
	"title": "Integrate Bridgecrew with GitHub",
	"tags": [],
	"description": "",
	"content": " Integrating Bridgecrew with GitHub To enable automated PR scanning on your repositories, goto the **Integrations **page at the bottom of the icon bar on the left.\nThen, click on New Integration and select GitHub from the code repositories options\nA popout dialog will allow you to Authorize with your GitHub account and chose the repositories you want Bridgecrew to scan, click **Authorize **to be redirected to GitHub to complete this.\nIf you have access to multiple GitHub organizations, you’ll be asked to select the one you wish Bridgecrew to access, then will be able to select all or specific repositories.\nYou’ll then be redirected back to the Bridgecrew interface, where again you will be able to select specific subsets of repositories if needbe.\nThats it, Bridgecrew is now configured to scan your Git repo’s for Infrastructure as Code issues, as well as automatically scan Pull Requests into your repo’s for potential issues.\nCheck PR tagging settings While we are here, click on your username in the bottom left of the Bridgecrew Dashboard, and select Code Repository Settings from the user options.\nHere you will find a section called Code Reviews and Pull Request Bot Comments. Make sure both options are on in order to have Pull Requests automatically scanned and annotated, you can also select specific issue severity at a global level here for annotated PR’s.\n"
},
{
	"uri": "/kubernetes/40_pull_requests_and_ci/4002_create_test_pr.html",
	"title": "Create A Pull Request",
	"tags": [],
	"description": "",
	"content": " Creating Infrastructure with a Pull Request! To see our new security controls in action, let\u0026rsquo;s create a pull request to modify our Dev environment configuration!\nIn GitHub, on your fork of KustomizeGoat, click into the kustomize \u0026gt; overlays and dev directories:\nClick on the kustomization.yaml file to open it in the GitHub web viewer, and click edit\nLets make a simple change right now, and modify the name of the dev Namespace\nEnsure you select Create a new branch for this commit and propose the change.\nThis will automatically queue up a new pull request with your change included, on the next page, press Create Pull Request\nThe pull request will load, and you will immediately see Bridgecrew checks about to run against the proposed infrastructure changes. "
},
{
	"uri": "/kubernetes/40_pull_requests_and_ci/4003_blocking_with_ci.html",
	"title": "Block with CI",
	"tags": [],
	"description": "",
	"content": " PR Scanning vs CI Our pull request annotations give good collaborative team feedback to the development teams involved, however, without extra configuration, the feedback is ecactly that, just feedback.\nCI pipelines allow us to actually block (by failing) a build or change from making it from a development branch, into a main or production branch, while these two types of scans overlap, it is worth showing how you can configure Bridgecrew to sit within any CI pipeline to perform this function.\nAs we are in a GitHub source control environment, we\u0026rsquo;ll configure GitHub actions to block builds, giving us another defensive checkpoint.\nConfigure the Bridgecrew GitHub action integration. To enable automated PR scanning on your repositories, goto the **Integrations **page at the bottom of the icon bar on the left.\nThen, click on New Integration and select GitHub Actions from the CI/CD Systems section\nA popout dialog will allow you to create a new Bridgecrew API token to be used by the GitHub Action, give the token a name and click next, twice.\nFollow the instructions on the “Add Environment Variable” page to ensure the API key is stored in our Github KustomizeGoat repository as a secret.\nWithin the GitHub repository settings, find Security \u0026gt; Secrets and select Actions then from the **Actions secrets **page above, select New repository secret and fill in the relevant details.\nFinally, click Add secret, you will see the new secret listed in the Actions secrets page.\nThen back in Bridgecrew, click Next to access an example GitHub Action step, then click Done to exit the new integration setup!\nAdding the action to our github repository. Github Actions are defined as workflow files within your code repository under the .github/workflows directory. To create an action, you’ll add a new file to this directory. If you already have workflows and are familiar with the workflow file format, you could add the Bridgecrew step section example we saw in the integration setup page to your own workflows for the same results.\nTo create a new workflow, select “Actions” within your KustomizeGoat forked repository, and then click on “set up a workflow yourself” to create a new, blank workflow.\nName the new file bridgecrew.yaml\nNow we’ll replace the entire example / documentation contents shown by default with the workflow template provided below. This takes the jobs section provided by the Bridgecrew integration instructions and wraps it in a fully functional GitHub Actions definition.\nname: Bridgecrew on: pull_request: push: branches: - main jobs: scan: runs-on: ubuntu-latest strategy: matrix: python-version: [3.8] steps: - uses: actions/checkout@v2 - name: Run Bridgecrew id: Bridgecrew uses: bridgecrewio/bridgecrew-action@master with: api-key: ${{ secrets.BC_API_KEY }} Select “Start commit” at the top right once you’ve added the workflow file contents.\nFinally, save the new workflow file into your code repository by selecting Commit new file.\nNotice how the action was configured for Pull Requests and the main branch?\nThe GitHub Action will start running Bridgecrew scans against the latest commit in your KustomizeGoat repository. You can see this by selecting the “Actions” page within your forked repository in GitHub. You will see a new workflow, titled Bridgecrew, and that the job that was kicked off by merging in the workflow yaml file.\nSelecting this job will allow you to view the status and logging output from the pipeline, where checkov will run and output any violations found in the KustomizeGoat codebase.\nRather than digging through the job logs, the action also outputs security annotations for each violation found in the “*Security*” tab of the repository on github, here we get a much clearer at-a-glance view of the main branch:\nThe full output can always be found through the Actions tab and drilling down into a specific run.\nThe Bridgecrew GitHub Action can either pass all builds or block builds based on policy violations. The first acts as just an observability and alerting tool, the second as guardrails for developers to prevent misconfigured templates from making it into the repository. You can change this to not fail a build by adding soft_fail: true setting in the with block.\nAs with all Bridgecrew integrations, all CI scans are also reported into the Bridgecrew dashboard as Code Reviews:\nThats it, We\u0026rsquo;ll now block our CI pipeline from continuing if we have IaC policy failures.\n"
},
{
	"uri": "/aws/6_prerequisites/7_aws_setup/8_aws_eventengine/setup_short.html",
	"title": "Quick Setup",
	"tags": [],
	"description": "",
	"content": " We are going to install jq and initilize a python enviroment. Cloud9 already has the latest version of Python installed.\n Install jq - jq is a command-line tool for parsing JSON.\nsudo yum install jq Start a python enviroment\npython3 -m venv env source ./env/bin/activate "
},
{
	"uri": "/terraform/20_prerequisites/aws_setup/aws_event/setup_short.html",
	"title": "Quick Setup",
	"tags": [],
	"description": "",
	"content": " We are going to install jq and initilize a python enviroment. Cloud9 already has the latest version of Python installed.\n Install jq - jq is a command-line tool for parsing JSON.\nsudo yum install jq Start a python enviroment\npython3 -m venv env source ./env/bin/activate "
},
{
	"uri": "/kubernetes/50_ide_integration.html",
	"title": "IDE Integration",
	"tags": [],
	"description": "",
	"content": " The new scenario Not only do we now have controls blocking severe security issues from our Kubernetes cluster, but we also have early warning systems directly in the developers eye-line (Pull Request scans and CI testing).\nBut we’re still causing a little bit of friction! no-one likes thinking they are finished, committed, pull request raised, only to need to go back and make more changes.\nHere we’ll add the VSCode IDE plugin, to surface potential issues right at the point of development!\nFixing before commit The best issue is one that never even makes it into a git commit, and by highlighting potential issues in VSCode, we can achieve just that!\nFor this section, we’ve jumped out of our pre-built environment, and I have cloned by KustomizeGoat fork directly onto my local machine in order to open within VSCode!\nBy all means skip this section if you’d rather not touch your local machine setup, the rest of the workshop does not depend on this VSCode module. (It is very cool though!)\nHere we can see VSCode, with the Extensions sidebar open on the left, we have found and installed the Checkov by Bridgecrew extension.\nThe extension simply needs a Bridgecrew API key to function, like the one we created with the GitHub action integration, and can be entered by clicking on the new checkov status item on the blue bar at the bottom of the VSCode window:\nCheckov is currently scanning the kustomize/base/deployment.yaml file within our KustomizeGoat repository, it will scan any IaC (infrastructure as code) file when opened in VSCode.\nOnce the scan is complete, any issues found will be annotated onto the Kubernetes objects themselves with red underline of the object in question.\nHovering over the red underlined object will provide more context, and a list of all the same issues that we were seeing in our CI/CD pipeline and Pull Requests!\nThere are other ways to surface this information rather than the hover-over dialog box, opening the VSCode Problem payne will allow you to see Checkov’s findings detached from the code display.\nKubernetes mode vs Kustomize mode In VSCode, kubernetes objects are scanned and annotated as they are found, it makes no sense to render a resulting kustomize manifest at this stage (it may not even be complete), so any valid Kubernetes objects, per-file, will be scanned as-is.\nTherefore results could vary slightly from VSCode and the fully rendered Kustomize environments in CI/CD and our Admission Controller checks; however having the same policies being enforced in all these locations aims to help the developer experience when it comes to implementing DevSecOps and a more secure IaC posture.\nCongrats, That\u0026rsquo;s all for IDE enablement! At the time of this workshop, we also support IntelliJ with the same style of plugin! Check it out if interested from the Integrations page in Bridgecrew.\n"
},
{
	"uri": "/kubernetes/60_securing_runtime.html",
	"title": "Securing Runtime",
	"tags": [],
	"description": "",
	"content": " The new scenario Awesome work! Now we have helpful security feedback in VSCode, security warnings in Pull Requests, Blocking CI/CD on our main branch, and the admission controller providing backup for the most critical issues!\nWe’ve shifted so far left and pretty much got our lifecycle covered, but we never considered where our deployments were going, “Runtime”.\nOur AWS accounts are just as likely to have misconfigurations, consider the following possibilities:\n Anything deployed before all the companies teams’ implemented a DevSecOps pipeline, with less security checks and balances enforced. Operator error changing an IAM policy when debugging an issue in production. An attackers foothold, editing anything they have permission to access to try and broaden their privileges  Lets make sure we complete the circle by also holding our runtime environment to the same expectations as we’re now holding our infrastructure code!\nThe many faces of runtime If our infrastructure was deployed using another Infrastructure-as-code framework, such as Terraform, or CloudFormation, where the IaC was directly creating AWS objects, we would only need to monitor the AWS account itself; Bridgecrew can use the AWS API’s to do this via the AWS Runtime integration we’ll enable below.\nHowever, our workloads, while running in AWS, are ontop of another layer of abstraction, Kubernetes, which brings it’s own context and API’s.\nFor full visibility of our runtime environment (as workloads are often not alone, with supporting services such as storage, databases, queues, not to mention IAM) we will need to enable AWS Integration AND Kubernetes Runtime integration to see the whole picture.\n"
},
{
	"uri": "/kubernetes/60_securing_runtime/6001_aws_runtime_scanning.html",
	"title": "AWS Runtime",
	"tags": [],
	"description": "",
	"content": " AWS Runtime Greenfield infrastructure as code deployments are a luxury not many of us have. In reality, our AWS accounts have objects that were created manually for one reason or another. Transitioning to IaC is rarely a one-and-done affair, so you may have objects in your AWS accounts that are managed by a team that has not yet made the switch.\nThat’s why it’s important to scan objects directly in your AWS environment in addition to scanning your Terraform templates in git or as part of the CI/CD pipeline, as we’ve already shown.\nBridgecrew provides runtime scanning via an AWS integration, allowing full coverage of infrastructure security both before and after deployment.\nAWS runtime integration To enable runtime scanning of your AWS account, go to the Integrations Tab and select “AWS” under the Cloud Providers section. Choose the AWS Read Access Stack and click “Next”.\nRead-only access is scoped as minimally as possible in order to give Bridgecrew only the necessary access to scan your AWS accounts.\nClick Launch Stack to enable the integration.\nYou will be taken to your AWS account to spin up the CloudFormation stack to authorize the integration:\nCheck the checkbox to approve the IAM permission creations via our CloudFormation stack, and click Create Stack:\nYou can track the progress of the stack creation within your AWS account.\nOnce completed, you’ll see the integration in the Bridgecrew Integrations dashboard:\nThat’s all it takes to connect your AWS account to Bridgecrew for continuous cloud security monitoring and compliance benchmarking.\nExploring runtime violations With the AWS account connected, you’ll start to see runtime violations in the Incidents page.\nUnlike the rest of this workshop, the information displayed in your Bridgecrew Dashboard may differ from the images below, as no two AWS accounts will have the same content.\nWe can browse through all the security and compliance violations detected in our live AWS account. We can filter based on Status, Source, Category, Severity, Time Range, Benchmarks, and Tags. There are “low hanging fruit” filters for traced resource, unencrypted resources and publicly accessible resources.\nIn the example below, we can see a security group we deployed previously that opens port 22 to all traffic:\nFurther context on the issue and remediation options is also available by clicking on the lightbulb and on the “Guidelines” link.\nBridgecrew also alerts on account-wide settings such as user password policies and informational best practices, such as tagging each resource with ownership or purpose information or weak account password policies:\nIdentity and Access Management (IAM) Insights Bridgecrew also analyzes AWS IAM roles, permissions, groups, and policies to identify unused and overly-permissive configurations. You can use the filter pane to only show IAM specific issues.\n"
},
{
	"uri": "/kubernetes/60_securing_runtime/6002_k8s_runtime_scanning.html",
	"title": "Kubernetes Runtime",
	"tags": [],
	"description": "",
	"content": " Kubernetes Runtime Great! Now lets add insight into our already-running Kubernetes workloads too!\nIn the integrations page, once again click “ADD INTEGRATION”\nThen, from the Cloud Providers section, chose Kubernetes:\nCreate a new API key for the integration and click “CREATE”:\nGive the cluster a name, this is used to identify the Kubernetes cluster within Bridgecrew. For example, use workshop-cluster.\nFinally, select your kubernetes version (\u0026gt;0.19 or \u0026lt;0.19) and copy the provided kubectl commands:\nNext, we simply run the Kubectl commands provided to enable the runtime integration in our Kubenetes cluster:\nBy running kubectl get cronjob –namespace bridgecrew we can see the bridgecrew runtime agent, scheduled to run and keep bridgecrew updated with the runtime posture of the cluster.\nInstead of waiting for the first scheduled run, lets manually run the job the first time so we can see data in the Bridgecrew dashboard:\nkubectl create job --from=cronjob/bridgecrew manual-bc-runtime-scan --namespace=bridgecrew\nWe will now start to see data under the incidents tab in the Bridgecrew dashboard, you can check on the status of the Job’s instance with the kubectl get job -n bridgecrew command also.\nIn the Incidents tab, which covers only runtime-related events, we will be able to filter on our new cluster name, to see issues with the current running pods and services.\nSome of these are core kubernetes services which require more access than regular hosted applications, so we’ll be looking at how to suppress and create suppression rules for certain items, as well as fixing up our buggy dev environment code in future workshops!\nCongratulations, Runtime scanning is enabled! "
},
{
	"uri": "/kubernetes/70_cleanup.html",
	"title": "Cleanup",
	"tags": [],
	"description": "",
	"content": " Environment Cleanup Below are steps to remove the created environment, depending on which environment you used. You can choose to remove / delete everything, or keep your accounts (such as Github and Bridgecrew) if you previously did not have a user account.\nIf you are not sure whether the accounts were created specifically for the workshop or pre-existed, we recommend keeping them as a precaution, you can also reach out to the workshop host for assistance!\nBridgecrew You can keep your Bridgecrew.cloud account for free, however if you do require account removal, it can be achieved via the “user options” \u0026gt; “Usage”. in the bottom left corner of the dashboard. https://docs.bridgecrew.io/docs/how-do-i-delete-my-account\nAWS Environment To remove the resources created in your AWS account by the workshop, complete these two items.\n1. In CloudFormation, select the bridgecrew-workshop cloudformation template which will have the CREATE_COMPLETE status, and chose Delete.\nYou will then be asked to confirm by typing Delete into a prompt, this will remove the VM and all associated access roles with the workshop, as well as the nested kubernetes cluster, argoCD and related codebases.\n2. In Cloud9, chose the bridgecrew-workshop item under “Shared Environments” and select delete, this will remove the connection to the Cloud9 IDE, which is already being removed as it was hosted on the resources we deleted in step one, above.\nGo it alone (optional local setup) The following commands will remove everything we installed locally following the “Local Setup” instructions. Please ensure you do not need any of these tools or repositories before uninstallation!\n``` # Remove KIND Cluster kind delete cluster –-name bridgecrew-workshop\n# Remove Checkov pipenv uninstall checkov || pip uninstall checkov # Remove yor container docker rmi bridgecrew/yor # Remove cloned kustomizegoat repository rm -rfv kustomizegoat/ # Remove KIND CLI rm -v /usr/bin/kind # Remove kubectl CLI rm -v /usr/bin/kubectl"
},
{
	"uri": "/aws/10_module_one.html",
	"title": "Module - Scan",
	"tags": [],
	"description": "",
	"content": " In this module, we’ll identify common misconfigurations and security best practices in AWS CloudFormation.\nModule Learning Objectives  Creating a demo CloudFormation repository using GitHub by cloning CfnGoat Scan a CloudFormation template for misconfigurations locally Investigate security and compliance errors using Bridgecrew  "
},
{
	"uri": "/azure/30_module_one.html",
	"title": "Module - Scan",
	"tags": [],
	"description": "",
	"content": " MODULE - SCAN In this module, we’ll identify common misconfigurations and security best practices in Terraform.\nModule Learning Objectives  Create a demo environment using our vulnerable-by-design TerraGoat project Scan a Terraform template and directory for misconfigurations using two methods Investigate policy violations in the Bridgecrew platform  "
},
{
	"uri": "/terraform/30_module_one.html",
	"title": "Module - Scan",
	"tags": [],
	"description": "",
	"content": " MODULE - SCAN In this module, we’ll identify common misconfigurations and security best practices in Terraform.\nModule Learning Objectives  Create a demo environment using our vulnerable-by-design TerraGoat project Scan a Terraform template and directory for misconfigurations using two methods Investigate policy violations in the Bridgecrew platform  "
},
{
	"uri": "/aws/10_module_one/1001_cfngoat.html",
	"title": "CfnGoat",
	"tags": [],
	"description": "",
	"content": " Vulnerable-by-design demo repository setup This workshop uses our vulnerable-by-design CloudFormation project, CfnGoat, so that you can scan and automate infrastructure code without the added friction of integrating your own code. Simply clone the open-source project’s repository:\ngit clone https://github.com/bridgecrewio/cfngoat.git cd cfngoat git status Sample output:\n$ git clone https://github.com/bridgecrewio/cfngoat.git cd cfngoat git status Cloning into \u0026#39;cfngoat\u0026#39;... remote: Enumerating objects: 64, done. remote: Counting objects: 100% (64/64), done. remote: Compressing objects: 100% (54/54), done. remote: Total 64 (delta 18), reused 33 (delta 7), pack-reused 0 Unpacking objects: 100% (64/64), 73.62 KiB | 718.00 KiB/s, done.  On branch master Your branch is up to date with \u0026#39;origin/master\u0026#39;.  nothing to commit, working tree clean  ➜ cfngoat git:(master)"
},
{
	"uri": "/azure/30_module_one/1001_terragoat.html",
	"title": "TerraGoat",
	"tags": [],
	"description": "",
	"content": " Vulnerable-by-design demo repository setup This workshop uses our vulnerable-by-design Terraform project, TerraGoat, so that you can scan and automate infrastructure code without the added friction of integrating your own code.\nFork the TerraGoat repository on GitHub To set up your demo environment, we\u0026rsquo;re going to fork the TerraGoat repository.\nHead over to the TerraGoat repository and fork it using the button in the upper right corner.\nIf you have multiple organizations, GitHub will ask which of your orgs to fork into. Choose your personal account via your username in the list to fork the repo.\nClone a local copy To get a local copy of the TerraGoat repo, simply clone your fork:\ngit clone https://github.com/\u0026lt;your-organization\u0026gt;/terragoat.git cd terragoat git status Sample output:\n$ git clone https://github.com/bcworkshop/terragoat.git cd terragoat git status Cloning into \u0026#39;terragoat\u0026#39;... remote: Enumerating objects: 10, done. remote: Counting objects: 100% (10/10), done. remote: Compressing objects: 100% (10/10), done. remote: Total 581 (delta 2), reused 0 (delta 0), pack-reused 571 Receiving objects: 100% (581/581), 221.43 KiB | 4.26 MiB/s, done. Resolving deltas: 100% (269/269), done.  On branch master Your branch is up to date with \u0026#39;origin/master\u0026#39;.  nothing to commit, working tree clean"
},
{
	"uri": "/terraform/30_module_one/1001_terragoat.html",
	"title": "TerraGoat",
	"tags": [],
	"description": "",
	"content": " Vulnerable-by-design demo repository setup This workshop uses our vulnerable-by-design Terraform project, TerraGoat, so that you can scan and automate infrastructure code without the added friction of integrating your own code.\nFork the TerraGoat repository on GitHub To set up your demo environment, we\u0026rsquo;re going to fork the TerraGoat repository.\nHead over to the TerraGoat repository and fork it using the button in the upper right corner.\nIf you have multiple organizations, GitHub will ask which of your orgs to fork into. Choose your personal account via your username in the list to fork the repo.\nClone a local copy To get a local copy of the TerraGoat repo, simply clone your fork:\ngit clone https://github.com/\u0026lt;your-organization\u0026gt;/terragoat.git cd terragoat git status Sample output:\n$ git clone https://github.com/bcworkshop/terragoat.git cd terragoat git status Cloning into \u0026#39;terragoat\u0026#39;... remote: Enumerating objects: 10, done. remote: Counting objects: 100% (10/10), done. remote: Compressing objects: 100% (10/10), done. remote: Total 581 (delta 2), reused 0 (delta 0), pack-reused 571 Receiving objects: 100% (581/581), 221.43 KiB | 4.26 MiB/s, done. Resolving deltas: 100% (269/269), done.  On branch master Your branch is up to date with \u0026#39;origin/master\u0026#39;.  nothing to commit, working tree clean"
},
{
	"uri": "/aws/10_module_one/1002_local_scan_cli.html",
	"title": "Bridgecrew CLI",
	"tags": [],
	"description": "",
	"content": " Run Bridgecrew CLI locally To demonstrate what kinds of security and compliance errors Bridgecrew can identify in CloudFormation templates, we’ll start by using Bridgecrew CLI and send the results to the Bridgecrew platform.\nMake sure you are in the cfngoat directory from the previous step, copy your unique Bridgecrew API token, and scan the cfngoat.yaml file:\nbridgecrew -f cfngoat.yaml --bc-api-key $YOUR_BC_API_KEY --repo-id bridgecrewio/cfngoat You can also scan entire directories with -d \u0026lt;path\u0026gt;:\nbridgecrew -d . --framework cloudformation --bc-api-key $YOUR_BC_API_KEY --repo-id bridgecrewio/cfngoat You can use the bridgecrew CLI without --bc-api-key, the results will still display locally, without uploading to the bridgecrew cloud, for testing or local-only scan results.  The results will show all the failed checks and link to a guide explaining the cause and how to fix them. Note the output also includes the filename and snippet of code that is misconfigured:\nAs you can see in the highlighted CLI output above, our demo CloudFormation repository has failing checks for two policies: - Ensure S3 bucket has ignore public ACLs enabled - Ensure S3 bucket has ‘restrict_public_bucket’ enabled\nTo get the list of policies that Bridgecrew checks for, use -l or –list:\nbridgecrew --list Bridgecrew policies In many instances, when testing locally with the Bridgecrew CLI, you may only be interested in running just a few checks. In that case, you can add the -c or --check option:\nbridgecrew -f cfngoat.yaml -c CKV_AWS_55,CKV_AWS_56 Alternatively, if you want to run all but a few checks, use the --skip-check option:\nbridgecrew -f cfngoat.yaml --skip-check CKV_AWS_55,CKV_AWS_56  Next, let’s inspect these results in the Bridgecrew dashboard.\n"
},
{
	"uri": "/azure/30_module_one/1002_local_scan_cli.html",
	"title": "Checkov",
	"tags": [],
	"description": "",
	"content": " If you are running Checkov with the Bridgecrew API token and you use a proxy, you may need to turn off your VPN/proxy or use the --ca-certificate flag to allow your proxy\u0026rsquo;s certificate using the directions here: https://github.com/bridgecrewio/checkov/pull/1099. If you run Checkov without the Bridgecrew API token, this won\u0026rsquo;t be an issue.\n Run Checkov locally To demonstrate what kinds of security and compliance errors Bridgecrew can identify in Terraform templates, start by using Checkov and send the results to the Bridgecrew platform.\nMake sure you are in the cloned directory from the previous step, copy your unique Bridgecrew API token, and scan the storage.tf in the azure directory:\ncheckov -f terraform/azure/storage.tf --bc-api-key $YOUR_BC_API_KEY --repo-id bridgecrewio/storage You can also scan entire directories with -d , such as the azure directory:\ncheckov -d terraform/azure/ --bc-api-key $YOUR_BC_API_KEY --repo-id bridgecrewio/azureterragoat You can use Checkov without --bc-api-key to display the results in the command line without uploading to the Bridgecrew platform for testing or local-only scan results.\nThe results will show all the failed policies and link to guides explaining the rationale behind each misconfiguration and steps to fix them. Note the output also includes the filename and snippet of code that is misconfigured:\nIn the example output above, you can see that Bridgecrew identified two failing policies: “Ensure that managed disks use a specific set of disk encryption sets for the customer-managed key encryption” and “Ensure Azure managed disk has encryption enabled”.\nTo get the list of policies that Checkov checks for, use -l or --list:\ncheckov --list Checkov policies In many instances, when testing locally with the Checkov, you may only be interested in running just a few policies. In that case, you can add the -c or --check option:\ncheckov -f terraform/azure/storage.tf -c CKV_AZURE_93,CKV_AZURE_2 Alternatively, if you want to run all but a few policies, use the --skip-check option:\ncheckov -f terraform/azure/storage.tf --skip-check CKV_AZURE_93,CKV_AZURE_2"
},
{
	"uri": "/terraform/30_module_one/1002_local_scan_cli.html",
	"title": "Checkov",
	"tags": [],
	"description": "",
	"content": " If you are running Checkov with the Bridgecrew API token and you use a proxy, you may need to turn off your VPN/proxy or use the --ca-certificate flag to allow your proxy\u0026rsquo;s certificate using the directions here: https://github.com/bridgecrewio/checkov/pull/1099. If you run Checkov without the Bridgecrew API token, this won\u0026rsquo;t be an issue.\n Run Checkov locally To demonstrate what kinds of security and compliance errors Bridgecrew can identify in Terraform templates, start by using Checkov and send the results to the Bridgecrew platform.\nMake sure you are in the cloned directory from the previous step, copy your unique Bridgecrew API token, and scan the s3.tf in the aws directory:\ncheckov -f terraform/aws/s3.tf --bc-api-key $YOUR_BC_API_KEY --repo-id bridgecrewio/s3 You can also scan entire directories with -d , such as the aws directory:\ncheckov -d terraform/aws/ --bc-api-key $YOUR_BC_API_KEY --repo-id bridgecrewio/awsterragoat You can use Checkov without --bc-api-key to display the results in the command line without uploading to the Bridgecrew platform for testing or local-only scan results.\nThe results will show all the failed policies and link to guides explaining the rationale behind each misconfiguration and steps to fix them. Note the output also includes the filename and snippet of code that is misconfigured:\nIn the example output above, you can see that Bridgecrew identified two failing policies: “Ensure EKS Cluster has Secrets Encryption Enabled” and “Ensure Amazon EKS public endpoint not accessible to 0.0.0.0/0”.\nTo get the list of policies that Checkov checks for, use -l or --list:\ncheckov --list Checkov policies In many instances, when testing locally with the Checkov, you may only be interested in running just a few policies. In that case, you can add the -c or --check option:\ncheckov -f terraform/aws/s3.tf -c CKV_AWS_18,CKV_AWS_52 Alternatively, if you want to run all but a few policies, use the --skip-check option:\ncheckov -f terraform/aws/s3.tf --skip-check CKV_AWS_18,CKV_AWS_52"
},
{
	"uri": "/azure/30_module_one/1003_local_scan_dashboard.html",
	"title": "Bridgecrew Dashboard",
	"tags": [],
	"description": "",
	"content": " Viewing results in Bridgecrew You just scanned your Terraform templates locally using Checkov. If you included your API key, the results were sent to the Bridgecrew platform for further investigation. You may have noticed the URL at the end of the CLI scan. That’s a direct link to the results in Bridgecrew.\nClick on that link to bring up that scan’s Projects page, which is an aggregated view of the different Code Reviews across all scan types. This is a list of all of the misconfigurations identified from that CLI scan with filters, severity ratings, and more. We\u0026rsquo;ll discuss this page in more detail later.\n"
},
{
	"uri": "/terraform/30_module_one/1003_local_scan_dashboard.html",
	"title": "Bridgecrew Dashboard",
	"tags": [],
	"description": "",
	"content": " Viewing results in Bridgecrew You just scanned your Terraform templates locally using Checkov. If you included your API key, the results were sent to the Bridgecrew platform for further investigation. You may have noticed the URL at the end of the CLI scan. That’s a direct link to the results in Bridgecrew.\nClick on that link to bring up that scan’s Projects page, which is an aggregated view of the different Code Reviews across all scan types. This is a list of all of the misconfigurations identified from that CLI scan with filters, severity ratings, and more. We\u0026rsquo;ll discuss this page in more detail later.\n"
},
{
	"uri": "/aws/10_module_one/1003_vscode.html",
	"title": "VSCode Plugin",
	"tags": [],
	"description": "",
	"content": " Visual Studio Code extension The Bridgecrew CLI can be used for a quick local scan, but is better suited when automated into a CI/CD pipeline, which we\u0026rsquo;ll dive into in Module Two.\nFor more developer-friendly local scanning, Bridgecrew\u0026rsquo;s Checkov VS Code extension shows scan results directly at the point of code, without having to constantly re-run the CLI tool. Results and suggested fixes are annotated directly onto the specific code block causing the violation in real-time.\nYou can find the plugin here.\n"
},
{
	"uri": "/aws/10_module_one/1004_local_scan_dashboard.html",
	"title": "Bridgecrew Dashboard",
	"tags": [],
	"description": "",
	"content": " Viewing results in Bridgecrew In the previous section, we scanned our demo CloudFormation repository locally with both standalone CLI and the Checkov VSCode plugin, and sent the results to the Bridgecrew platform for investigation and remediation.\nTo explore the reported issues we saw in the CLI output, click on the link at the end of the output or head to the Projects tab in your Bridgecrew account.\nBridgecrew comes with hundreds of out-of-the-box policies to help you adhere to cloud security best practices as defined by the Center of Internet Security (CIS). Bridgecrew policies also correspond to popular compliance frameworks such as PCI-DSS V3.2, NIST-800-53, SOC2, and more.\nThe Projects page comes chock full of features like filters, git blame integrations, dependency mapping, and an audit history.\nFor example\u0026hellip;\nFrom here, we can drill down into a specific violations, or click on the lightbulb icon to see additional details about the policy. We’ll cover how to implement remediations in more depth a little later!\nNow that we have a feel for the kinds of IaC security issues Bridgecrew is equipped to find, let\u0026rsquo;s add some DevSecOps magic.\n"
},
{
	"uri": "/azure/30_module_one/1004_vs_code.html",
	"title": "VS Code Plugin",
	"tags": [],
	"description": "",
	"content": " Run Checkov in your IDE You can get feedback directly in your integrated development environment (IDE) using Bridgecrew’s Checkov Visual Studio Code extension. The tool highlights misconfigurations inline and in development environments—like spell check for IaC misconfigurations.\nFirst, you need to install the extension. In VS Code, go to Extensions and search for Checkov. Click Install.\nNext, go to the Checkov Extension Settings and paste the API Token from the Bridgecrew platform that we saved earlier.\nScan the TerraGoat instance.tf file using the extension. Go to File -\u0026gt; Add Folder to Workspace and navigate to the cloned TerraGoat directory. Add /terraform/azure to your VS Code workspace and open instance.tf.\nCheckov will immediately start scanning and will highlight any identified misconfigurations, with red underline. Move your cursor over the second code block resource azurerm_linux_virtual_machine \u0026quot;linux_machine\u0026quot;. Checkov has identified multiple misconfigurations, including “Ensure Virtual Machine Extensions are not Installed.\u0026rdquo;\nYou can learn more about the policy by selecting “View Problem” or select “Quick Fix” to do exactly that. By selecting “Apply fix for - Ensure Virtual Machine Extensions are not Installed” you automatically patched your codebase for a common misconfiguration.\nNow you can commit that code to your repository with the patch and improved posture.\nNow that we know what Bridgecrew is scanning for and what the results look like, let’s automate it!\n"
},
{
	"uri": "/terraform/30_module_one/1004_vs_code.html",
	"title": "VS Code Plugin",
	"tags": [],
	"description": "",
	"content": " Run Checkov in your IDE You can get feedback directly in your integrated development environment (IDE) using Bridgecrew’s Checkov Visual Studio Code extension. The tool highlights misconfigurations inline and in development environments—like spell check for IaC misconfigurations.\nFirst, you need to install the extension. In VS Code, go to Extensions and search for Checkov. Click Install.\nNext, go to the Checkov Extension Settings and paste the API Token from the Bridgecrew platform that we saved earlier.\nScan your S3 bucket template using the extension. Go to File -\u0026gt; Add Folder to Workspace and navigate to the cloned TerraGoat directory. Add /terraform/aws to your VS Code workspace and open s3.tf.\nCheckov will immediately start scanning and will highlight any identified misconfigurations, with red underline. Move your cursor over the first code block resource \u0026quot;aws_s3_bucket\u0026quot; \u0026quot;data\u0026quot;. Checkov has identified multiple misconfigurations, including “Ensure all data stored in the S3 bucket have versioning enabled Checkov CKV_AWS_21.\u0026rdquo;\nYou can learn more about the policy by selecting “View Problem” or select “Quick Fix” to do exactly that. By selecting “Apply fix for - Ensure all data stored in the S3 bucket have versioning enabled” you automatically patched your codebase for a common misconfiguration.\nNow you can commit that code to your repository with the patch and improved posture.\nNow that we know what Bridgecrew is scanning for and what the results look like, let’s automate it!\n"
},
{
	"uri": "/aws/20_module_two.html",
	"title": "Module - Automate",
	"tags": [],
	"description": "",
	"content": " MODULE - AUTOMATE In the previous section, we used the Bridgecrew CLI to do some quick scanning before committing a change into the code repository. That’s great for checking work here and there but forcing every developer to run a scan on their machines before every single commit isn’t reasonable or feasible. To continuously audit code, automation and built-in workflows are key. With Bridgecrew, you can automate your infrastructure scanning along with the rest of your unit and integration testing by embedding it into your version control system and CI/CD pipeline.\nThis module will show you how to prevent cloud security issues from being deployed by integrating Bridgecrew with both the AWS developer tools suite, and GitHub Actions.\nModule Learning Objectives  Creating your own CloudFormation demo repository on GitHub Setting up AWS CodeBuild Setting up AWS CodePipeline Adding Bridgecrew scanning of CloudFormation manifests into CodeBuild Adding Bridgecrew scanning of CloudFormation manifests with GitHub Actions  "
},
{
	"uri": "/azure/40_module_two.html",
	"title": "Module - Automate",
	"tags": [],
	"description": "",
	"content": " MODULE - AUTOMATE In the previous section, we used Checkov and VS Code extension to scan our Terraform templates locally. However, we can’t expect consistency if the process is one-off. We need to continuously scan the code for misconfigurations before it makes its way into production.\nThat’s where automating IaC scanning in our continuous integration/continuous delivery (CI/CD) pipeline comes in. With Bridgecrew, we can scan templates before they are committed to our VCS when you run other unit and integration testing, or in your VCS. This allows you to provide automated feedback as a part of a CI run and, if in blocking mode, block misconfigured code.\nIn this module, we’ll add in automated scans using GitHub Actions and with Terraform Cloud.\nModule Learning Objectives  Set up the Bridgecrew GitHub Action Set up the Bridgrew GitHub Application Set up the Bridgecrew and Terraform Cloud integration Run a scan  "
},
{
	"uri": "/terraform/40_module_two.html",
	"title": "Module - Automate",
	"tags": [],
	"description": "",
	"content": " MODULE - AUTOMATE In the previous section, we used Checkov and VS Code extension to scan our Terraform templates locally. However, we can’t expect consistency if the process is one-off. We need to continuously scan the code for misconfigurations before it makes its way into production.\nThat’s where automating IaC scanning in our continuous integration/continuous delivery (CI/CD) pipeline comes in. With Bridgecrew, we can scan templates before they are committed to our VCS when you run other unit and integration testing, or in your VCS. This allows you to provide automated feedback as a part of a CI run and, if in blocking mode, block misconfigured code.\nIn this module, we’ll add in automated scans using GitHub Actions and with Terraform Cloud.\nModule Learning Objectives  Set up the Bridgecrew GitHub Action Set up the Bridgrew GitHub Application Set up the Bridgecrew and Terraform Cloud integration Run a scan  "
},
{
	"uri": "/aws/20_module_two/2001_automating_iac_github.html",
	"title": "CloudFormation repository setup",
	"tags": [],
	"description": "",
	"content": " Creating your own CfnGoat repository on GitHub To set up our continuous workflow and demonstrate the value of getting automated infrastructure security scanning, we need a hosted source repository. You can either push your local demo repository to GitHub or, since CfnGoat is already hosted on GitHub, we recommend you fork the repository to your own GitHub account.\nHead to your GitHub account, visit the CfnGoat repository at https://github.com/bridgecrewio/cfngoat, and select Fork in the top right-hand corner:\nIf you have multiple organizations, GitHub will ask which of your orgs to fork into. Choose your personal account via your username in the list to fork the repo.\nYou’ll then be redirected to your newly forked repository—notice your username at the top of the page:\nNow we’re ready to make changes and integrate our automated pipeline!\n"
},
{
	"uri": "/azure/40_module_two/2001_automating_iac_github_action.html",
	"title": "GitHub Action",
	"tags": [],
	"description": "",
	"content": " Setting up the Bridgecrew GitHub Action You can leverage GitHub actions to run automated scans for every build or specific builds, such as the ones that merge into the master branch. This action can alert on misconfigurations, or you can set it up to block code from being merged if certain policies are violated. It can also send the results to Bridgecrew for further review and remediation steps.\nThe TerraGoat repository already has a Checkov Action built in at terragoat/.github/workflows/pull_request.yaml and terragoat/.github/workflows/checkov.yaml. You can remove those files to remove that redundant scan, but we will keep it for this workshop. Typically, you wouldn’t do more than one scan during a build, such as two Actions, a CI/CD integration and a Terraform Cloud scan, so you can remove the Actions when you set up the Terraform Cloud scan or leave it for illustrative purposes.  Start with the GitHub Actions integration page within the Bridgecrew platform. Give your key a name like gh_action and select “Create.” Copy that API token for the next step in the process and click \u0026ldquo;Next\u0026rdquo; and \u0026ldquo;Done.\u0026rdquo;\nThe wizard provides example code to enable Bridgecrew as a GitHub Action.\nYou need to add the Bridgecrew API key you just generated to GitHub in their secrets store as an environment variable. This prevents your API key from being public when you have your code in a public repository.\nGo to your fork of TerraGoat on GitHub and select “Settings”.\nThen select “Secrets” from the left, and click “New Repository Secret”.\nName the secret BC_API_KEY as instructed in the Bridgecrew integration details above.\nCopy and paste your API Token from the Bridgecrew integration wizard into the value field.\nSelecting “Add secret” will list the secret in the “Settings” -\u0026gt; “Secrets” page.\nAdding the automated workflow Github Actions are defined as workflow files within your code repository under the .github/workflows directory. To create an action, you’ll add a new file to this directory. If you already have workflows and are familiar with the workflow file format, you could add the Bridgecrew step section to your own workflows for the same results.\nTo create a new workflow, select “Actions” within your TerraGoat forked repository, click on \u0026ldquo;I understand my workflows, go ahead and enable them,\u0026rdquo; then select “New Workflow.”\nSelect “Set up a workflow yourself” to create a new, blank workflow.\nName the new file bridgecrew.yaml and replace the entire contents with the workflow template provided below. This takes the jobs section provided by the Bridgecrew integration instructions and wraps it in a fully functional GitHub Actions definition.\nname: Bridgecrew on: pull_request: push: branches: - master jobs: scan: runs-on: ubuntu-latest strategy: matrix: python-version: [3.8] steps: - uses: actions/checkout@v2 - name: Run Bridgecrew id: Bridgecrew uses: bridgecrewio/bridgecrew-action@master with: api-key: ${{ secrets.BC_API_KEY }} directory: terraform/ Select “Start commit” once you’ve added the workflow file contents:\nFinally, save the new workflow file into your code repository by selecting “Commit new file”.\nThe GitHub Action will start running Bridgecrew scans against the latest commit in your TerraGoat repository. You can see this by selecting the “Actions” page within your TerraGoat forked repository in GitHub. You will see a new workflow, titled Bridgecrew, and that the job that was kicked off by merging in the workflow yaml file.\nSelecting this job will allow you to view the status and logging output from the pipeline, where checkov will run and output any violations found in the TerraGoat codebase.\nRather than digging through the job logs, the action also outputs annotations for each violation found into the “Summary” page of the action. Again, we can see the identified misconfigurations:\nThe Bridgecrew GitHub Action can either pass all builds or block builds based on policy violations. The first acts as just an observability and alerting tool, the second as guardrails for developers to prevent misconfigured templates from making it into the repository. You can change this to not fail a build by adding soft_fail: true setting in the with block.\n"
},
{
	"uri": "/terraform/40_module_two/2001_automating_iac_github_action.html",
	"title": "GitHub Action",
	"tags": [],
	"description": "",
	"content": " Setting up the Bridgecrew GitHub Action You can leverage GitHub actions to run automated scans for every build or specific builds, such as the ones that merge into the master branch. This action can alert on misconfigurations, or you can set it up to block code from being merged if certain policies are violated. It can also send the results to Bridgecrew for further review and remediation steps.\nThe TerraGoat repository already has a Checkov Action built in at terragoat/.github/workflows/pull_request.yaml and terragoat/.github/workflows/checkov.yaml. You can remove those files to remove that redundant scan, but we will keep it for this workshop. Typically, you wouldn’t do more than one scan during a build, such as two Actions, a CI/CD integration and a Terraform Cloud scan, so you can remove the Actions when you set up the Terraform Cloud scan or leave it for illustrative purposes.  Start with the GitHub Actions integration page within the Bridgecrew platform. Give your key a name like gh_action and select “Create.” Copy that API token for the next step in the process and click \u0026ldquo;Next\u0026rdquo; and \u0026ldquo;Done.\u0026rdquo;\nThe wizard provides example code to enable Bridgecrew as a GitHub Action.\nYou need to add the Bridgecrew API key you just generated to GitHub in their secrets store as an environment variable. This prevents your API key from being public when you have your code in a public repository.\nGo to your fork of TerraGoat on GitHub and select “Settings”.\nThen select “Secrets” from the left, and click “New Repository Secret”.\nName the secret BC_API_KEY as instructed in the Bridgecrew integration details above.\nCopy and paste your API Token from the Bridgecrew integration wizard into the value field.\nSelecting “Add secret” will list the secret in the “Settings” -\u0026gt; “Secrets” page.\nAdding the automated workflow Github Actions are defined as workflow files within your code repository under the .github/workflows directory. To create an action, you’ll add a new file to this directory. If you already have workflows and are familiar with the workflow file format, you could add the Bridgecrew step section to your own workflows for the same results.\nTo create a new workflow, select “Actions” within your TerraGoat forked repository, click on \u0026ldquo;I understand my workflows, go ahead and enable them,\u0026rdquo; then select “New Workflow.”\nSelect “Set up a workflow yourself” to create a new, blank workflow.\nName the new file bridgecrew.yaml and replace the entire contents with the workflow template provided below. This takes the jobs section provided by the Bridgecrew integration instructions and wraps it in a fully functional GitHub Actions definition.\nname: Bridgecrew on: pull_request: push: branches: - master jobs: scan: runs-on: ubuntu-latest strategy: matrix: python-version: [3.8] steps: - uses: actions/checkout@v2 - name: Run Bridgecrew id: Bridgecrew uses: bridgecrewio/bridgecrew-action@master with: api-key: ${{ secrets.BC_API_KEY }} directory: terraform/ Select “Start commit” once you’ve added the workflow file contents:\nFinally, save the new workflow file into your code repository by selecting “Commit new file”.\nThe GitHub Action will start running Bridgecrew scans against the latest commit in your TerraGoat repository. You can see this by selecting the “Actions” page within your TerraGoat forked repository in GitHub. You will see a new workflow, titled Bridgecrew, and that the job that was kicked off by merging in the workflow yaml file.\nSelecting this job will allow you to view the status and logging output from the pipeline, where checkov will run and output any violations found in the TerraGoat codebase.\nRather than digging through the job logs, the action also outputs annotations for each violation found into the “Summary” page of the action. Again, we can see the identified misconfigurations:\nThe Bridgecrew GitHub Action can either pass all builds or block builds based on policy violations. The first acts as just an observability and alerting tool, the second as guardrails for developers to prevent misconfigured templates from making it into the repository. You can change this to not fail a build by adding soft_fail: true setting in the with block.\n"
},
{
	"uri": "/aws/20_module_two/2002_automating_iac_codebuild.html",
	"title": "AWS CodeBuild setup",
	"tags": [],
	"description": "",
	"content": " Setting up AWS CodeBuild for our CloudFormation repository. AWS CodeBuild paired with AWS CodePipeline is a CI/CD platform that can build projects, run jobs, and deploy infrastructure. We’re going to use it to scan the CloudFormation templates before deployment, allowing us to fail the build job and halt a deployment if there are any security violations in our CloudFormation code.\nWe’ll also automatically send the results to Brigecrew to maintain a view across all of our infrastructure projects and share visibility throughout our organization.\nFirst, tell the Bridgecrew dashboard you’re going to integrate AWS CodeBuild. To do this, open the Integrations menu in your Bridgecrew account, select Add Integration and select AWS CodeBuild. Give your token a name and click Next twice. Copy and paste the SSM command in your terminal and hit enter. This will save the Bridgecrew API key into your AWS System Manager’s parameter store so we can access it from our CodeBuild jobs later.\nNext, copy the buildspec.yaml configuration to keep handy (or keep this Bridgecrew tab open).\nIf the aws command fails, your IAM user may not have the correct permissions to create parameters in AWS Systems Manager (SSM). In that case, you’ll need to add write permissions to the user.  New Codebuild Project Now go to your AWS CodeBuild service select Create a Build Project and name your project bridgecrew-tutorial.\nUnder the Source section, choose GitHub in the Source Provider dropdown and select Connect using OAuth. When you select Connect to GitHub, you’ll be prompted to authorize your GitHub account:\nNow the Source section will have changed, allowing us to search for and select our CfnGoat repository from GitHub:\nConfigure your Environment setup to mirror the image below:\nAdding our Buildspec To complete our build setup, we need to add the build commands. Select Insert build commands, and use the editor to overwrite the contents with the YAML code you copied from Bridgecrew earlier.\nSelect Create build project to finalize our CodeBuild project setup!\n"
},
{
	"uri": "/azure/40_module_two/2002_yor_github_action.html",
	"title": "Yor tag &amp; trace",
	"tags": [],
	"description": "",
	"content": " There are two options to detect drift. You can either add the integration with Terraform Cloud or tag your resources with Yor. These don't conflict with each other so you can add both.  An introduction to Yor Yor is an open-source tool that automatically tags infrastructure as code (IaC) templates with attribution and ownership details, unique IDs that get carried across to cloud resources, and any other need-to-know information. It can run locally, as a pre-commit hook, or in a CI/CD pipeline.\nFor drift detection, the important tag is yor_trace. It’s a unique identifier that helps us trace from a cloud runtime configuration back to the IaC that provisioned it. To do that we need 3 elements:\n Yor automated tagging (this page) Integration with the VCS that stores the IaC (we’ll use GitHub in step 5.4 as an example) Cloud integration (we’ll use AWS in step 6.3 as an example)  Let’s start with Yor!\nAdding the Yor GitHub Action If you are using a recent clone of TerraGoat, yor is already setup as a GitHub Action in terragoat/.github/workflows/checkov.yaml. You can skip this page if you have that in place.  If you followed the previous setup for the Bridgecrew GitHub Action, this will be very straightforward. If you’re in the home directory of your TerraGoat repository, select “Create new file”.\nSet the path to .github/workflows/yor.yml. Add the following code:\nname: IaC tag and trace  on:  push:  pull_request:  jobs:  yor:  runs-on: ubuntu-latest  steps:  - uses: actions/checkout@v2  name: Checkout repo  with:  fetch-depth: 0  - name: Run yor action  uses: bridgecrewio/yor-action@main This will run Yor to automatically tag your IaC resources every time you perform a push or pull request to your repo. The result will look something like this:\nNotice the yor_trace tag? That’s all we need to track drift!\n"
},
{
	"uri": "/terraform/40_module_two/2002_yor_github_action.html",
	"title": "Yor tag &amp; trace",
	"tags": [],
	"description": "",
	"content": " There are two options to detect drift. You can either add the integration with Terraform Cloud or tag your resources with Yor. These don't conflict with each other so you can add both.  An introduction to Yor Yor is an open-source tool that automatically tags infrastructure as code (IaC) templates with attribution and ownership details, unique IDs that get carried across to cloud resources, and any other need-to-know information. It can run locally, as a pre-commit hook, or in a CI/CD pipeline.\nFor drift detection, the important tag is yor_trace. It’s a unique identifier that helps us trace from a cloud runtime configuration back to the IaC that provisioned it. To do that we need 3 elements:\n Yor automated tagging (this page) Integration with the VCS that stores the IaC (we’ll use GitHub in step 5.4 as an example) Cloud integration (we’ll use AWS in step 6.3 as an example)  Let’s start with Yor!\nAdding the Yor GitHub Action If you are using a recent clone of TerraGoat, yor is already setup as a GitHub Action in terragoat/.github/workflows/checkov.yaml. You can skip this page if you have that in place.  If you followed the previous setup for the Bridgecrew GitHub Action, this will be very straightforward. If you’re in the home directory of your TerraGoat repository, select “Create new file”.\nSet the path to .github/workflows/yor.yml. Add the following code:\nname: IaC tag and trace  on:  push:  pull_request:  jobs:  yor:  runs-on: ubuntu-latest  steps:  - uses: actions/checkout@v2  name: Checkout repo  with:  fetch-depth: 0  - name: Run yor action  uses: bridgecrewio/yor-action@main This will run Yor to automatically tag your IaC resources every time you perform a push or pull request to your repo. The result will look something like this:\nNotice the yor_trace tag? That’s all we need to track drift!\n"
},
{
	"uri": "/aws/20_module_two/2003_automating_iac_codebuild_iam.html",
	"title": "Edit IAM for CodeBuild",
	"tags": [],
	"description": "",
	"content": " Edit AWS IAM permissions to enable CodeBuild To give CodeBuild access to our Bridgecrew API secret we stored in AWS System Manager, we’ll need to add more permissions to the default IAM role created for new CodeBuild environments.\nIn the AWS IAM Dashboard, find the role called codebuild-bridgecrew-tutorial-service-role\nSelect the role, then click select Add Inline Policy from the right hand side.\nThis will bring up the \u0026ldquo;create policy visual editor\u0026rdquo;, for Service, select Systems Manager in the search box, then chose the GetParameters and GetParameter Actions.\nUnder Resources, choose Specific and select Add ARN. Fill in the same region you’ve created your CodeBuild project and leave the account number as the default. Type bc-api-key as the parameter name to match the name we gave the key in the aws CLI command we used earlier.\nYou could also use the cli command aws ssm get-parameter --name bc-api-key to get the whole ARN and paste it into the ARN field. Select Add then select Review Policy.\nOn the next page, name the policy allow_codebuild_access_to_bridgecrew_secret and select Create policy:\nWe’re now ready to tie this all together with AWS CodePipeline!\n"
},
{
	"uri": "/azure/40_module_two/2003_automating_iac_terraform_cloud.html",
	"title": "Terraform Cloud",
	"tags": [],
	"description": "",
	"content": " There are two options to detect drift. You can either add the integration with Terraform Cloud or tag your resources with Yor. These don't conflict with each other so you can add both.  A new, native integration between Bridgecrew and Terraform Cloud called Run Tasks is coming soon! Check out the HashiCorp keynote for a preview: https://youtu.be/ZzLZaWUve4M?t=1387  Leveraging Terraform Cloud and Sentinel for Bridgecrew scans Bridgecrew has a native integration with Terraform Cloud that leverages Sentinel for policy controls. This means any commit that is pushed to Terraform Cloud will run through a Bridgecrew scan, identifying policy violations, blocking misconfigured builds, and detecting drift, all from the same place that you collaborate on Terraform templates, automate deployments, and store state.\nSentinel is a paid add-on. If you want to try this out for free, HashiCorp does offer a free trial. If you prefer not to sign up for the trial, feel free to skip this section and the \u0026ldquo;drift detection\u0026rdquo; section.\n To sign up for the free trial of Terraform Cloud’s Team \u0026amp; Governance plan, go to your Terraform Cloud instance. In the top navigation, select “Settings” and “Plan \u0026amp; Billing.” Choose the \u0026ldquo;Trial Plan\u0026rdquo; option. You should see Policies and Policy Sets show up in the left navigation menu.\nYou need to add your TerraGoat repository to Terraform Cloud. Go to “Workspaces” and select “Create one now.”\nSelect “Version control workflow”:\nSelect “GitHub,\u0026rdquo; then \u0026ldquo;github.com,\u0026rdquo; and choose your TerraGoat repository we previously forked:\nName the workspace terragoat and open the “Advanced options” and add the directory /terraform/simple_instance/ (we\u0026rsquo;ll be adding that directory later). This will focus the scans to just the Azure templates. Turn on \u0026ldquo;Automatic speculative plans\u0026rdquo; and select “Create workspace”:\nSelect “Configure variables” and add your ARM API variables as follows:\n ARM_TENANT_ID - The tenant field when you created your Contributor Service Account ARM_CLIENT_ID - The appId field when you created your Contributor Service Account ARM_CLIENT_SECRET - The password field when you created your Contributor Service Account ARM_SUBSCRIPTION_ID - The id field from the Account List  If you aren’t sure where to find the keys, go back to the Azure setup step or refer to this guide.\nGo to the Workspace Settings and select General. From this settings screen, grab your workspace ID for the next step.\nGrab the API token from Terraform Cloud for the integration. Go to the API token menu (User -\u0026gt; Settings -\u0026gt; Tokens) and select “Create an API token.”\nCopy that API token for the next step.\nNext, you’ll add the Bridgecrew integration. Head over to the Integrations screen in the Bridgecrew platform. Scroll down and select Terraform Cloud (Sentinel). Enter the token name tfc and choose \u0026ldquo;Create.\u0026rdquo; You don\u0026rsquo;t need to copy that key for this workshop. Paste your \u0026ldquo;Workspace ID,\u0026rdquo; \u0026ldquo;terragoat,\u0026rdquo; \u0026ldquo;TerraGoat,\u0026rdquo; and the API key from Terraform Cloud. Then click \u0026ldquo;Next.\u0026rdquo;\nNormally, you would add a new repo with the Sentinel policies, but for the purpose of this workshop, we\u0026rsquo;re going to simplify this flow. You can click \u0026ldquo;Next\u0026rdquo; on the \u0026ldquo;Create \u0026lsquo;sentinel.hcl\u0026rsquo;\u0026rdquo; step.\nCopy the \u0026lsquo;bridgecrew.sentinel\u0026rsquo; code and click \u0026ldquo;Next\u0026rdquo; in the wizard, then \u0026ldquo;Done.\u0026rdquo; Head back to Terraform Cloud. Go to Settings in the top nav and select “Policy Sets” and “Connect a new policy set”. You can create a versioned policy set, but for the sake of this workshop, go with \u0026ldquo;No VCS connection.\u0026rdquo;. Name your setting terragoat_set and choose the terragoat workspace and select “Connect policy set”.\nThen, select \u0026ldquo;Policies.\u0026rdquo; Click on \u0026ldquo;Create a new policy.\u0026rdquo; Name the policy bridgecrew. The \u0026ldquo;Enforcement mode\u0026rdquo; will determine whether builds are blocked (hard-mandatory) by violations of Sentinel policies, in this case sourced from Bridgecrew, are blocked but with an override (soft-mandatory), or just provide the violations but don\u0026rsquo;t block. For the purpose of this workshop, we know there are violations but we want to deploy them anyway. Set the mode to advisory (logging only).\nPaste the code you copied in the Bridgecrew integration page and paste it into the “Policy code” section. Under \u0026ldquo;Policy Sets,\u0026rdquo; choose terragoat_set from the drop down, then \u0026ldquo;Add policy set\u0026rdquo; and select “Create policy”:\nFinally, go to your workspace\u0026rsquo;s main page and under \u0026ldquo;Actions\u0026rdquo; select \u0026ldquo;Start new plan\u0026rdquo;; don\u0026rsquo;t worry if it fails, this just primes the runs to be automated with future GitHub pull requests.\nYour Terraform Cloud integration is ready to go!\n"
},
{
	"uri": "/terraform/40_module_two/2003_automating_iac_terraform_cloud.html",
	"title": "Terraform Cloud",
	"tags": [],
	"description": "",
	"content": " There are two options to detect drift. You can either add the integration with Terraform Cloud or tag your resources with Yor. These don't conflict with each other so you can add both.  A new, native integration between Bridgecrew and Terraform Cloud called Run Tasks is coming soon! Check out the HashiCorp keynote for a preview: https://youtu.be/ZzLZaWUve4M?t=1387  Leveraging Terraform Cloud and Sentinel for Bridgecrew scans Bridgecrew has a native integration with Terraform Cloud that leverages Sentinel for policy controls. This means any commit that is pushed to Terraform Cloud will run through a Bridgecrew scan, identifying policy violations, blocking misconfigured builds, and detecting drift, all from the same place that you collaborate on Terraform templates, automate deployments, and store state.\nSentinel is a paid add-on. If you want to try this out for free, HashiCorp does offer a free trial. If you prefer not to sign up for the trial, feel free to skip this section and the \u0026ldquo;drift detection\u0026rdquo; section.\n To sign up for the free trial of Terraform Cloud’s Team \u0026amp; Governance plan, go to your Terraform Cloud instance. In the top navigation, select “Settings” and “Plan \u0026amp; Billing.” Choose the \u0026ldquo;Trial Plan\u0026rdquo; option. You should see Policies and Policy Sets show up in the left navigation menu.\nYou need to add your TerraGoat repository to Terraform Cloud. Go to “Workspaces” and select “Create one now.”\nSelect “Version control workflow”:\nSelect “GitHub,\u0026rdquo; then \u0026ldquo;github.com,\u0026rdquo; authorize access, and choose your TerraGoat repository we previously forked:\nName the workspace terragoat and open the “Advanced options” and add the directory /terraform/simple_instance/ (we\u0026rsquo;ll be adding that directory later). This will focus the scans to just the aws templates. Turn on \u0026ldquo;Automatic speculative plans\u0026rdquo; to create plans for pull requests. Select “Create workspace”:\nSelect “Configure variables” and under \u0026ldquo;Workspace variables\u0026rdquo; add your AWS Account and Access Keys as environment variables called AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY. If you are at an AWS event and using Event Engine, include your AWS_SESSION_TOKEN. If you aren’t sure where to find the keys, see this guide.\nFor Event Engine, it will look like this:\nGo to the Workspace Settings and select General. From this settings screen, grab your workspace ID for the next step.\nGrab the API token from Terraform Cloud for the integration. Go to the API token menu (User -\u0026gt; Settings -\u0026gt; Tokens) and select “Create an API token.”\nCopy that API token for the next step.\nNext, you’ll add the Bridgecrew integration. Head over to the Integrations screen in the Bridgecrew platform. Scroll down and select Terraform Cloud (Sentinel). Enter the token name tfc and choose \u0026ldquo;Create.\u0026rdquo; You don\u0026rsquo;t need to copy that key for this workshop. Paste your \u0026ldquo;Workspace ID,\u0026rdquo; \u0026ldquo;terragoat,\u0026rdquo; \u0026ldquo;TerraGoat,\u0026rdquo; and the API key from Terraform Cloud. Then click \u0026ldquo;Next.\u0026rdquo;\nNormally, you would add a new repo with the Sentinel policies, but for the purpose of this workshop, we\u0026rsquo;re going to simplify this flow. You can click \u0026ldquo;Next\u0026rdquo; on the \u0026ldquo;Create \u0026lsquo;sentinel.hcl\u0026rsquo;\u0026rdquo; step.\nCopy the \u0026lsquo;bridgecrew.sentinel\u0026rsquo; code and click \u0026ldquo;Next\u0026rdquo; in the wizard, then \u0026ldquo;Done.\u0026rdquo; Head back to Terraform Cloud. Go to Settings in the top nav and select “Policy Sets” and “Connect a new policy set”. You can create a versioned policy set, but for the sake of this workshop, go with \u0026ldquo;No VCS connection.\u0026rdquo;. Name your setting terragoat_set and choose the terragoat workspace and select “Connect policy set”.\nThen, select \u0026ldquo;Policies.\u0026rdquo; Click on \u0026ldquo;Create a new policy.\u0026rdquo; Name the policy bridgecrew. The \u0026ldquo;Enforcement mode\u0026rdquo; will determine whether builds are blocked (hard-mandatory) by violations of Sentinel policies, in this case sourced from Bridgecrew, are blocked but with an override (soft-mandatory), or just provide the violations but don\u0026rsquo;t block. For the purpose of this workshop, we know there are violations but we want to deploy them anyway. Set the mode to advisory (logging only).\nPaste the code you copied in the Bridgecrew integration page and paste it into the “Policy code” section. Under \u0026ldquo;Policy Sets,\u0026rdquo; choose terragoat_set from the drop down, then \u0026ldquo;Add policy set\u0026rdquo; and select “Create policy”:\nFinally, go to your workspace\u0026rsquo;s main page and under \u0026ldquo;Actions\u0026rdquo; select \u0026ldquo;Start new plan\u0026rdquo;; don\u0026rsquo;t worry if it fails, this just primes the runs to be automated with future GitHub pull requests.\nYour Terraform Cloud integration is ready to go!\n"
},
{
	"uri": "/aws/20_module_two/2004_automating_iac_codepipeline.html",
	"title": "AWS CodePipeline Setup",
	"tags": [],
	"description": "",
	"content": " Setting up AWS CodePipeline to automatically trigger scans To trigger CodeBuild to run the scan automatically on each new commit in your CfnGoat GitHub repository, we’ll need to configure AWS CodePipeline. You can skip this step, but if you do, you’ll only be able to run manual scans from the CodeBuild UI, AWS CLI, or APIs, which doesn’t provide the DevSecOps automation we’re looking for!\nTo set it up, go to AWS CodePipeline and select Create Pipeline:\nAfter giving the pipeline a name, (scan-cfngoat-pipeline) select Next.\nChoose Github (Version 2) as the source provider.\nAs CodeBuild and CodePipeline are different tools, you\u0026rsquo;ll also need to authorize CodePipeline to your GitHub account, select Connect to Github and follow the authorization redirects in the popup window.\nGive the Github Connection a name:\nSelect which Github Repositories you want CodePipeline to receive events for, in this case, i\u0026rsquo;ve just selected the CfnGoat repository.\nOnce you’ve authorized GitHub, select Install a new app to finalize the GitHub integration and select Connect:\nThe CodePipeline screen should refresh with a green Sucessfully connected to GitHub message:\nNow that CodePipeline has access to our GitHub repository, we can select it as the pipeline source. Select the master (or main branch) to have our pipeline run when commits to this branch occur and Full clone:\nInstruct CodePipeline to trigger our CodeBuild When CodePipeline sees a new commit in our GitHub repository, it will trigger a build action. To set this to be our CodeBuild commands, select the same region as the CodeBuild project, then select the CodeBuild project, bridgecrew-tutorial.\nLeave the default of Single Build selected and select Next\nOn the next screen, select Skip deploy stage. We don’t want to deploy our CfnGoat CloudFormation to AWS as we’re just highlighting how to stop a build from progressing if there are security violations!\nCopy the ARN from under \u0026ldquo;ConnectionArn\u0026rdquo; under \u0026ldquo;Step 2: Add source stage.\u0026rdquo; In the example above it\u0026rsquo;s arn:aws:codestar-connections:us-east-1:714....\nNow go to the AWS IAM dashboard, click on Roles and search for the role created by CodePipeline (\u0026ldquo;cfngoat\u0026rdquo; should help you find it.). Click on that role.\nUnder Add permissions click on Attach policies then Create policies. Click on JSON and fill in the following, replacing the ARN with your ARN from CodePipeline (should still be in your clipboard).\n{  \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;,  \u0026#34;Statement\u0026#34;: [  {  \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;,  \u0026#34;Action\u0026#34;: \u0026#34;codestar-connections:UseConnection\u0026#34;,  \u0026#34;Resource\u0026#34;: \u0026#34;insert connection ARN here\u0026#34;  }  ] } Don\u0026rsquo;t worry about tags. Give your policy a name like connection-permissions and then Create policy. Return to the IAM page where you were attaching permissions, refresh the policy list, and select the policy you just created. Choose Attach policies.\nFinally, go back to your CodePipeline and select Create pipeline on the review page, which will trigger your new CodePipeline to immediately run against the latest commit in our CfnGoat repository:\nNow we don’t need to manually run the Bridgecrew CLI; your developers will get a Bridgecrew scan every time they commit!\n"
},
{
	"uri": "/azure/40_module_two/2004_github_application.html",
	"title": "GitHub Application",
	"tags": [],
	"description": "",
	"content": " Integrating Bridgecrew with GitHub In this section, you’ll add a GitHub integration to automatically generate pull request comments and set up for automated fix pull requests (PRs) in the next section. This integration also provides native and automated scanning of incoming commits and pull requests.\nHead back to the Bridgecrew Integrations tab and select GitHub under the Code Repositories section and click on the \u0026ldquo;GitHub organization\u0026rdquo; link:\nChoose which accounts and repositories to grant the Bridgecrew GitHub integration access to:\nThis will bring you back to the Bridgecrew Integrations page. Select \u0026lt;your-org\u0026gt;/terragoat, \u0026ldquo;Next,\u0026rdquo; and \u0026ldquo;Done.\u0026rdquo;\nOnce you’ve connected Bridgecrew to your TerraGoat demo repository, Bridgecrew will scan your Terraform templates directly from GitHub again and bring the results into Bridgecrew.\nHead over to the Projects tab and find the TerraGoat repository:\nYou will now see the same violation alerting from multiple sources. Although this may seem redundant, it’s actually an important feature for tracking security posture at multiple steps in the DevOps lifecycle.\nYou’re all set!\nNow head over to your forked TerraGoat repository in GitHub to kick off a pull request to make sure it’s working.\n"
},
{
	"uri": "/terraform/40_module_two/2004_github_application.html",
	"title": "GitHub Application",
	"tags": [],
	"description": "",
	"content": " Integrating Bridgecrew with GitHub In this section, you’ll add a GitHub integration to automatically generate pull request comments and set up for automated fix pull requests (PRs) in the next section. This integration also provides native and automated scanning of incoming commits and pull requests.\nHead back to the Bridgecrew Integrations tab and select GitHub under the Code Repositories section and click on the \u0026ldquo;GitHub organization\u0026rdquo; link:\nChoose which accounts and repositories to grant the Bridgecrew GitHub integration access to:\nThis will bring you back to the Bridgecrew Integrations page. Select \u0026lt;your-org\u0026gt;/terragoat, \u0026ldquo;Next,\u0026rdquo; and \u0026ldquo;Done.\u0026rdquo;\nOnce you’ve connected Bridgecrew to your TerraGoat demo repository, Bridgecrew will scan your Terraform templates directly from GitHub again and bring the results into Bridgecrew.\nHead over to the Projects tab and find the TerraGoat repository:\nYou will now see the same violation alerting from multiple sources. Although this may seem redundant, it’s actually an important feature for tracking security posture at multiple steps in the DevOps lifecycle.\nYou’re all set!\nNow head over to your forked TerraGoat repository in GitHub to kick off a pull request to make sure it’s working.\n"
},
{
	"uri": "/aws/20_module_two/2005_automating_iac_results.html",
	"title": "Pipeline Results",
	"tags": [],
	"description": "",
	"content": " Reviewing our pipeline results Your new CodePipeline will immediatley start running your CodeBuild job against the latest commit in your GFNGoat Repository.\nYou will be taken to the Pipeline Jobs page where you will see the progress as CodeBuild checks out the latest commit from GitHub and starts our job to run Bridgecrew against the CloudFormation configuration.\nBelow we see the Pipeline sucessfully created and starting to run:\nIf everything goes as intended, the pipeline should fail at the build stage since the CfnGoat code is purposely designed with security flaws. Only when the issues are fixed will the pipeline status turn to green.\nBy blocking the committed code from making it to any “Deploy” steps, we can prevent vulnerable infrastructure from making its way to any AWS account, be it test or prod and helping to satisfy the requirements of the AWS Shared Responsibility Model\nDig into the failed build Details and select the link to execution details:\nHere we are provided a link to our build logs, revealing the security violations and why Bridgecrew blocked the build:\nNavigating to Codebuild \u0026gt; Report Group, we can also see a simple graph of failed and passed checks with an easier-to-read output of all failed checks.\n\u0026ldquo;AWS CodeBuild JUnit output\u0026rdquo;)\nCongratulations! You’ve just automated security scanning of your infrastructure as code into a developer-friendly CI/CD pipeline.\nIn the next module, we’ll look at how to investigate and fix these issues, as well as providing more tips for integrating security into the developer workflow without causing friction.\n"
},
{
	"uri": "/azure/40_module_two/2005_kickoff_pr.html",
	"title": "Test pull request",
	"tags": [],
	"description": "",
	"content": " Kick off a test pull request Check that all three integrations are working by kicking off a pull request. Go back to your fork of the TerraGoat repo and select \u0026ldquo;Add file\u0026rdquo; -\u0026gt; \u0026ldquo;Create new file.\u0026rdquo; Set the path to terraform/simple_instance/storage.tf. Add the following code:\nprovider \u0026#34;random\u0026#34; { } resource \u0026#34;random_string\u0026#34; \u0026#34;sa_name_affix\u0026#34; { length = 8 special = false upper = false } provider \u0026#34;azurerm\u0026#34; { features {} } resource \u0026#34;azurerm_resource_group\u0026#34; \u0026#34;trekgroup\u0026#34; { name = \u0026#34;trekgroup-resources\u0026#34; location = \u0026#34;West US\u0026#34; } resource \u0026#34;azurerm_storage_account\u0026#34; \u0026#34;storagebay\u0026#34; { name = \u0026#34;storagebay${random_string.sa_name_affix.result}\u0026#34; resource_group_name = azurerm_resource_group.trekgroup.name location = azurerm_resource_group.trekgroup.location account_tier = \u0026#34;Standard\u0026#34; account_replication_type = \u0026#34;GRS\u0026#34; } Select \u0026ldquo;Create a new branch\u0026rdquo; and \u0026ldquo;Propose new file.\u0026rdquo;\nThen \u0026ldquo;Create a pull request.\u0026rdquo; After a few seconds, you should automatically see Code Review Comments. Expand one to see the additional details like Fix recommendations. At the bottom, you should see five checks:\n The Checkov GitHub Action The Bridgecrew GitHub Action The Bridgecrew GitHub Application The Terraform Cloud integration checks (if you added that integration) Note that this one will fail the first time because we haven\u0026rsquo;t committed the directory yet  If you added the Yor GitHub Action, you will see that kick off and all of your resources will be tagged by Yor.\nYou can fix the violations later, but for now, click \u0026ldquo;Merge pull request\u0026rdquo; and \u0026ldquo;Confirm merge.\u0026rdquo;\nWith Terraform Cloud If you added the Terraform Cloud integration - Head back over to Terraform Cloud and select the latest run. You\u0026rsquo;ll again see the policy violations, but since we set the failure level to \u0026ldquo;advisory (logging only),\u0026rdquo; we can still apply the template.\nWe\u0026rsquo;re using a free resource (Storage Account), but remember to cleanup with terraform destroy at the end to avoid additional charges from Azure.\n Click \u0026ldquo;Confirm \u0026amp; Apply.\u0026rdquo; This will deploy the empty Storage Account. If you have the Yor GitHub Action, you may have to select that run as well and click \u0026ldquo;Confirm \u0026amp; Apply.\u0026rdquo;\nWithout Terraform Cloud Alternatively, locally you can run git pull origin master to update your local directory. Move to your simple_instance directory in your terminal (cd terraform/simple_instance from the terragoat directory). Then run terraform init to initialize your directory and terraform apply to create your Storage Account. Type yes and let Terraform provision your resources.\nCheck that the bucket is live Optionally, head over to your Azure console to confirm a bucket was created.\nCongratulations! You’ve now set up a GitHub Action, a GitHub Application, and either a Terraform Cloud integration or Yor to secure your Terraform templates.\nIn the next module, you’ll look at how to investigate and fix the issues arising from the automated scans, as well as providing more tips for integrating security into the developer workflow without causing friction.\n"
},
{
	"uri": "/terraform/40_module_two/2005_kickoff_pr.html",
	"title": "Test pull request",
	"tags": [],
	"description": "",
	"content": " Kick off a test pull request Check that all three integrations are working by kicking off a pull request. Go back to your fork of the TerraGoat repo and select \u0026ldquo;Add file\u0026rdquo; -\u0026gt; \u0026ldquo;Create new file.\u0026rdquo; Set the path to terraform/simple_instance/s3.tf. Add the following code:\nprovider \u0026#34;aws\u0026#34; { region = \u0026#34;us-west-2\u0026#34; } resource \u0026#34;aws_s3_bucket\u0026#34; \u0026#34;docking_bay\u0026#34; { bucket_prefix = \u0026#34;docking-bay-storage-\u0026#34; tags = { Name = \u0026#34;Docking Bay\u0026#34; Environment = \u0026#34;Dev\u0026#34; } } Select \u0026ldquo;Create a new branch\u0026rdquo; and \u0026ldquo;Propose new file.\u0026rdquo;\nThen \u0026ldquo;Create a pull request.\u0026rdquo; After a few seconds, you should automatically see Code Review Comments. Expand one to see the additional details like Fix recommendations. At the bottom, you should see five checks:\n The Checkov GitHub Action The Bridgecrew GitHub Action The Bridgecrew GitHub Application The Terraform Cloud integration checks (if you added that integration) Note that this one will fail the first time because we haven\u0026rsquo;t committed the directory yet  If you added the Yor GitHub Action, you will see that kick off and all of your resources will be tagged by Yor.\nYou can fix the violations later, but for now, click \u0026ldquo;Merge pull request\u0026rdquo; and \u0026ldquo;Confirm merge.\u0026rdquo;\nWith Terraform Cloud If you added the Terraform Cloud integration - Head back over to Terraform Cloud and select the latest run. You\u0026rsquo;ll again see the policy violations, but since we set the failure level to \u0026ldquo;advisory (logging only),\u0026rdquo; we can still apply the template.\nClick \u0026ldquo;Confirm \u0026amp; Apply.\u0026rdquo; This will deploy the simple S3 bucket. If you have the Yor GitHub Action, you may have to select that run as well and click \u0026ldquo;Confirm \u0026amp; Apply.\u0026rdquo;\nWithout Terraform Cloud Alternatively, locally you can run git pull origin master to update your local directory. Move to your simple_instance directory in your terminal (cd terraform/simple_instance from the terragoat directory). Then run terraform init to initialize your directory and terraform apply to create your S3 bucket. Type yes and let Terraform provision your resources.\nWe\u0026rsquo;re using a free tier resource (S3), but remember to cleanup with terraform destroy at the end to avoid additional charges from AWS.\n Check that the bucket is live Optionally, head over to your AWS console to confirm a bucket was created.\nCongratulations! You’ve now set up a GitHub Action, a GitHub Application, and either a Terraform Cloud integration or Yor to secure your Terraform templates.\nIn the next module, you’ll look at how to investigate and fix the issues arising from the automated scans, as well as providing more tips for integrating security into the developer workflow without causing friction.\n"
},
{
	"uri": "/aws/20_module_two/2006_automating_iac_github_actions.html",
	"title": "GitHub Actions",
	"tags": [],
	"description": "",
	"content": " Setting up GitHub Actions for our CloudFormation repository. If your existing CI/CD Pipeline runs in GitHub Actions, this can also be configured to scan the CloudFormation templates before deployment, allowing us to fail the build job and halt a deployment if there are any security violations in our CloudFormation code.\nAs with AWS CodeBuild, we’ll also automatically send the results to Brigecrew to maintain a view across all of our infrastructure projects and share visibility throughout our organization.\nGenerally speaking, you wouldn\u0026rsquo;t configure both CI/CD solutions for a single repository, consider this page informational only if you have followed through the AWS CodeBuild and AWS CodeDeploy sections, the observability provided into the Bridgecrew platform will be similar.\n As with other Integrations, the GitHub Actions CI/CD integration page at https://www.bridgecrew.cloud/integrations/githubActions allows us to setup GitHub Actions. Give the API key a name like gh_action and then click \u0026ldquo;Create\u0026rdquo; and \u0026ldquo;Next.\u0026rdquo;\nThe integration provides steps to enable GitHub actions, which we\u0026rsquo;ll walk through below.\nFirstly, just like we stored the Bridgecrew API secret in aws ssm put-parameter for CodeBuild, allowing the CI/CD run to securely access the secret, we do the same with GitHub Actions, by creating a GitHub secret, this prevents our API key being exposed in the configuration (which is stored in our codebase).\nGo to your fork of CFNGoat on GitHub, select Settings\nThen select Secrets from the left, and click New Repository Secret\nName the secret BC_API_KEY as instructed in the Bridgecrew integration details above.\nCopy and paste your API Token from the Bridgecrew integration details page into the value field.\nSelect Add secret, the secret will then be listed by name in the Settings \u0026gt; Secrets page you\u0026rsquo;ll be taken back to.\nAdding the automated workflow. Github Actions are defined as workflow files, within your code repository under the .github/workflows directory. To create an action, we\u0026rsquo;ll be adding a new file to this directory. If you already have workflows, and are familiar with the workflow file format, you could add the bridgecrew step section to your own workflows for the same results.\n To create a new workflow, select Actions within your CFNGoat forked repository, then select New Workflow button.\nSelect set up a workflow yourself to create a new, blank workflow.\nName the new file bridgecrew.yaml and replace the entire contents with the workflow template provided below, This takes the jobs section provided by the Bridgecrew integration instructions and wraps it in a fully functional GitHub Actions definition.\nname: Bridgecrew on: push: branches: - master jobs: scan: runs-on: ubuntu-latest strategy: matrix: python-version: [3.8] steps: - uses: actions/checkout@v2 - name: Run Bridgecrew id: Bridgecrew uses: bridgecrewio/bridgecrew-action@master with: api-key: ${{ secrets.BC_API_KEY }} The result should look like this, select Start commit\nFinally, save the new workflow file into your code repository by selecting Commit new file\nThe GitHub Action will immediatley start running the Bridgecrew CLI against the latest commit in your GFNGoat Repository.\nYou can see this by selecting the Actions page within your CFNGoat forked repository in GitHub.\nYou will see a new workflow, titled Bridgecrew and a job about to run automatically because of the new commit (of the workflow file)\nSelecting this job will allow you to view the status and logging output from the pipeline, where the Bridgecrew CLI will run and output any violations found in the CFNGoat codebase.\nRather than digging through the job logs, the action also outputs annotations for each violation found into the Summary page of the action.\nIf you want your GitHub Action to soft-fail and just act as an observability tool, add \u0026ldquo;soft_fail: true\u0026rdquo; under \u0026ldquo;api-key\u0026rdquo; in the YAML.\n Congratulations! You’ve just automated security scanning of your infrastructure as code into a developer-friendly CI/CD pipeline.\nIn the next module, we’ll look at how to investigate and fix the issues arising from the automated scans, as well as providing more tips for integrating security into the developer workflow without causing friction.\n"
},
{
	"uri": "/aws/30_module_three.html",
	"title": "Module - Fix",
	"tags": [],
	"description": "",
	"content": " As we’ve shown so far, Bridgecrew provides the policies and workflow to audit your CloudFormation templates before deployment, and optionally, to block vulnerabilities from making their way to your deployment pipeline.\nIn this module, we’ll head back to the Bridgecrew platform to show how easy it can be to improve your cloud security posture with easy-to-understand visualizations and automated remediations.\nModule Learning Objectives  Investigating security violations in Bridgecrew Integrating Bridgecrew with GitHub Automating pull requests with GitHub Scanning runtime resources for vulnerable infrastructure  "
},
{
	"uri": "/azure/50_module_three.html",
	"title": "Module - Fix",
	"tags": [],
	"description": "",
	"content": " MODULE - FIX We’ve covered scanning for misconfigurations during the development cycle and prior to committing to our repository. We can alert or block at each stage to provide that feedback early and make updates before the issues make it into production.\nIn this module, we’ll show how to visualize our posture and automate remediations. We teased this module in the VS Code section, where we performed our first fix, but in this section, we’ll fix the issues that make it into our repository and in production.\nModule Learning Objectives  Investigate security violations in Bridgecrew Automate pull requests in GitHub Scan runtime resources for vulnerable infrastructure Detect and mitigate drift  "
},
{
	"uri": "/terraform/50_module_three.html",
	"title": "Module - Fix",
	"tags": [],
	"description": "",
	"content": " MODULE - FIX We’ve covered scanning for misconfigurations during the development cycle and prior to committing to our repository. We can alert or block at each stage to provide that feedback early and make updates before the issues make it into production.\nIn this module, we’ll show how to visualize our posture and automate remediations. We teased this module in the VS Code section, where we performed our first fix, but in this section, we’ll fix the issues that make it into our repository and in production.\nModule Learning Objectives  Investigate security violations in Bridgecrew Automate pull requests in GitHub Scan runtime resources for vulnerable infrastructure Detect and mitigate drift  "
},
{
	"uri": "/aws/30_module_three/3001_bridgecrew_dashboard_results.html",
	"title": "Bridgecrew platform results",
	"tags": [],
	"description": "",
	"content": " Investigating security violations in Bridgecrew While the output from your CodeBuild run is very useful for quickly getting a sense of why your build failed, you may also want to visualize issues over time with a given repository or group objects affected by the same issue for clearer understanding.\nIf your developers don’t have direct access to the AWS account, the provided logs may be constrained.\nFor all those reasons and more, Bridgecrew provides reporting, monitoring, alerting, and visualizations for individual runs and across your entire infrastructure.\nHeading back to Bridgecrew, you’ll notice, our AWS CodeBuild integration has been added to the Integrations list showing that we’ve received data.\nNavigating to the Projects tab and select CFNGoat from the dropdown and you’ll see a list of all of the issues previously reported in the CodeBuild logs. If you select an item on the left-hand side, you’ll see all of the policy violations in our CFN repository.\nYou can also filter issues by status, category, severity, tags, has fix, by modifier.\nSelecting a specific resource, you will see metadata such as commit details and a historical timeline, which includes all actions and changes made to the resource. Bridgecrew also shows the code configuration and lines that need to be addressed:\nRefresh the dashboard to see updated historical trends and collated information from all of your monitoring sources:\nBridgecrew goes a step further, making it easy for teams to investigate issues and get visibility into their cloud security posture. Hit next to learn how to address issues fast with automated security-as-code fixes!\n"
},
{
	"uri": "/azure/50_module_three/3001_bridgecrew_dashboard_results.html",
	"title": "Bridgecrew platform results",
	"tags": [],
	"description": "",
	"content": " Investigating security violations in Bridgecrew Providing feedback in IDEs and CI/CD pipelines provides valuable insights into the posture of your code. Bridgecrew provides a centralized view for tracking misconfigurations across your code scans and runtime environments. We’ll start with the view across code scans.\nNavigate to the Projects tab in the Bridgecrew platform. Here you can see the results of your GitHub scan, as well as any other code scan that includes a repository ID and your Bridgecrew API.\nThis page comes packed with information and navigation tools for misconfigurations identified.\n Use the filters on the left to narrow down violations, or the top to narrow down to previous git modifiers. Search for code snippets or tags in the top. See dependent resources and audit histories on the right side.  Hit next to learn how to create a pull request with automatic fixes!\n"
},
{
	"uri": "/terraform/50_module_three/3001_bridgecrew_dashboard_results.html",
	"title": "Bridgecrew platform results",
	"tags": [],
	"description": "",
	"content": " Investigating security violations in Bridgecrew Providing feedback in IDEs and CI/CD pipelines provides valuable insights into the posture of your code. Bridgecrew provides a centralized view for tracking misconfigurations across your code scans and runtime environments. We’ll start with the view across code scans.\nNavigate to the Projects tab in the Bridgecrew platform. Here you can see the results of your GitHub scan, as well as any other code scan that includes a repository ID and your Bridgecrew API.\nThis page comes packed with information and navigation tools for misconfigurations identified.\n Use the filters on the left to narrow down violations, or the top to narrow down to previous git modifiers. Search for code snippets or tags in the top. See dependent resources and audit histories on the right side.  Hit next to learn how to create a pull request with automatic fixes!\n"
},
{
	"uri": "/aws/30_module_three/3002_bridgecrew_automate_integrate_github.html",
	"title": "GitHub integration",
	"tags": [],
	"description": "",
	"content": " Integrating Bridgecrew with GitHub By adding another Bridgecrew integration, you can generate and push automated pull requests (PRs) back into your GitHub repository to update your CloudFormation code and fix security issues, as well as gain automated scanning of incoming community pull requests with bot generated comments for misconfigurations.\nHead back to the Bridgecrew Integrations tab and select GitHub under the Code Repositories section. Click on the \u0026ldquo;GitHub organization\u0026rdquo; link to grant Bridgecrew access to your organization.\nJust like we did for the AWS CodePipeline GitHub authorization, choose which accounts and repositories to grant the Bridgecrew github integration access too.\nIn the next screen, select the relevant repos (make sure to select cfngoat) and click \u0026ldquo;Next\u0026rdquo; and \u0026ldquo;Done.\u0026rdquo; Once you’ve connected Bridgecrew to your CfnGoat demo repository, Bridgecrew will scan your CloudFormation code directly from GitHub again and bring the results into Bridgecrew.\nTo see all issues across your scanning sources— your bridgecrew-tutorial CodePipeline and your newly integrated GitHub repository—head over to the Projects page. You may need to change the drop down to cfngoat.\nYou will now see all of the violations across the repo. You can also switch the top drop down to your CodeBuild integration to see the same violations. Although this may seem redundant, it’s actually an important feature for tracking security posture at multiple steps in the DevOps lifecycle.\n"
},
{
	"uri": "/azure/50_module_three/3002_bridgecrew_pull_request_fix.html",
	"title": "Pull request fixes",
	"tags": [],
	"description": "",
	"content": " Automating fixes through pull requests Now that you’ve pulled in multiple infrastructure sources, you may get overwhelmed at the prospect of fixing the several dozen issues Bridgecrew has identified. To help us implement fixes as fast as possible, Bridgecrew generates and pushes fix pull requests back into your GitHub repository. These fixes are sourced from static recommendations and Smart Fixes that are fixes sourced from your own repositories based on other code that has passed those checks.\nLet’s walk through the process with one of the policies you looked at earlier, \u0026ldquo;Ensure secure transfer required is enabled.\u0026rdquo;\nThe lightbulb icon takes you to the Bridgecrew docs for more information about the violation. We can also suppress that check for this specific resource. Finally, in the middle is the Fix button. This enables you to automatically create a pull request with the diff shown. In this case, it will remove the acl with public-read access and force_destroy setting.\nThat\u0026rsquo;s a static fix. Next, look for the \u0026ldquo;Ensure Azure SQL server send alerts to field value is set\u0026rdquo; violation. There is no one right answer for every company for who should be the contact, but based on other code in my repo, securityengineer@bridgecrew.io is the input I\u0026rsquo;ve used every time in the past. That\u0026rsquo;s a lot easier than looking it up.\nYou can include other fixes, but for the sake of this workshop, we’ll just do the two. Select Submit.\nThat created a pull request, but you’ll need to approve the patch to make the changes in your repository. Over in your TerraGoat repository in GitHub, you’ll see a new PR under the “Pull requests” tab, which is ready for review:\nBecause of the scans from previous steps, the Merge button won’t be highlighted. Merge the patch anyway. You’ll receive a confirmation that the PR was merged and closed.\nMake sure to pull the origin locally to update your local copy of TerraGoat with the patch.\nCongratulations!\nYou’ve built an automated IaC scanning workflow in a live environment and automated the fixing of an IaC template!\n"
},
{
	"uri": "/terraform/50_module_three/3002_bridgecrew_pull_request_fix.html",
	"title": "Pull request fixes",
	"tags": [],
	"description": "",
	"content": " Automating fixes through pull requests Now that you’ve pulled in multiple infrastructure sources, you may get overwhelmed at the prospect of fixing the several dozen issues Bridgecrew has identified. To help us implement fixes as fast as possible, Bridgecrew generates and pushes fix pull requests back into your GitHub repository. These fixes are sourced from static recommendations and Smart Fixes that are fixes sourced from your own repositories based on other code that has passed those checks.\nLet’s walk through the process with one of the policies you looked at earlier, \u0026ldquo;Ensure bucket ACL does not grant READ permission to everyone\u0026rdquo;\nThe lightbulb icon takes you to the Bridgecrew docs for more information about the violation. We can also suppress that check for this specific resource. Finally, in the middle is the Fix button. This enables you to automatically create a pull request with the diff shown. In this case, it will remove the acl with public-read access and force_destroy setting.\nThat\u0026rsquo;s a static fix. Next, look for the \u0026ldquo;Ensure RDS instances have backup policy\u0026rdquo; violation. There is no one right answer for how long to keep backups, but based on other code in my repo, 15 days is the most common.\nYou can include other fixes, but for the sake of this workshop, we’ll just do the two. Select Submit.\nThat created a pull request, but you’ll need to approve the patch to make the changes in your repository. Over in your TerraGoat repository in GitHub, you’ll see a new PR under the “Pull requests” tab, which is ready for review:\nBecause of the scans from previous steps, the Merge button won’t be highlighted. Merge the patch anyway. You’ll receive a confirmation that the PR was merged and closed.\nMake sure to pull the origin locally to update your local copy of TerraGoat with the patch.\nCongratulations!\nYou’ve built an automated IaC scanning workflow in a live environment and automated the fixing of an IaC template!\n"
},
{
	"uri": "/terraform/50_module_three/3003_bridgecrew_automate_add_runtime.html",
	"title": "AWS runtime scanning",
	"tags": [],
	"description": "",
	"content": " Scanning runtime resources for vulnerable infrastructure Let’s switch gears to address infrastructure that wasn\u0026rsquo;t deployed by Terraform.\nGreenfield infrastructure as code deployments are a luxury not many of us have. In reality, our AWS accounts have objects that were created manually for one reason or another. Transitioning to IaC is rarely a one-and-done affair, so you may have objects in your AWS accounts that are managed by a team that has not yet made the switch.\nThat’s why it’s important to scan objects directly in your AWS environment in addition to scanning your Terraform templates in git or as part of the CI/CD pipeline, as we’ve already shown.\nBridgecrew provides runtime scanning via an AWS integration, allowing full coverage of infrastructure security both before and after deployment.\nAWS runtime integration To enable runtime scanning of your AWS account, go to the Integrations Tab and select \u0026ldquo;AWS\u0026rdquo; under the Cloud Providers section. Choose the AWS Read Access Stack and click \u0026ldquo;Next.\u0026rdquo;\nRead-only access is scoped as minimally as possible in order to give Bridgecrew only the necessary access to scan your AWS accounts.  Click \u0026ldquo;Launch Stack\u0026rdquo; to enable the integration.\nYou will be taken to your AWS account to spin up the CloudFormation stack to authorize the integration:\nCheck the checkbox to approve the IAM permission creations via our CloudFormation stack, and click Create Stack:\nYou can track the progress of the stack creation within your AWS account.\nOnce completed, you\u0026rsquo;ll see the integration in the Bridgecrew Integrations dashboard:\nThat’s all it takes to connect your AWS account to Bridgecrew for continuous cloud security monitoring and compliance benchmarking.\nExploring runtime violations With the AWS account connected, you\u0026rsquo;ll start to see runtime violations in the Incidents page.\nUnlike the rest of this workshop, the information displayed in your Bridgecrew Dashboard may differ from the images below, as no two AWS accounts will have the same content.  We can browse through all the security and compliance violations detected in our live AWS account. We can filter based on Status, Source, Category, Severity, Time Range, Benchmarks, and Tags. There are \u0026ldquo;low hanging fruit\u0026rdquo; filters for traced resource, unencrypted resources and publicly accessible resources.\nIn the example below, we can see a security group we deployed previously that opens port 22 to all traffic:\nFurther context on the issue and remediation options is also available by clicking on the lightbulb and on the \u0026ldquo;Guidelines\u0026rdquo; link.\nBridgecrew also alerts on account-wide settings such as user password policies and informational best practices, such as tagging each resource with ownership or purpose information or weak account password policies:\nIdentity and Access Management (IAM) Insights Bridgecrew also analyzes AWS IAM roles, permissions, groups, and policies to identify unused and overly-permissive configurations. You can use the filter pane to only show IAM specific issues.\nNext, we\u0026rsquo;ll look at Drift Detection.\n"
},
{
	"uri": "/azure/50_module_three/3003_bridgecrew_automate_add_runtime.html",
	"title": "Azure runtime scanning",
	"tags": [],
	"description": "",
	"content": " Scanning runtime resources for vulnerable infrastructure Let’s switch gears to address infrastructure that wasn\u0026rsquo;t deployed by Terraform.\nGreenfield infrastructure as code deployments are a luxury not many of us have. In reality, our Azure accounts have objects that were created manually for one reason or another. Transitioning to IaC is rarely a one-and-done affair, so you may have objects in your Azure accounts that are managed by a team that has not yet made the switch.\nThat’s why it’s important to scan objects directly in your Azure environment in addition to scanning your Terraform templates in git or as part of the CI/CD pipeline, as we’ve already shown.\nBridgecrew provides runtime scanning via an Azure integration, allowing full coverage of infrastructure security both before and after deployment.\nAzure runtime integration To enable runtime scanning of your Azure account, go to the Integrations Tab and select \u0026ldquo;Azure\u0026rdquo; under the Cloud Providers section. Make sure your computer meets the requirements and click \u0026ldquo;Next.\u0026rdquo;\nRead-only access is scoped as minimally as possible in order to give Bridgecrew only the necessary access to scan your Azure accounts.  Give your token a name like azure token, then click \u0026ldquo;Create.\u0026rdquo; We don\u0026rsquo;t need to save that key, so click \u0026ldquo;Next.\u0026rdquo;\nCopy that code to be added to an existing Terraform file or, in our case, a new one. In a new folder, add that code to a file called bc.tf with a blank azure provider block, so it will looke like this:\nprovider \u0026#34;azurerm\u0026#34; {  features {} }  module \u0026#34;bridgecrew-read\u0026#34; {  source = \u0026#34;bridgecrewio/bridgecrew-azure-read-only/azurerm\u0026#34;  org_name = \u0026#34;example\u0026#34;  bridgecrew_token = \u0026#34;27bd647e-ea89-47be-adea-EXAMPLE\u0026#34; } In your terminal, move to that directory and run terraform init. After initialized, run terraform apply.\nThat’s all it takes to connect your Azure account to Bridgecrew for continuous cloud security monitoring and compliance benchmarking.\nExploring runtime violations With the Azure account connected, you\u0026rsquo;ll start to see runtime violations in the Incidents page.\nUnlike the rest of this workshop, the information displayed in your Bridgecrew Dashboard may differ from the images below, as no two Azure accounts will have the same content.  We can browse through all the security and compliance violations detected in our live Azure account. We can filter based on Status, Source, Category, Severity, Time Range, Benchmarks, and Tags. We can leverage traced resources to tie cloud to code. There are \u0026ldquo;low hanging fruit\u0026rdquo; filters for unencrypted resources and publicly accessible resources.\nIn the example below, we can see a Storage Account that failed the \u0026ldquo;Ensure Azure Storage Account default network access is set to Deny\u0026rdquo; policy:\nFurther context on the issue and remediation options is also available by clicking on the lightbulb and on the \u0026ldquo;Guidelines\u0026rdquo; link.\nNext, we\u0026rsquo;ll look at Drift Detection.\n"
},
{
	"uri": "/aws/30_module_three/3003_bridgecrew_automate_pr_remediation.html",
	"title": "Pull request fixes",
	"tags": [],
	"description": "",
	"content": " Automating fixes through pull requests Now that you’ve pulled in multiple infrastructure sources, you might be getting overwhelmed at the prospect of fixing the several dozen issues Bridgecrew has identified. To help you implement fixes as fast as possible, Bridgecrew generates and pushes fix pull requests back into your GitHub repository.\nLet’s walk through the process with one of the policies we looked at earlier, Ensure S3 bucket has ‘restrict_public_bucket’ enabled:\nYou can see that this issue has a suggested fix available (green for new lines added). We can click on the lightbulb icon and follow the \u0026ldquo;View Guidelines\u0026rdquo; link to see the docs for that misconfiguration.\nLet\u0026rsquo;s open a pull request. Select the FIX button then Submit in the upper right corner.\nThe remediation modal shows there will be a pull request fix raised against your GitHub repository.\nAfter you select Submit, you’ll see a message confirming the pull request has been successfully raised with a link to the PR in GitHub. You’ll also see the remediation has had the effect of hiding the issue from the Projects list; other policy violations are listed, but the one we addressed is gone.\nYou’ll also notice, however, that the issue is still present from our CodePipeline source, so we’re not secure yet!\nOver in our CfnGoat repository in GitHub, we’ll see a new PR under the Pull requests tab, which is ready for review:\nDigging into the changed files, you’ll see the updated code that will soon be merged.\nBringing it all together. Merging our pull request in GitHub triggers our CI/CD deployment in AWS CodePipeline that we previously set up.\nYou may be able to tell where this is going!\nNotice our merged pull request commit has triggered the build:\nOf course, the scan will still fail as there are several other security issues affecting the CfnGoat repository, but if we head back to Bridgecrew, the issue we just fixed is gone:\nNow we know that the issue is not only fixed at source, but also that the fix has also made it through the CI/CD pipeline into production!\nCongratulations! You’ve built an automated IaC scanning workflow in a live environment and automated the fixing of an exposed S3 bucket!\n"
},
{
	"uri": "/aws/30_module_three/3004_bridgecrew_automate_add_runtime.html",
	"title": "AWS runtime scanning",
	"tags": [],
	"description": "",
	"content": " Scanning runtime resources for vulnerable infrastructure Last but definitely not least, let’s switch gears to address infrastructure that wasn\u0026rsquo;t deployed by CloudFormation.\nGreenfield infrastructure as code deployments are a luxury not many of us have. In reality, our AWS accounts have objects that were created manually for one reason or another. Transitioning to IaC is rarely a one-and-done affair, so you may have objects in your AWS accounts that are managed by a team that has not yet made the switch.\nThat’s why it’s important to scan objects directly in your AWS environment in addition to scanning your CloudFormation or Terraform manifests in git or as part of the CI/CD pipeline, as we’ve already shown.\nBridgecrew provides runtime scanning via an AWS integration, allowing full coverage of infrastructure security both before and after deployment.\nAWS Runtime Integration To enable runtime scanning of your AWS account, go to the Integrations Tab and select \u0026ldquo;AWS\u0026rdquo; under the Cloud Providers section. Choose the AWS Read Access Stack and click \u0026ldquo;Next.\u0026rdquo;\nRead-only access is scoped as minimally as possible in order to give Bridgecrew only the necessary access to scan your AWS accounts.  Click \u0026ldquo;Launch Stack\u0026rdquo; to enable the integration.\nYou will be taken to your AWS account to spin up the CloudFormation stack to authorize the integration:\nCheck the checkbox to approve the IAM permission creations via our CloudFormation stack, and click Create Stack:\nYou can track the progress of the stack creation within your AWS account.\nOnce completed, you\u0026rsquo;ll see the integration in the Bridgecrew Integrations dashboard:\nThat’s all it takes to connect your AWS account to Bridgecrew for continuous cloud security monitoring and compliance benchmarking.\nExploring runtime violations With the AWS account connected, you\u0026rsquo;ll start to see runtime violations in the Incidents page.\nUnlike the rest of this workshop, the information displayed in your Bridgecrew Dashboard may differ from the images below, as no two AWS accounts will have the same content.  We can browse through all the security and compliance violations detected in our live AWS account. We can filter based on Status, Source, Category, Severity, Time Range, Benchmarks, and Tags. There are \u0026ldquo;low hanging fruit\u0026rdquo; filters for traced resource, unencrypted resources and publicly accessible resources.\nIn the example below, we can see a security group we deployed previously that opens port 22 to all traffic:\nFurther context on the issue and remediation options is also available by clicking on the lightbulb and on the \u0026ldquo;Guidelines\u0026rdquo; link.\nBridgecrew also alerts on account-wide settings such as user password policies and informational best practices, such as tagging each resource with ownership or purpose information or weak account password policies:\nIdentity and Access Management (IAM) Insights Bridgecrew also analyzes AWS IAM roles, permissions, groups, and policies to identify unused and overly-permissive configurations. You can use the filter pane to only show IAM specific issues.\n"
},
{
	"uri": "/azure/50_module_three/3005_bridgecrew_drift_detections.html",
	"title": "Drift Detection",
	"tags": [],
	"description": "",
	"content": " Drift Detection between Azure and Terraform Cloud state using Bridgecrew In this final section, you’ll switch gears and detect drift. Drift occurs when the infrastructure deployed in the cloud is different from what was defined in the IaC template. You call what the infrastructure should be the “state” saved in files locally or in Terraform Cloud. For example, if the infrastructure in Azure may have different configurations than the Terraform template defined.\nThis usually occurs during a major incident, where DevOps and SRE teams make manual changes to quickly solve the problem, such as opening up ports to larger CIDR blocks or turning off HTTPS to find the problem, or if there are knowledge or access control gaps that make fixing an issue in the cloud directly the easier option. If these aren’t reverted, they present security issues and it weakens the benefits of using IaC.\nCreate drift Make sure you\u0026rsquo;ve applied the Terraform resources from the Test Pull Request section.\nConfirm in your Azure console that your new Storage Account is up. Go to the Storage Account console and confirm that there is a new Storage Account running.\nNext, let\u0026rsquo;s add a tag and increase the encryption requirement for the Storage Account. Select the Storage Account and go to \u0026ldquo;Tags.\u0026rdquo; Add a tag with the key drift and value spotted.\nThen, go down to \u0026ldquo;Configuration\u0026rdquo; under \u0026ldquo;Settings\u0026rdquo; and bump up the Minimum TLS version to Version 1.2 and click \u0026ldquo;Save.\u0026rdquo;\nBridgecrew scans your cloud configurations periodically, but to speed up the process, you can use the following API call in your terminal with your Bridgecrew API key from the earlier steps.\ncurl -X POST -H \u0026#34;Authorization: $YOUR_BC_API_KEY\u0026#34; https://www.bridgecrew.cloud/api/v1/scans/integrations That will force start a scan of your environment that will find misconfigurations and identify drift from your Terraform state. After a few moments, head back over to the Projects page of Bridgecrew. Select your repository (\u0026lt;organization\u0026gt;/terragoat) and filter by \u0026ldquo;Drift.\u0026rdquo; Here you can see the difference in Azure versus the state saved in Terraform Cloud or your VCS.\nYou found drift! From here, you can either run terraform apply to bring your cloud instances back in line with the state saved locally or in Terraform Cloud, or make the changes to your Terraform templates to match the changes made in production and update the state in Terraform Cloud. Alternatively, in the Projects page, you will find Fix Drift that will open a pull request on your behalf to make the change to match code to cloud.\n"
},
{
	"uri": "/terraform/50_module_three/3005_bridgecrew_drift_detections.html",
	"title": "Drift Detection",
	"tags": [],
	"description": "",
	"content": " Drift Detection between AWS and Terraform Cloud state using Bridgecrew In this final section, you’ll switch gears and detect drift. Drift occurs when the infrastructure deployed in the cloud is different from what was defined in the IaC template. You call what the infrastructure should be the “state” saved in files locally or in Terraform Cloud. For example, if the infrastructure in AWS may have different configurations than the Terraform template defined.\nThis usually occurs during a major incident, where DevOps and SRE teams make manual changes to quickly solve the problem, such as opening up ports to larger CIDR blocks or turning off HTTPS to find the problem, or if there are knowledge or access control gaps that make fixing an issue in the cloud directly the easier option. If these aren’t reverted, they present security issues and it weakens the benefits of using IaC.\nCreate drift Make sure you\u0026rsquo;ve applied the Terraform resources from the Test Pull Request section.\nConfirm in your AWS console that your new S3 bucket is up. Go to the S3 console and confirm that there is a new bucket running.\nNext, let\u0026rsquo;s add a tag and encryption to the S3 bucket. Select the bucket and go to \u0026ldquo;Properties.\u0026rdquo; Next to \u0026ldquo;Tags\u0026rdquo; click \u0026ldquo;Edit.\u0026rdquo; Add a tag with the key drift and value spotted.\nThen, next to \u0026ldquo;Default encryption click \u0026ldquo;Edit.\u0026rdquo; Select \u0026ldquo;Enable\u0026rdquo; and \u0026ldquo;Amazon S3 key,\u0026rdquo; then \u0026ldquo;Save changes.\u0026rdquo;\nBridgecrew scans your cloud configurations periodically, but to speed up the process, you can use the following API call in your terminal with your Bridgecrew API key from the earlier steps.\ncurl -X POST -H \u0026#34;Authorization: $YOUR_BC_API_KEY\u0026#34; https://www.bridgecrew.cloud/api/v1/scans/integrations That will force start a scan of your environment that will find misconfigurations and identify drift from your Terraform state. After a few moments, head back over to the Projects page of Bridgecrew. Select your repository (\u0026lt;organization\u0026gt;/terragoat) and filter by \u0026ldquo;Drift.\u0026rdquo; Here you can see the difference in AWS versus the state saved in Terraform Cloud or your VCS.\nYou found drift! From here, you can either run terraform apply to bring your cloud resources back in line with the state saved locally or in Terraform Cloud, or make the changes to your Terraform templates to match the changes made in production and update the state in Terraform Cloud. Alternatively, in the Projects page, you will find Fix Drift that will open a pull request on your behalf to make the change to match code to cloud.\n"
},
{
	"uri": "/aws/30_module_three/3005_bridgecrew_automate_fix_runtime.html",
	"title": "AWS fixes in runtime",
	"tags": [],
	"description": "",
	"content": " Automating fixes in runtime Similar to what we did with pull request fixes in the previous module, Bridgecrew allows for immediate remediation of issues in runtime by reconfiguring your objects via the AWS APIs.\nImplementing automated remediations does require extra permissions than previously granted with the default AWS Read Only integration. When you attempt a runtime remediation without the correct permissions, you’ll be prompted to configure the AWS Remediation Stack:\nAdding the AWS Remediation stack follows the same workflow as the previous read-only AWS integration. Go to the Integrations page and select \u0026ldquo;AWS\u0026rdquo;:\nSelect AWS Remediation Stack as the type. Then click Next and Launch Stack. Fixing an unencrypted S3 bucket Continuing with the example of the unencrypted S3 bucket from the previous page, the Fix button will now allow runtime changes to the S3 configuration:\nFor the sake of this workshop, we can use the AWS Console to confirm the selected bucket is currently unencrypted:\nBack in Bridgecrew, review the remediation, and select Fix a final time.\nBridgecrew will now use AWS API\u0026rsquo;s to ensure encryption is turned on for the selected resource:\nChecking the resource once more in the AWS Console, you will see that encryption is now enabled:\nThe violation will also have been marked resolved in the Bridgecrew Incidents page.\nCongratulations! You\u0026rsquo;ve integrated runtime security alerting and remediation into your DevSecOps automation!\n"
},
{
	"uri": "/aws/40_conclusion.html",
	"title": "Conclusion",
	"tags": [],
	"description": "",
	"content": " Conclusion In this workshop, you didn’t just learn how to automate security scanning—you learned how to bridge the gap between infrastructure development, DevOps, and cloud security. With these tools and processes at your disposal, you’re equipped to reduce risk by preventing cloud security errors as part of your development lifecycle. We also hope you’ve learned how important and easy it is to make security accessible to your engineering teams.\nFeel free to explore more of the Bridgecrew Dashboard, and try inviting more of your team to view and collaborate on the same security dashboard from the User Management page\nTo continue the conversation, you can find us @bridgecrewio on twitter, or say hi! in our #CodifiedSecurity slack channel, here!\nYou can also check out the Prisma Cloud DevDay to experience that platform in action.\n"
},
{
	"uri": "/azure/60_conclusion.html",
	"title": "Conclusion",
	"tags": [],
	"description": "",
	"content": " CONCLUSION In this workshop, we didn’t just learn how to identify and automate fixing misconfigurations — we learned how to bridge the gap between infrastructure development, DevOps, and cloud security. We are now equipped with full visibility, guardrails, and remediation capabilities across the development lifecycle. We also learned how important and easy it is to make security accessible to our engineering teams.\nTry more of the integrations with other popular developer and DevOps tools. Share what you’ve found with other members of your team and show how easy it is to incorporate this into their development processes. This will show how we can collaborate on the same security dashboard from the User Management page.\nIf you have any questions or thoughts, find us @bridgecrewio on Twitter, or say hi! in our #CodifiedSecurity Slack channel!\nYou can also check out the Prisma Cloud DevDay to experience the Prisma Cloud platform in action.\n"
},
{
	"uri": "/terraform/60_conclusion.html",
	"title": "Conclusion",
	"tags": [],
	"description": "",
	"content": " CONCLUSION In this workshop, we didn’t just learn how to identify and automate fixing misconfigurations — we learned how to bridge the gap between infrastructure development, DevOps, and cloud security. We are now equipped with full visibility, guardrails, and remediation capabilities across the development lifecycle. We also learned how important and easy it is to make security accessible to our engineering teams.\nTry more of the integrations with other popular developer and DevOps tools. Share what you’ve found with other members of your team and show how easy it is to incorporate this into their development processes. This will show how we can collaborate on the same security dashboard from the User Management page.\nIf you have any questions or thoughts, find us @bridgecrewio on Twitter, or say hi! in our #CodifiedSecurity Slack channel!\nYou can also check out the Prisma Cloud DevDay to experience that platform in action.\n"
},
{
	"uri": "/aws/100_cleanup.html",
	"title": "Cleanup",
	"tags": [],
	"description": "",
	"content": " AWS Cleanup In order to prevent charges to your account we recommend cleaning up the infrastructure that was created. If you plan to keep things running so you can examine the workshop a bit more please remember to do the cleanup when you are done. It is very easy to leave things running in an AWS account, forget about it, and then accrue charges. CodePipeline In the AWS console, go to AWS CodePipeline, and delete the scan-cfngoat-bridgecrew pipeline we created.\nCodeBuild AWS CodeBuild, and delete the bridgecrew-tutorial project we created.\nIAM Role Finally, remove the IAM role we created: - codebuild-bridgecrew-tutorial-service-role\nBridgecrew Cleanup The Bridgecrew account you created is free to use for up to 100 cloud resources, you can leave your AWS account integrated from the runtime section of this workshop to automatically detect infrastructure security issues in your account. The GitHub integration will also continue to scan pull requests to detect, annotate and prevent new infrastructure as code issues.\nYou may want to check out the following resources:\nIAM Insights: Automated right-sizing with policy-as-code Scanning AWS Cloud Development Kit (CDK) with Bridgecrew Bridgecrew Documentation\nThese integrations can be disabled from the Bridgecrew platform integrations page if need be.\n "
},
{
	"uri": "/azure/100_cleanup.html",
	"title": "Cleanup",
	"tags": [],
	"description": "",
	"content": " Azure Cleanup In order to prevent charges to your account we recommend cleaning up the infrastructure that was created. If you plan to keep things running so you can examine the workshop a bit more please remember to do the cleanup when you are done. It is very easy to leave things running in an Azure account, forget about it, and then accrue charges. Terraform If you deployed any infrastructure using the Terraform CLI, make sure to run terraform destroy. This includes both the example pull request template and the Bridgecrew Azure integration. If you deployed any infrastructure using Terraform Cloud, go into the workspace and select “Settings” -\u0026gt; “Destruction and Deletion” -\u0026gt; “Queue destroy plan”.\nBridgecrew Cleanup The Bridgecrew account you created is free to use for up to 50 cloud resources, you can leave your Azure account integrated from the runtime section of this workshop to automatically detect infrastructure security issues in your account. The GitHub integration will also continue to scan pull requests to detect, annotate and prevent new infrastructure as code issues.\nThese integrations can be disabled from the Bridgecrew platform integrations page if need be.\n"
},
{
	"uri": "/terraform/100_cleanup.html",
	"title": "Cleanup",
	"tags": [],
	"description": "",
	"content": " AWS Cleanup In order to prevent charges to your account we recommend cleaning up the infrastructure that was created. If you plan to keep things running so you can examine the workshop a bit more please remember to do the cleanup when you are done. It is very easy to leave things running in an AWS account, forget about it, and then accrue charges. Terraform If you deployed any infrastructure using the Terraform CLI, make sure to run terraform destroy. If you deployed any infrastructure using Terraform Cloud, go into the workspace and select “Settings” -\u0026gt; “Destruction and Deletion” -\u0026gt; “Queue destroy plan”.\nIAM Role Finally, remove the IAM role you created: - codebuild-bridgecrew-tutorial-service-role\nBridgecrew Cleanup The Bridgecrew account you created is free to use for up to 100 cloud resources, you can leave your AWS account integrated from the runtime section of this workshop to automatically detect infrastructure security issues in your account. The GitHub integration will also continue to scan pull requests to detect, annotate and prevent new infrastructure as code issues.\nThese integrations can be disabled from the Bridgecrew platform integrations page if need be.\n"
},
{
	"uri": "/categories.html",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags.html",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]