[
{
	"uri": "/aws.html",
	"title": "AWS Workshop",
	"tags": [],
	"description": "",
	"content": " Welcome! In this workshop, you’ll learn how to leverage infrastructure as code (IaC) and DevSecOps to automate your cloud security efforts. If you’re interested in making cloud security more efficient, proactive, and accessible to developers, this workshop is for you!\nUsing Bridgecrew, GitHub, AWS CodeBuild, and AWS CodePipeline, you’ll get hands-on experience implementing an automated CloudFormation security and compliance workflow.\nLearning Objectives  Overview of DevSecOps and CloudFormation infrastructure as code (IaC) Getting started with Bridgecrew to scan for CloudFormation misconfigurations Setting up your CI/CD pipeline to automate security scanning and policy enforcement Fixing IaC security errors and AWS resource misconfigurations with Bridgecrew  Before we dive in, let’s go through a refresher on the core concepts explored in this workshop.\n"
},
{
	"uri": "/",
	"title": "Cloud DevSecOps with Bridgecrew",
	"tags": [],
	"description": "",
	"content": "  a { color: inherit; text-decoration: none; } \nWelcome! \nAWS workshop Learn about securing CloudFormation templates from code to cloud using Bridgecrew\u0026rsquo;s integrations with VS Code, CodeBuild, CodePipeline, GitHub and AWS runtime\n    Terraform workshop Learn about securing Terraform templates from code to cloud using Bridgecrew\u0026rsquo;s integrations with VS Code, GitHub, Terraform Cloud, and AWS runtime\n     \n"
},
{
	"uri": "/terraform.html",
	"title": "Terraform Workshop",
	"tags": [],
	"description": "",
	"content": " Welcome! In this workshop, you’ll learn how to leverage infrastructure as code (IaC) and DevSecOps to automate, scale, and improve the security posture of your cloud infrastructure. We’ll create a pipeline that provides frequent, easy-to-digest improvements to ensure our configurations are secure and compliant from the build-time to runtime.\nUsing Bridgecrew, Checkov, VS Code, GitHub, Terraform Cloud, and AWS, we’ll get hands-on experience implementing an automated Terraform security and compliance workflow.\nLearning Objectives  Get an overview of DevSecOps and Terraform infrastructure as code (IaC) Scan IaC files for misconfigurations locally Set up CI/CD pipelines to automate security scanning and policy enforcement Fix IaC security errors and AWS resource misconfigurations with Bridgecrew  Let’s start with a few core concepts!\n"
},
{
	"uri": "/aws/5_getting_started.html",
	"title": "DevSecWhat?",
	"tags": [],
	"description": "",
	"content": " DevSecWhat? The foundation of DevSecOps lies in the DevOps movement, wherein development and operations functions have merged to make deployments faster, safer, and more repeatable. Common DevOps practices include automated infrastructure build pipelines (CI/CD) and version-controlled manifests (GitOps) to make it easier to control cloud deployments. By baking software and infrastructure quality requirements into the release lifecycle, teams save time manually reviewing code, allowing them to focus more on shipping features.\nAs deployments to production speed up, however, many traditional cloud security concepts break down. With the rise of containerized technologies, serverless functions, and IaC frameworks (which we’ll dig into in the next section), it’s harder to maintain cloud security posture visibility.\nBy leveraging DevOps foundations, security and development teams can build security scanning and policy enforcement into automated pipelines. The ultimate goal with DevSecOps is to “shift cloud security left.” That means automating it and embedding it earlier into the development lifecycle so that actions can be taken earlier. Preventing risky deployments is a more proactive approach to traditional cloud security that often slows down development teams with deployment rollbacks and disruptive fixes.\nFor DevSecOps to be successful for teams working to build and secure infrastructure, embracing existing tools and workflows is critical. At Bridgecrew, we’re committed to making it as simple, effective, and painless as possible to automate cloud security and integrate it seamlessly into release lifecycles.\nThe examples and sample code provided in this workshop are intended to be consumed as instructional content. These will help you understand how various Bridgecrew and AWS services can be architected to build a solution while demonstrating best practices along the way. These examples, especially the intentionally vulnerable \"CFNGoat\" repository, are not intended for use in production environments.  "
},
{
	"uri": "/terraform/00_getting_started.html",
	"title": "DevSecWhat?",
	"tags": [],
	"description": "",
	"content": "The foundation of DevSecOps lies in the DevOps movement, wherein development and operations functions are creating tighter coupling with more collaboration. DevOps tooling usually includes codifying every aspect of an application stack, version controlling all the code (GitOps), and automating the build and deployment process (CI/CD).\nDevSecOps is when we embed security into each of those steps.\nModern development processes have sped up the innovation process. Traditional security can’t keep pace with DevOps unless there are fundamental changes in security reviews. Security is still essential in agile development, and cloud security posture needs to be improved.\nThe solution is to “shift left” your cloud security efforts. That is to bring security in an automated, scalable way earlier in the development process—planning, development, and build-time. The result is higher patch rates with faster time-to-fix. With the “shift left” approach, development teams are happy because they’re making security fixes in their development cycle, and security teams are happy because security posture improves.\nWith cloud deployments, we have an opportunity to secure infrastructure from code to cloud. By securing infrastructure as code (IaC) templates at every stage of development, production infrastructure has the best possible chance to be secure and compliant. Bridgecrew is committed to making this as easy and seamless as possible with developer-friendly integrations and workflows.\nThe examples and sample code provided in this workshop are intended to be consumed as instructional content. These will help you understand how various services can be architected to build a solution while demonstrating best practices along the way. These examples, especially the intentionally vulnerable \"TerraGoat\" repository, are not intended for use in production environments.  "
},
{
	"uri": "/aws/5b_what_cloudformation.html",
	"title": "CloudFormation Overview",
	"tags": [],
	"description": "",
	"content": " How do CloudFormation and infrastructure as code work? Infrastructure as code (IaC) frameworks such as AWS CloudFormation, Terraform, and Pulumi make cloud provisioning simple and scalable by leveraging automation and code. Defining your cloud infrastructure in code simplifies repetitive DevOps tasks and gives you a single source of truth for your app and environment configuration.\nAWS CloudFormation enables you to define your AWS infrastructure with templates, which you can check into version control or store in S3 buckets. CloudFormation templates are JSON or YAML files. For instance, the following template defines an S3 bucket:\n{ \u0026#34;AWSTemplateFormatVersion\u0026#34; : \u0026#34;2010-09-09\u0026#34;, \u0026#34;Description\u0026#34; : \u0026#34;AWS CloudFormation Sample Template: Sample template showing how to create a publicly accessible S3 bucket.\u0026#34;, \u0026#34;Resources\u0026#34; : { \u0026#34;S3Bucket\u0026#34; : { \u0026#34;Type\u0026#34; : \u0026#34;AWS::S3::Bucket\u0026#34;, \u0026#34;Properties\u0026#34; : { \u0026#34;AccessControl\u0026#34; : \u0026#34;PublicRead\u0026#34;, \u0026#34;WebsiteConfiguration\u0026#34; : { \u0026#34;IndexDocument\u0026#34; : \u0026#34;index.html\u0026#34;, \u0026#34;ErrorDocument\u0026#34; : \u0026#34;error.html\u0026#34; } }, \u0026#34;DeletionPolicy\u0026#34; : \u0026#34;Retain\u0026#34; } }, \u0026#34;Outputs\u0026#34; : { \u0026#34;WebsiteURL\u0026#34; : { \u0026#34;Value\u0026#34; : { \u0026#34;Fn::GetAtt\u0026#34; : [ \u0026#34;S3Bucket\u0026#34;, \u0026#34;WebsiteURL\u0026#34; ] }, \u0026#34;Description\u0026#34; : \u0026#34;URL for website hosted on S3\u0026#34; }, \u0026#34;S3BucketSecureURL\u0026#34; : { \u0026#34;Value\u0026#34; : { \u0026#34;Fn::Join\u0026#34; : [ \u0026#34;\u0026#34;, [ \u0026#34;https://\u0026#34;, { \u0026#34;Fn::GetAtt\u0026#34; : [ \u0026#34;S3Bucket\u0026#34;, \u0026#34;DomainName\u0026#34; ] } ] ] }, \u0026#34;Description\u0026#34; : \u0026#34;Name of S3 bucket to hold website content\u0026#34; } } } Using the AWS CLI, you can provision the above bucket in seconds: (This is an example, not required for the workshop)\naws cloudformation create-stack --stack-name myexamplestack --template-body file:///home/example/mytemplate.json Security and CloudFormation IaC The benefit of using CloudFormation to define your AWS infrastructure is that it allows you to audit templates before they’re deployed. That will enable you to bake security best practices into your development and deployment lifecycle and finding potential security and compliance issues before the infrastructure becomes real.\nCloudFormation gives us total control to create, change, and delete resources in AWS. With CloudFormation, it’s easy to pick and deploy any of the hundreds of templates readily available from the AWS sample templates. Because these templates are built solely with functionality in mind, it’s also easy to forget important security configuration and end up having an insecure service running in production.\nThat’s why scanning your CloudFormation templates for vulnerable infrastructure before deployment is so important. With Bridgecrew, you can automate the scanning of your IaC codebase and cloud resources to both find and fix misconfigurations.\nIn this workshop, we’re doing exactly that. So let’s get started!\n"
},
{
	"uri": "/terraform/10_what_is_terraform.html",
	"title": "Infrastructure as Code using Terraform",
	"tags": [],
	"description": "",
	"content": " What is infrastructure as code anyway? Infrastructure as code (IaC) frameworks such as AWS CloudFormation, HashiCorp Terraform, and Pulumi make cloud provisioning scalable and straightforward by leveraging automation and code. Defining our cloud infrastructure in code simplifies repetitive DevOps tasks and gives us a versioned, auditable single source of truth for our environment configurations.\nHashiCorp Terraform is a multi-cloud IaC tool that allows us to define how we want our infrastructure to look, and it will generate all of the commands to make that happen. Any changes we want to make, such as adding more instances with the same configurations, Terraform will handle for us after we define the changes in our template.\nFor strictly demonstration purposes, the following Terraform resource block creates an S3 bucket without any CLI or GUI commands:\nresource \u0026#34;aws_s3_bucket\u0026#34; \u0026#34;data\u0026#34; { bucket = \u0026#34;my_bucket_name\u0026#34; acl = \u0026#34;public-read-write\u0026#34; } After performing terraform init, we can provision an S3 bucket with the following command:\nterraform apply Any changes we make to that file, such as adding tagging or changing the acl, will just require another terraform apply command to update our bucket.\nSecurity and Terraform Another benefit of using Terraform to define our infrastructure is that we can audit the code for misconfigurations before any infrastructure is created. That enables us to bake security into development processes and prevent infrastructure issues before they open an S3 bucket to the world.\nThat’s why we scan our Terraform templates for vulnerabilities before deployment. With Bridgecrew, we can automate this whole process, from finding the bugs to fixing them.\nIn this workshop, we’re doing exactly that. So let’s get started!\n"
},
{
	"uri": "/aws/6_prerequisites.html",
	"title": "Prerequisites",
	"tags": [],
	"description": "",
	"content": " Before we get started, make sure you have the following prerequisites. To get the most out of this tutorial, it will also be helpful to have a basic understanding of git, AWS core concepts (IAM, regions, UI, CLI, APIs), and CI/CD principles.\nGit git --version If you don’t have git installed, do so here.\nGitHub account If you don’t have a GitHub account, please sign up for one here.\nThe examples and sample code provided in this workshop are intended to be consumed as instructional content. These will help you understand how various Bridgecrew and AWS services can be architected to build a solution while demonstrating best practices along the way. These examples, especially the intentionally vulnerable \"CFNGoat\" repository, are not intended for use in production environments.  "
},
{
	"uri": "/terraform/20_prerequisites.html",
	"title": "Prerequisites",
	"tags": [],
	"description": "",
	"content": " Before you get started, make sure you have the following prerequisites. To get the most out of this tutorial, it will also be helpful to have a basic understanding of git, Terraform, AWS core concepts (IAM, regions, UI, CLI, APIs), and CI/CD principles.\nGit git --version If you don’t have git installed, do so here.\nGitHub account If you don’t have a GitHub account, please sign up for one here.\nVS Code If you don’t have Visual Studio Code installed, download and install it here.\n"
},
{
	"uri": "/terraform/20_prerequisites/2001_terraform_setup.html",
	"title": "Terraform Environment",
	"tags": [],
	"description": "",
	"content": " Terraform Environment Setup You’ll use the Terraform CLI locally as well as Terraform Cloud. If you don’t have the Terraform CLI installed on your computer, see the instructions here.\nTerraform Cloud (TFC) is a self-service SaaS platform that extends the capabilities of the open source Terraform CLI. It’s free for basic usage, but we’ll be leveraging advanced features, such as Sentinel, that will require a paid subscription or trial. Sign up for Terraform Cloud here and log in using your CLI.\nterraform login"
},
{
	"uri": "/aws/6_prerequisites/7_aws_setup.html",
	"title": "AWS Environment",
	"tags": [],
	"description": "",
	"content": " AWS Environment Setup To start the workshop, select one of the following, depending on whether you are\u0026hellip;\n \u0026hellip;running the workshop on your own AWS account, or \u0026hellip;attending an AWS hosted event  "
},
{
	"uri": "/terraform/20_prerequisites/2002_aws_setup.html",
	"title": "AWS Environment setup",
	"tags": [],
	"description": "",
	"content": " Disclaimer: We will be using an AWS account to show Bridgecrew’s runtime capabilities and drift detection. If you follow along, remember to shut down any AWS services to avoid additional fees.\n AWS Environment setup Your account must have the ability to create new IAM roles and scope other IAM permissions.\n  If you don\u0026rsquo;t already have an AWS account with Administrator access: create one now by clicking here\n Once you have an AWS account, ensure you are following the remaining workshop steps as an IAM user with administrator access to the AWS account: Create a new IAM user to use for the workshop\n Enter the user details:  Attach the AdministratorAccess IAM Policy:  Click to create the new user:  Take note of the login URL and save:   "
},
{
	"uri": "/terraform/20_prerequisites/2003_bc_setup.html",
	"title": "Bridgecrew setup",
	"tags": [],
	"description": "",
	"content": " You’ll need to sign up for a free Bridgecrew account to follow along with this tutorial. You can sign up for a free account here.\nCheckov In this tutorial, we’re also going to use Checkov. Checkov works on Windows, Mac, and Linux. You can install it with pip:\npip3 install checkov If installing globally on your system (not in a python venv or pipenv) you may need to have permissions to write the libraries to the necessary locations, ie:\nsudo pip3 install checkov If you run into problems, try the alternate install instructions.\nBridgecrew API token Throughout the tutorial, you’ll need to use the Bridgecrew API token. You can access it here or in your Bridgecrew account by navigating to the Integrations tab and selecting API Token.\n"
},
{
	"uri": "/aws/6_prerequisites/7_aws_setup/8_aws_eventengine.html",
	"title": "At an AWS Event",
	"tags": [],
	"description": "",
	"content": " Using AWS Event engine To complete this workshop, you are provided with an AWS account via the AWS Event Engine service. A 12-digit hash will be provided to you by event staff - this is your unique access code. eg:\ne8476543c00e Create AWS Account 1 . Connect to the portal by clicking the button or browsing to https://dashboard.eventengine.run/. The following screen shows up. Enter the provided hash in the text box. The button on the bottom right corner changes to Accept Terms \u0026amp; Login. Click on that button to continue.\n2 . Choose AWS Console, then Open AWS Console. This account will expire at the end of the workshop and the all the resources created will be automatically deprovisioned. You will not be able to access this account after today.\n3 . Use a single region for the duration of this workshop. This workshop supports the following regions:\n us-west-2 (US West - Oregon)  Please select US West (Oregon) in the top right corner.\n"
},
{
	"uri": "/aws/6_prerequisites/7_aws_setup/8_aws_eventengine/workspace.html",
	"title": "Create a workspace",
	"tags": [],
	"description": "",
	"content": " The Cloud9 workspace should be built by an IAM user with Administrator privileges, not the root account user. Please ensure you are logged in as an IAM user, not the root account user.\n This workshop was designed to run in the Oregon (us-west-2) region. Please don\u0026rsquo;t run in any other region. Future versions of this workshop will expand region availability, and this message will be removed.\n Ad blockers, javascript disablers, and tracking blockers should be disabled for the cloud9 domain, or connecting to the workspace might be impacted. Cloud9 requires third-party-cookies. You can whitelist the specific domains.\n Launch Cloud9: Create a Cloud9 Environment: https://us-west-2.console.aws.amazon.com/cloud9/home?region=us-west-2\nMake sure you are naming your Cloud9 environment Bridgecrew-Workshop, otherwise things will break later.\n  Select Create environment Name it Bridgecrew-Workshop and hit next. Select a t3 medium instance  Leave all the default selections.\n When it comes up, customize the environment by closing the welcome tab and lower work area, and opening a new terminal tab in the main work area:  Your workspace should now look like this:  If you like this theme, you can choose it yourself by selecting View / Themes / Solarized / Solarized Dark in the Cloud9 workspace menu.\n  "
},
{
	"uri": "/aws/6_prerequisites/7_aws_setup/9_own_account.html",
	"title": "Own AWS Account",
	"tags": [],
	"description": "",
	"content": " Using your own AWS Account Your account must have the ability to create new IAM roles and scope other IAM permissions.\n  If you don\u0026rsquo;t already have an AWS account with Administrator access: create one now by clicking here\n Once you have an AWS account, ensure you are following the remaining workshop steps as an IAM user with administrator access to the AWS account: Create a new IAM user to use for the workshop\n Enter the user details:  Attach the AdministratorAccess IAM Policy:  Click to create the new user:  Take note of the login URL and save:   "
},
{
	"uri": "/aws/6_prerequisites/7_aws_setup/9_own_account/workspace.html",
	"title": "Create a workspace",
	"tags": [],
	"description": "",
	"content": " The Cloud9 workspace should be built by an IAM user with Administrator privileges, not the root account user. Please ensure you are logged in as an IAM user, not the root account user.\n This workshop was designed to run in the Oregon (us-west-2) region. Please don\u0026rsquo;t run in any other region. Future versions of this workshop will expand region availability, and this message will be removed.\n Ad blockers, javascript disablers, and tracking blockers should be disabled for the cloud9 domain, or connecting to the workspace might be impacted. Cloud9 requires third-party-cookies. You can whitelist the specific domains.\n Launch Cloud9: Create a Cloud9 Environment: https://us-west-2.console.aws.amazon.com/cloud9/home?region=us-west-2\nMake sure you are naming your Cloud9 environment Bridgecrew-Workshop, otherwise things will break later.\n  Select Create environment Name it Bridgecrew-Workshop, and take all other defaults When it comes up, customize the environment by closing the welcome tab and lower work area, and opening a new terminal tab in the main work area:  Your workspace should now look like this:  If you like this theme, you can choose it yourself by selecting View / Themes / Solarized / Solarized Dark in the Cloud9 workspace menu.\n  "
},
{
	"uri": "/aws/6_prerequisites/601_setting_up_bridgecrew_account.html",
	"title": "Bridgecrew Setup",
	"tags": [],
	"description": "",
	"content": " You’ll need to sign up for a free Bridgecrew account to follow along with this tutorial. You can sign up for a free account here.\nBridgecrew CLI In this tutorial, we’re also going to use Bridgecrew CLI. The CLI works on Windows, Mac, and Linux. You can install it with pip:\npip3 install bridgecrew If installing globally on your system (not in a python venv or pipenv) you may need to have permissions to write the libraries to the necessary locations, ie:\nsudo pip3 install bridgecrew If you run into problems, try the alternate install instructions.\nBridgecrew API token Throughout the tutorial, you’ll need to use the Bridgecrew API token. You can access it here or in your Bridgecrew account by navigating to the Integrations tab and selecting API Token.\n"
},
{
	"uri": "/aws/6_prerequisites/7_aws_setup/8_aws_eventengine/setup_short.html",
	"title": "Quick Setup",
	"tags": [],
	"description": "",
	"content": " We are going to install jq and initilize a python enviroment. Cloud9 already has the latest version of Python installed.\n Install jq - jq is a command-line tool for parsing JSON.\nsudo yum install jq Start a python enviroment\npython3 -m venv env source ./env/bin/activate "
},
{
	"uri": "/aws/10_module_one.html",
	"title": "Module - Scan",
	"tags": [],
	"description": "",
	"content": " In this module, we’ll identify common misconfigurations and security best practices in AWS CloudFormation.\nModule Learning Objectives  Creating a demo CloudFormation repository using GitHub by cloning CfnGoat Scan a CloudFormation template for misconfigurations locally Investigate security and compliance errors using Bridgecrew  "
},
{
	"uri": "/terraform/30_module_one.html",
	"title": "Module - Scan",
	"tags": [],
	"description": "",
	"content": " MODULE - SCAN In this module, we’ll identify common misconfigurations and security best practices in Terraform.\nModule Learning Objectives  Create a demo environment using our vulnerable-by-design TerraGoat project Scan a Terraform template and directory for misconfigurations using two methods Investigate policy violations in the Bridgecrew platform  "
},
{
	"uri": "/aws/10_module_one/1001_cfngoat.html",
	"title": "CfnGoat",
	"tags": [],
	"description": "",
	"content": " Vulnerable-by-design demo repository setup This workshop uses our vulnerable-by-design CloudFormation project, CfnGoat, so that you can scan and automate infrastructure code without the added friction of integrating your own code. Simply clone the open-source project’s repository:\ngit clone https://github.com/bridgecrewio/cfngoat.git cd cfngoat git status Sample output:\n$ git clone https://github.com/bridgecrewio/cfngoat.git cd cfngoat git status Cloning into \u0026#39;cfngoat\u0026#39;... remote: Enumerating objects: 64, done. remote: Counting objects: 100% (64/64), done. remote: Compressing objects: 100% (54/54), done. remote: Total 64 (delta 18), reused 33 (delta 7), pack-reused 0 Unpacking objects: 100% (64/64), 73.62 KiB | 718.00 KiB/s, done. On branch master Your branch is up to date with \u0026#39;origin/master\u0026#39;. nothing to commit, working tree clean ➜ cfngoat git:(master)"
},
{
	"uri": "/terraform/30_module_one/1001_terragoat.html",
	"title": "TerraGoat",
	"tags": [],
	"description": "",
	"content": " Vulnerable-by-design demo repository setup This workshop uses our vulnerable-by-design Terraform project, TerraGoat, so that you can scan and automate infrastructure code without the added friction of integrating your own code. Simply clone the open-source project’s repository:\ngit clone https://github.com/bridgecrewio/terragoat.git cd terragoat git status Sample output:\n$ git clone https://github.com/bridgecrewio/terragoat.git cd terragoat git status Cloning into \u0026#39;terragoat\u0026#39;... remote: Enumerating objects: 10, done. remote: Counting objects: 100% (10/10), done. remote: Compressing objects: 100% (10/10), done. remote: Total 581 (delta 2), reused 0 (delta 0), pack-reused 571 Receiving objects: 100% (581/581), 221.43 KiB | 4.26 MiB/s, done. Resolving deltas: 100% (269/269), done. On branch master Your branch is up to date with \u0026#39;origin/master\u0026#39;. nothing to commit, working tree clean"
},
{
	"uri": "/aws/10_module_one/1002_local_scan_cli.html",
	"title": "Bridgecrew CLI",
	"tags": [],
	"description": "",
	"content": " Run Bridgecrew CLI locally To demonstrate what kinds of security and compliance errors Bridgecrew can identify in CloudFormation templates, we’ll start by using Bridgecrew CLI and send the results to the Bridgecrew platform.\nMake sure you are in the cfngoat directory from the previous step, copy your unique Bridgecrew API token, and scan the cfngoat.yaml file:\nbridgecrew -f cfngoat.yaml --bc-api-key $YOUR_BC_API_KEY --repo bridgecrewio/cfngoat You can also scan entire directories with -d \u0026lt;path\u0026gt;:\nbridgecrew -d . --framework cloudformation --bc-api-key $YOUR_BC_API_KEY --repo bridgecrewio/cfngoat You can use the bridgecrew CLI without --bc-api-key, the results will still display locally, without uploading to the bridgecrew cloud, for testing or local-only scan results.  The results will show all the failed checks and link to a guide explaining the cause and how to fix them. Note the output also includes the filename and snippet of code that is misconfigured:\nAs you can see in the highlighted CLI output above, our demo CloudFormation repository has failing checks for two policies: - Ensure S3 bucket has ignore public ACLs enabled - Ensure S3 bucket has ‘restrict_public_bucket’ enabled\nTo get the list of policies that Bridgecrew checks for, use -l or –list:\nbridgecrew --list Bridgecrew policies In many instances, when testing locally with the Bridgecrew CLI, you may only be interested in running just a few checks. In that case, you can add the -c or --check option:\nbridgecrew -f cfngoat.yaml -c CKV_AWS_55,CKV_AWS_56 Alternatively, if you want to run all but a few checks, use the --skip-check option:\nbridgecrew -f cfngoat.yaml --skip-check CKV_AWS_55,CKV_AWS_56  Next, let’s inspect these results in the Bridgecrew dashboard.\n"
},
{
	"uri": "/terraform/30_module_one/1002_local_scan_cli.html",
	"title": "Checkov",
	"tags": [],
	"description": "",
	"content": " If you are running Checkov with the Bridgecrew API token and you use a proxy, you may need to turn off your VPN/proxy or use the --ca-certificate flag to allow your proxy\u0026rsquo;s certificate using the directions here: https://github.com/bridgecrewio/checkov/pull/1099. If you run Checkov without the Bridgecrew API token, this won\u0026rsquo;t be an issue.\n Run Checkov locally To demonstrate what kinds of security and compliance errors Bridgecrew can identify in Terraform templates, start by using Checkov and send the results to the Bridgecrew platform.\nMake sure you are in the cloned directory from the previous step, copy your unique Bridgecrew API token, and scan the s3.tf in the aws directory:\ncd terragoat checkov -f terraform/aws/s3.tf --bc-api-key $YOUR_BC_API_KEY --repo-id bridgecrewio/s3 You can also scan entire directories with -d , such as the aws directory:\ncheckov -d terraform/aws/ --bc-api-key $YOUR_BC_API_KEY --repo-id bridgecrewio/awsterragoat You can use Checkov without --bc-api-key to display the results in the command line without uploading to the Bridgecrew platform for testing or local-only scan results.\nThe results will show all the failed policies and link to guides explaining the rationale behind each misconfiguration and steps to fix them. Note the output also includes the filename and snippet of code that is misconfigured:\nIn the example output above, you can see that Bridgecrew identified two failing policies: “Ensure EKS Cluster has Secrets Encryption Enabled” and “Ensure Amazon EKS public endpoint not accessible to 0.0.0.0/0”.\nTo get the list of policies that Checkov checks for, use -l or --list:\ncheckov --list Checkov policies In many instances, when testing locally with the Checkov, you may only be interested in running just a few policies. In that case, you can add the -c or --check option:\ncheckov -f terraform/aws/s3.tf -c CKV_AWS_18,CKV_AWS_52 Alternatively, if you want to run all but a few policies, use the --skip-check option:\ncheckov -f terraform/aws/s3.tf --skip-check CKV_AWS_18,CKV_AWS_52"
},
{
	"uri": "/terraform/30_module_one/1003_local_scan_dashboard.html",
	"title": "Bridgecrew Dashboard",
	"tags": [],
	"description": "",
	"content": " Viewing results in Bridgecrew You just scanned your Terraform templates locally using Checkov. If you included your API key, the results were sent to the Bridgecrew platform for further investigation. You may have noticed the URL at the end of the CLI scan. That’s a direct link to the results in Bridgecrew.\nClick on that link to bring up that scan’s Code Review page. This is a list of all of the misconfigurations identified from that scan grouped by resource and labeled by severity.\nIn a later section, we’ll review the Projects page, which is an aggregated view of the different Code Reviews across all scan types.\n"
},
{
	"uri": "/aws/10_module_one/1003_vscode.html",
	"title": "VSCode Plugin",
	"tags": [],
	"description": "",
	"content": " Visual Studio Code extension The Bridgecrew CLI can be used for a quick local scan, but is better suited when automated into a CI/CD pipeline, which we\u0026rsquo;ll dive into in Module Two.\nFor more developer-friendly local scanning, Bridgecrew\u0026rsquo;s Checkov VS Code extension shows scan results directly at the point of code, without having to constantly re-run the CLI tool. Results and suggested fixes are annotated directly onto the specific code block causing the violation in real-time.\nYou can find the plugin here.\n"
},
{
	"uri": "/aws/10_module_one/1004_local_scan_dashboard.html",
	"title": "Bridgecrew Dashboard",
	"tags": [],
	"description": "",
	"content": " Viewing results in Bridgecrew In the previous section, we scanned our demo CloudFormation repository locally with both standalone CLI and the Checkob VSCode plugin, and sent the results to the Bridgecrew platform for investigation and remediation.\nTo explore the reported issues we saw in the CLI output, head to the Incidents tab in your Bridgecrew account.\nBridgecrew comes with hundreds of out-of-the-box policies to help you adhere to cloud security best practices as defined by the Center of Internet Security (CIS). Bridgecrew policies also correspond to popular compliance frameworks such as PCI-DSS V3.2, NIST-800-53, SOC2, and more.\nClicking into one of the violations will show all the violating resources found in our vulnerable-by-design CfnGoat codebase.\nFor example\u0026hellip;\nFrom here, we can drill down into a specific CloudFormation object to see the relevant piece of code along with a suggestion for fixing the error. We’ll cover how to implement remediations in more depth a little later!\nNow that we have a feel for the kinds of IaC security issues Bridgecrew is equipped to find, let\u0026rsquo;s add some DevSecOps magic.\n"
},
{
	"uri": "/terraform/30_module_one/1004_vs_code.html",
	"title": "VS Code Plugin",
	"tags": [],
	"description": "",
	"content": " Run Checkov in your IDE You can get feedback directly in your integrated development environment (IDE) using Bridgecrew’s Checkov Visual Studio Code extension. The tool highlights misconfigurations inline and in development environments—like spell check for IaC misconfigurations.\nFirst, you need to install the extension. In VS Code, go to Extensions and search for Checkov. Click Install.\nNext, go to the Checkov Extension Settings and paste the API Token from the Bridgecrew platform that we saved earlier.\nScan your S3 bucket template using the extension. Go to File -\u0026gt; Add Folder to Workspace and navigate to the cloned TerraGoat directory. Add /terraform/aws to your VS Code workspace and open s3.tf.\nCheckov will immediately start scanning and will highlight any identified misconfigurations, with red underline. Move your cursor over the first code block resource \u0026quot;aws_s3_bucket\u0026quot; \u0026quot;data\u0026quot;. Checkov has identified multiple misconfigurations, including “Ensure all data stored in the S3 bucket have versioning enabled Checkov CKV_AWS_21.\u0026rdquo;\nYou can learn more about the policy by selecting “View Problem” or select “Quick Fix” to do exactly that. By selecting “Apply fix for - Ensure all data stored in the S3 bucket have versioning enabled” you automatically patched your codebase for a common misconfiguration.\nNow you can commit that code to your repository with the patch and improved posture.\nNow that we know what Bridgecrew is scanning for and what the results look like, let’s automate it!\n"
},
{
	"uri": "/aws/20_module_two.html",
	"title": "Module - Automate",
	"tags": [],
	"description": "",
	"content": " MODULE - AUTOMATE In the previous section, we used the Bridgecrew CLI to do some quick scanning before committing a change into the code repository. That’s great for checking work here and there but forcing every developer to run a scan on their machines before every single commit isn’t reasonable or feasible. To continuously audit code, automation and built-in workflows are key. With Bridgecrew, you can automate your infrastructure scanning along with the rest of your unit and integration testing by embedding it into your version control system and CI/CD pipeline.\nThis module will show you how to prevent cloud security issues from being deployed by integrating Bridgecrew with both the AWS developer tools suite, and GitHub Actions.\nModule Learning Objectives  Creating your own CloudFormation demo repository on GitHub Setting up AWS CodeBuild Setting up AWS CodePipeline Adding Bridgecrew scanning of CloudFormation manifests into CodeBuild Adding Bridgecrew scanning of CloudFormation manifests with GitHub Actions  "
},
{
	"uri": "/terraform/40_module_two.html",
	"title": "Module - Automate",
	"tags": [],
	"description": "",
	"content": " MODULE - AUTOMATE In the previous section, we used Checkov and VS Code extension to scan our Terraform templates locally. However, we can’t expect consistency if the process is one-off. We need to continuously scan the code for misconfigurations before it makes its way into production.\nThat’s where automating IaC scanning in our continuous integration/continuous delivery (CI/CD) pipeline comes in. With Bridgecrew, we can scan templates before they are committed to our VCS when you run other unit and integration testing, or in your VCS. This allows you to provide automated feedback as a part of a CI run and, if in blocking mode, block misconfigured code.\nIn this module, we’ll add in automated scans using GitHub Actions and with Terraform Cloud.\nModule Learning Objectives  Set up the Bridgecrew GitHub Action Set up the Bridgrew GitHub Application Set up the Bridgecrew and Terraform Cloud integration Run a scan  "
},
{
	"uri": "/aws/20_module_two/2001_automating_iac_github.html",
	"title": "CloudFormation repository setup",
	"tags": [],
	"description": "",
	"content": " Creating your own CfnGoat repository on GitHub To set up our continuous workflow and demonstrate the value of getting automated infrastructure security scanning, we need a hosted source repository. You can either push your local demo repository to GitHub or, since CfnGoat is already hosted on GitHub, we recommend you fork the repository to your own GitHub account.\nHead to your GitHub account, visit the CfnGoat repository at https://github.com/bridgecrewio/cfngoat, and select Fork in the top right-hand corner:\nIf you have multiple organizations, GitHub will ask which of your orgs to fork into. Choose your personal account via your username in the list to fork the repo.\nYou’ll then be redirected to your newly forked repository—notice your username at the top of the page:\nNow we’re ready to make changes and integrate our automated pipeline!\n"
},
{
	"uri": "/terraform/40_module_two/2001_automating_iac_github.html",
	"title": "Fork TerraGoat",
	"tags": [],
	"description": "",
	"content": " Fork the TerraGoat repository on GitHub To set up your demo environment, you can push your local clone of TerraGoat or fork the repository. We’re doing the second option.\nHead over to the TerraGoat repository and fork it using the button in the upper right corner.\nIf you have multiple organizations, GitHub will ask which of your orgs to fork into. Choose your personal account via your username in the list to fork the repo.\nTime to integrate an automatic scan in our CI/CD pipeline!\n"
},
{
	"uri": "/aws/20_module_two/2002_automating_iac_codebuild.html",
	"title": "AWS CodeBuild setup",
	"tags": [],
	"description": "",
	"content": " Setting up AWS CodeBuild for our CloudFormation repository. AWS CodeBuild paired with AWS CodePipeline is a CI/CD platform that can build projects, run jobs, and deploy infrastructure. We’re going to use it to scan the CloudFormation templates before deployment, allowing us to fail the build job and halt a deployment if there are any security violations in our CloudFormation code.\nWe’ll also automatically send the results to Brigecrew to maintain a view across all of our infrastructure projects and share visibility throughout our organization.\nFirst, tell the Bridgecrew dashboard you’re going to integrate AWS CodeBuild. To do this, open the integrations menu in your Bridgecrew account and select AWS CodeBuild, then Add Subscription.\nRun the command provided by Bridgecrew with your local aws CLI. This will save the Bridgecrew API key into your AWS System Manager’s parameter store so we can access it from our CodeBuild jobs later.\nNext, copy the buildspec.yaml configuration to keep handy (or keep this Bridgecrew tab open).\nIf the aws command fails, your IAM user may not have the correct permissions to create parameters in AWS Systems Manager (SSM). In that case, you’ll need to add write permissions to the user.  New Codebuild Project Now go to your AWS CodeBuild service select Create a Build Project and name your project bridgecrew-tutorial.\nUnder the Source section, choose GitHub in the Source Provider dropdown and select Connect using OAuth. When you select Connect to GitHub, you’ll be prompted to authorize your GitHub account:\nNow the Source section will have changed, allowing us to search for and select our CfnGoat repository from GitHub:\nConfigure your Environment setup to mirror the image below:\nAdding our Buildspec To complete our build setup, we need to add the build commands. Select Insert build commands, and use the editor to overwrite the contents with the YAML code you copied from Bridgecrew earlier.\nSelect Create build project to finalize our CodeBuild project setup!\n"
},
{
	"uri": "/terraform/40_module_two/2002_automating_iac_github_action.html",
	"title": "GitHub Action",
	"tags": [],
	"description": "",
	"content": " Setting up the Bridgecrew GitHub Action You can leverage GitHub actions to run automated scans for every build or specific builds, such as the ones that merge into the master branch. This action can alert on misconfigurations, or you can set it up to block code from being merged if certain policies are violated. It can also send the results to Bridgecrew for further review and remediation steps.\nThe TerraGoat repository already has a Checkov Action built in at terragoat/.github/workflows/pull_request.yaml and terragoat/.github/workflows/checkov.yaml. You can remove those files to remove that redundant scan, but we will keep it for this workshop. Typically, you wouldn’t do more than one scan during a build, such as two Actions, a CI/CD integration and a Terraform Cloud scan, so you can remove the Actions when you set up the Terraform Cloud scan or leave it for illustrative purposes.  Start with the GitHub Actions integration page within the Bridgecrew platform and select “Add Subscription.”\nThe integration provides steps to enable GitHub actions, which you’ll walk through below.\nYou need to add that key to GitHub in their secrets store as an environment variable. This prevents your API key from being public when you have your code in a public repository.\nGo to your fork of TerraGoat on GitHub and select “Settings”.\nThen select “Secrets” from the left, and click “New Repository Secret”.\nName the secret BRIDGECREW_API_KEY as instructed in the Bridgecrew integration details above.\nCopy and paste your API Token from the Bridgecrew integration details page into the value field.\nSelecting “Add secret” will list the secret in the “Settings” -\u0026gt; “Secrets” page.\nAdding the automated workflow Github Actions are defined as workflow files within your code repository under the .github/workflows directory. To create an action, you’ll add a new file to this directory. If you already have workflows and are familiar with the workflow file format, you could add the Bridgecrew step section to your own workflows for the same results.\nTo create a new workflow, select “Actions” within your TerraGoat forked repository, then select “New Workflow.”\nSelect “Set up a workflow yourself” to create a new, blank workflow.\nName the new file bridgecrew.yaml and replace the entire contents with the workflow template provided below. This takes the jobs section provided by the Bridgecrew integration instructions and wraps it in a fully functional GitHub Actions definition.\nname: Bridgecrew on: push: branches: - master jobs: scan: runs-on: ubuntu-latest strategy: matrix: python-version: [3.8] steps: - uses: actions/checkout@v2 - name: Run Bridgecrew id: Bridgecrew uses: bridgecrewio/bridgecrew-action@master with: api-key: ${{ secrets.BRIDGECREW_API_KEY }} directory: terraform/ Select “Start commit” once you’ve added the workflow file contents:\nFinally, save the new workflow file into your code repository by selecting “Commit new file”.\nThe GitHub Action will start running Bridgecrew scans against the latest commit in your TerraGoat repository. You can see this by selecting the “Actions” page within your TerraGoat forked repository in GitHub. You will see a new workflow, titled Bridgecrew, and that the job that was kicked off by merging in the workflow yaml file.\nSelecting this job will allow you to view the status and logging output from the pipeline, where checkov will run and output any violations found in the TerraGoat codebase.\nRather than digging through the job logs, the action also outputs annotations for each violation found into the “Summary” page of the action. Again, we can see the identified misconfigurations:\nThe Bridgecrew GitHub Action can either pass all builds or block builds based on policy violations. The first acts as just an observability and alerting tool, the second as guardrails for developers to prevent misconfigured templates from making it into the repository. You can change the soft_fail setting to block builds in the bridgecrew.yaml file.\n"
},
{
	"uri": "/aws/20_module_two/2003_automating_iac_codebuild_iam.html",
	"title": "Edit IAM for CodeBuild",
	"tags": [],
	"description": "",
	"content": " Edit AWS IAM permissions to enable CodeBuild To give CodeBuild access to our Bridgecrew API secret we stored in AWS System Manager, we’ll need to add more permissions to the default IAM role created for new CodeBuild environments.\nIn the AWS IAM Dashboard, find the role called codebuild-bridgecrew-tutorial-service-role\nSelect the role, then click select Add Inline Policy from the right hand side.\nThis will bring up the \u0026ldquo;create policy visual editor\u0026rdquo;, for Service, select Systems Manager in the search box, then chose the GetParameters and GetParameter Actions.\nUnder Resources, choose Specific and select Add ARN. Fill in the same region you’ve created your CodeBuild project and leave the account number as the default. Type bridgecrew_api_key as the parameter name to match the name we gave the key in the aws CLI command we used earlier.\nYou could also use the cli command aws ssm get-parameter --name bridgecrew_api_key to get the whole ARN and paste it into the ARN field. Select Add then select Review Policy.\nOn the next page, name the policy allow_codebuild_access_to_bridgecrew_secret and select Create policy:\nWe’re now ready to tie this all together with AWS CodePipeline!\n"
},
{
	"uri": "/terraform/40_module_two/2003_automating_iac_terraform_cloud.html",
	"title": "Terraform Cloud",
	"tags": [],
	"description": "",
	"content": " A new, native integration between Bridgecrew and Terraform Cloud is coming soon! Check out the HashiCorp keynote for a preview: https://youtu.be/ZzLZaWUve4M?t=1387  Leveraging Terraform Cloud and Sentinel for Bridgecrew scans Bridgecrew has a native integration with Terraform Cloud that leverages Sentinel for policy controls. This means any commit that is pushed to Terraform Cloud will run through a Bridgecrew scan, identifying policy violations, blocking misconfigured builds, and detecting drift, all from the same place that you collaborate on Terraform templates, automate deployments, and store state.\nSentinel is a paid add-on. If you want to try this out for free, HashiCorp does offer a free trial. If you prefer not to sign up for the trial, feel free to skip this section and the \u0026ldquo;drift detection\u0026rdquo; section.\n To sign up for the free trial of Terraform Cloud’s Team \u0026amp; Governance plan, go to your Terraform Cloud instance. Select “Settings” and “Plan \u0026amp; Billing.” Choose the Trial option. You should see Policies and Policy Sets show up in the left navigation menu.\nYou need to add your TerraGoat repository to Terraform Cloud. Go to “Workspaces” and select “Create one now.”\nSelect “Version control workflow”:\nSelect “GitHub” and choose your TerraGoat repository we previously forked:\nName the workspace terragoat and open the “Advanced options” and add the directory /terraform/simple_instance/ (we\u0026rsquo;ll be adding that directory later). This will focus the scans to just the aws templates. Turn on \u0026ldquo;Automatic speculative plans\u0026rdquo; to create plans for pull requests. Select “Create workspace”:\nSelect “Configure variables” and add your AWS Account and Access Keys as environment variables called AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY. If you aren’t sure where to find the keys, see this guide.\nGo to Settings and select General. From this settings screen, grab your workspace ID for the next step.\nGrab the API token from Terraform Cloud for the integration. Go to the API token menu (User -\u0026gt; Settings -\u0026gt; Tokens) and select “Create an API token.”\nCopy that API token for the next step.\nNext, you’ll add the Bridgecrew integration. Head over to the Integrations screen in the Bridgecrew platform. Scroll down and select Terraform Cloud and Add Workspace. Fill in the Workspace ID, workspace name, and API token from the previous steps:\nSelecting “Create Policy” will generate a Sentinel Policy that you can then add to Terraform Cloud.\nHead back to Terraform Cloud and go to the “Policies\u0026rdquo; setting and \u0026ldquo;Create a new policy.\u0026rdquo; Name the policy bridgecrew and paste the code you copied in the Bridgecrew integration page and paste it into the “Policy code” section and select “Create policy”:\nSelect “Policy Sets” and “Connect a new policy set”. You can create a versioned policy set, but for the sake of this workshop, go without a VCS connection. Name your setting and choose the terragoat workspace and select “Connect policy set”.\nGo back to the “Policies” section and select the policy you made. Scroll down to the “Policy Sets” section and add the terragoat_set you made.\nFinally, go to your workspace\u0026rsquo;s main page and queue a run; don\u0026rsquo;t worry if it fails, this just primes the runs to be automated with future GitHub pull requests.\nYour Terraform Cloud integration is ready to go!\n"
},
{
	"uri": "/aws/20_module_two/2004_automating_iac_codepipeline.html",
	"title": "AWS CodePipeline Setup",
	"tags": [],
	"description": "",
	"content": " Setting up AWS CodePipeline to automatically trigger scans To trigger CodeBuild to run the scan automatically on each new commit in your CfnGoat GitHub repository, we’ll need to configure AWS CodePipeline. You can skip this step, but if you do, you’ll only be able to run manual scans from the CodeBuild UI, AWS CLI, or APIs, which doesn’t provide the DevSecOps automation we’re looking for!\nTo set it up, go to AWS CodePipeline and select Create Pipeline:\nAfter giving the pipeline a name, (scan-cfngoat-pipeline) select Next.\nChoose Github (Version 2) as the source provider.\nAs CodeBuild and CodePipeline are different tools, you\u0026rsquo;ll also need to authorize CodePipeline to your GitHub account, select Connect to Github and follow the authorization redirects in the popup window.\nGive the Github Connection a name:\nSelect which Github Repositories you want CodePipeline to receive events for, in this case, i\u0026rsquo;ve just selected the CfnGoat repository.\nOnce you’ve authorized GitHub, select Install a new app to finalize the GitHub integration and select Connect:\nThe CodePipeline screen should refresh with a green Sucessfully connected to GitHub message:\nNow that CodePipeline has access to our GitHub repository, we can select it as the pipeline source. Select the master (or main branch) to have our pipeline run when commits to this branch occur:\nInstruct CodePipeline to trigger our CodeBuild When CodePipeline sees a new commit in our GitHub repository, it will trigger a build action. To set this to be our CodeBuild commands, select the same region as the CodeBuild project, then select the CodeBuild project, bridgecrew-tutorial.\nLeave the default of Single Build selected and select Next\nOn the next screen, select Skip deploy stage. We don’t want to deploy our CfnGoat CloudFormation to AWS as we’re just highlighting how to stop a build from progressing if there are security violations!\nFinally, select Create pipeline on the review page, which will trigger your new CodePipeline to immediately run against the latest commit in our CfnGoat repository:\nNow we don’t need to manually run the Bridgecrew CLI; your developers will get a Bridgecrew scan every time they commit!\n"
},
{
	"uri": "/terraform/40_module_two/2004_github_application.html",
	"title": "GitHub Application",
	"tags": [],
	"description": "",
	"content": " Integrating Bridgecrew with GitHub In this section, you’ll add a GitHub integration to generate code comments and set up for automated pull requests (PRs) in the next section. This integration also provides native and automated scanning of incoming commits and pull requests.\nHead back to the Bridgecrew Integrations tab and select GitHub under the Source Control section and “Authorize on GitHub Marketplace”:\nChoose which accounts and repositories to grant the Bridgecrew GitHub integration access to:\nOnce you’ve connected Bridgecrew to your TerraGoat demo repository, Bridgecrew will scan your Terraform templates directly from GitHub again and bring the results into Bridgecrew.\nHead over to the Projects tab and find the TerraGoat repository:\nYou will now see the same violation alerting from multiple sources. Although this may seem redundant, it’s actually an important feature for tracking security posture at multiple steps in the DevOps lifecycle.\nYou’re all set!\nNow head over to your forked TerraGoat repository in GitHub to kick off a pull request to make sure it’s working.\n"
},
{
	"uri": "/aws/20_module_two/2005_automating_iac_results.html",
	"title": "Pipeline Results",
	"tags": [],
	"description": "",
	"content": " Reviewing our pipeline results Your new CodePipeline will immediatley start running your CodeBuild job against the latest commit in your GFNGoat Repository.\nYou will be taken to the Pipeline Jobs page where you will see the progress as CodeBuild checks out the latest commit from GitHub and starts our job to run Bridgecrew against the CloudFormation configuration.\nBelow we see the Pipeline sucessfully created and starting to run:\nIf everything goes as intended, the pipeline should fail at the build stage since the CfnGoat code is purposely designed with security flaws. Only when the issues are fixed will the pipeline status turn to green.\nBy blocking the committed code from making it to any “Deploy” steps, we can prevent vulnerable infrastructure from making its way to any AWS account, be it test or prod and helping to satisfy the requirements of the AWS Shared Responsibility Model\nDig into the failed build Details and select the link to execution details:\nHere we are provided a link to our build logs, revealing the security violations and why Bridgecrew blocked the build:\nNavigating to Codebuild \u0026gt; Report Group, we can also see a simple graph of failed and passed checks with an easier-to-read output of all failed checks.\n\u0026ldquo;AWS CodeBuild JUnit output)\nCongratulations! You’ve just automated security scanning of your infrastructure as code into a developer-friendly CI/CD pipeline.\nIn the next module, we’ll look at how to investigate and fix these issues, as well as providing more tips for integrating security into the developer workflow without causing friction.\n"
},
{
	"uri": "/terraform/40_module_two/2005_kickoff_pr.html",
	"title": "Test pull request",
	"tags": [],
	"description": "",
	"content": " Kick off a test pull request Check that all three integrations are working by kicking off a pull request. Go back to your fork of the TerraGoat repo and select \u0026ldquo;Add file\u0026rdquo; -\u0026gt; \u0026ldquo;Create new file.\u0026rdquo; Set the path to terragoat-demo-test/terraform/simple_instance/ec2.tf. Add the following code:\nprovider \u0026#34;aws\u0026#34; { region = \u0026#34;us-east-1\u0026#34; } resource \u0026#34;aws_security_group\u0026#34; \u0026#34;ssh_traffic\u0026#34; { name = \u0026#34;ssh_traffic\u0026#34; description = \u0026#34;Allow SSH inbound traffic\u0026#34; ingress { description = \u0026#34;SSH\u0026#34; from_port = 22 to_port = 22 protocol = \u0026#34;tcp\u0026#34; cidr_blocks = [\u0026#34;0.0.0.0/0\u0026#34;] } } resource \u0026#34;aws_instance\u0026#34; \u0026#34;web_server_instance\u0026#34; { ami = data.aws_ami.ubuntu.id instance_type = \u0026#34;t2.micro\u0026#34; security_groups = [ \u0026#34;${aws_security_group.ssh_traffic.name}\u0026#34; ] } data \u0026#34;aws_ami\u0026#34; \u0026#34;ubuntu\u0026#34; { most_recent = true filter { name = \u0026#34;name\u0026#34; values = [\u0026#34;ubuntu/images/hvm-ssd/ubuntu-bionic-18.04-amd64-server-*\u0026#34;] } filter { name = \u0026#34;virtualization-type\u0026#34; values = [\u0026#34;hvm\u0026#34;] } owners = [\u0026#34;099720109477\u0026#34;] # Canonical } Select \u0026ldquo;Create a new branch\u0026rdquo; and \u0026ldquo;Propose new file.\u0026rdquo;\nThen \u0026ldquo;Create a pull request.\u0026rdquo; After a few seconds, you should automatically see Code Review Comments. Expand one to see the additional details like Fix recommendations. At the bottom, you should see five checks:\n The Checkov GitHub Action The Bridgecrew GitHub Action The Bridgecrew GitHub Application Two Terraform Cloud integration checks  You can fix the violations later, but for now, click \u0026ldquo;Merge pull request\u0026rdquo; and \u0026ldquo;Confirm merge.\u0026rdquo; Head back over to Terraform Cloud and select the latest run. You\u0026rsquo;ll again see the policy violations, but since we set the failure level to \u0026ldquo;advisory (logging only),\u0026rdquo; we can still apply the template.\nWe\u0026rsquo;re using a free tier instance (t2-micro), but remember to cleanup with terraform destroy at the end to avoid additional charges from AWS.\n Click \u0026ldquo;Confirm \u0026amp; Apply.\u0026rdquo; This will deploy the simple EC2 instance and security group. Optionally, head over to your AWS console to confirm an instance was created.\nCongratulations! You’ve now set up a GitHub Action, a Terraform Cloud integration, and a GitHub Application to secure your Terraform templates.\nIn the next module, you’ll look at how to investigate and fix the issues arising from the automated scans, as well as providing more tips for integrating security into the developer workflow without causing friction.\n"
},
{
	"uri": "/aws/20_module_two/2006_automating_iac_github_actions.html",
	"title": "GitHub Actions",
	"tags": [],
	"description": "",
	"content": " Setting up GitHub Actions for our CloudFormation repository. If your existing CI/CD Pipeline runs in GitHub Actions, this can also be configured to scan the CloudFormation templates before deployment, allowing us to fail the build job and halt a deployment if there are any security violations in our CloudFormation code.\nAs with AWS CodeBuild, we’ll also automatically send the results to Brigecrew to maintain a view across all of our infrastructure projects and share visibility throughout our organization.\nGenerally speaking, you wouldn\u0026rsquo;t configure both CI/CD solutions for a single repository, consider this page informational only if you have followed through the AWS CodeBuild and AWS CodeDeploy sections, the observability provided into the Bridgecrew platform will be similar.\n As with other Integrations, the GitHub Actions CI/CD integration page at https://www.bridgecrew.cloud/integrations/githubActions allows us to setup GitHub Actions, select Add Subscription.\nThe integration provides steps to enable GitHub actions, which we\u0026rsquo;ll walk through below.\nFirstly, just like we stored the Bridgecrew API secret in aws ssm put-parameter for CodeBuild, allowing the CI/CD run to securely access the secret, we do the same with GitHub Actions, by creating a GitHub secret, this prevents our API key being exposed in the configuration (which is stored in our codebase).\nGo to your fork of CFNGoat on GitHub, select Settings\nThen select Secrets from the left, and click New Repository Secret\nName the secret BRIDGECREW_API_KEY as instructed in the Bridgecrew integration details above.\nCopy and paste your API Token from the Bridgecrew integration details page into the value field.\nSelect Add secret, the secret will then be listed by name in the Settings \u0026gt; Secrets page you\u0026rsquo;ll be taken back too.\nAdding the automated workflow. Github Actions are defined as workflow files, within your code repository under the .github/workflows directory. To create an action, we\u0026rsquo;ll be adding a new file to this directory. If you already have workflows, and are familiar with the workflow file format, you could add the bridgecrew step section to your own workflows for the same results.\n To create a new workflow, select Actions within your CFNGoat forked repository, then select New Workflow button.\nSelect set up a workflow yourself to create a new, blank workflow.\nName the new file bridgecrew.yaml and replace the entire contents with the workflow template provided below, This takes the jobs section provided by the Bridgecrew integration instructions and wraps it in a fully functional GitHub Actions definition.\nname: Bridgecrew on: push: branches: - master jobs: scan: runs-on: ubuntu-latest strategy: matrix: python-version: [3.8] steps: - uses: actions/checkout@v2 - name: Run Bridgecrew id: Bridgecrew uses: bridgecrewio/bridgecrew-action@master with: api-key: ${{ secrets.BRIDGECREW_API_KEY }} The result should look like this, select Start commit\nFinally, save the new workflow file into your code repository by selecting Commit new file\nThe GitHub Action will immediatley start running the Bridgecrew CLI against the latest commit in your GFNGoat Repository.\nYou can see this by selecting the Actions page within your CFNGoat forked repository in GitHub.\nYou will see a new workflow, titled Bridgecrew and a job about to run automatically because of the new commit (of the workflow file)\nSelecting this job will allow you to view the status and logging output from the pipeline, where the Bridgecrew CLI will run and output any violations found in the CFNGoat codebase.\nRather than digging through the job logs, the action also outputs annotations for each violation found into the Summary page of the action.\nBy default, the Bridgecrew GitHub Action is designed to pass, acting as a reporting and observability task, which updates the Bridgecrew dashboard of the current security posture within the CI/CD pipeline.\n Congratulations! You’ve just automated security scanning of your infrastructure as code into a developer-friendly CI/CD pipeline.\nIn the next module, we’ll look at how to investigate and fix the issues arising from the automated scans, as well as providing more tips for integrating security into the developer workflow without causing friction.\n"
},
{
	"uri": "/aws/30_module_three.html",
	"title": "Module - Fix",
	"tags": [],
	"description": "",
	"content": " As we’ve shown so far, Bridgecrew provides the policies and workflow to audit your CloudFormation templates before deployment, and optionally, to block vulnerabilities from making their way to your deployment pipeline.\nIn this module, we’ll head back to the Bridgecrew platform to show how easy it can be to improve your cloud security posture with easy-to-understand visualizations and automated remediations.\nModule Learning Objectives  Investigating security violations in Bridgecrew Integrating Bridgecrew with GitHub Automating pull requests with GitHub Scanning runtime resources for vulnerable infrastructure  "
},
{
	"uri": "/terraform/50_module_three.html",
	"title": "Module - Fix",
	"tags": [],
	"description": "",
	"content": " MODULE - FIX We’ve covered scanning for misconfigurations during the development cycle and prior to committing to our repository. We can alert or block at each stage to provide that feedback early and make updates before the issues make it into production.\nIn this module, we’ll show how to visualize our posture and automate remediations. We teased this module in the VS Code section, where we performed our first fix, but in this section, we’ll fix the issues that make it into our repository and in production.\nModule Learning Objectives  Investigate security violations in Bridgecrew Automate pull requests in GitHub Scan runtime resources for vulnerable infrastructure Detect and mitigate drift  "
},
{
	"uri": "/aws/30_module_three/3001_bridgecrew_dashboard_results.html",
	"title": "Bridgecrew platform results",
	"tags": [],
	"description": "",
	"content": " Investigating security violations in Bridgecrew While the output from your CodeBuild run is very useful for quickly getting a sense of why your build failed, you may also want to visualize issues over time with a given repository or group objects affected by the same issue for clearer understanding.\nIf your developers don’t have direct access to the AWS account, the provided logs may be constrained.\nFor all those reasons and more, Bridgecrew provides reporting, monitoring, alerting, and visualizations for individual runs and across your entire infrastructure.\nHeading back to Bridgecrew, you’ll notice, our AWS CodeBuild integration has gone green showing that we’ve received data. You can also see the AWS account ID and the name of our CodeBuild pipeline received from our CodeBuild job!\nNavigating to the Incidents tab, you’ll see a list of all of the issues previously reported in the CodeBuild logs. If you select an item on the left-hand side, you’ll see all of the CloudFormation resources impacted by that issue.\nYou can also filter issues by severity, benchmarks, categories, and by source:\nSelecting a specific resource, you will see metadata such as commit details and a historical timeline, which includes all actions and changes made to the resource. Bridgecrew also shows the code configuration and lines that need to be addressed:\nRefresh the dashboard to see updated historical trends and collated information from all of your monitoring sources:\nBridgecrew goes a step further, making it easy for teams to investigate issues and get visibility into their cloud security posture. Hit next to learn how to address issues fast with automated security-as-code fixes!\n"
},
{
	"uri": "/terraform/50_module_three/3001_bridgecrew_dashboard_results.html",
	"title": "Bridgecrew platform results",
	"tags": [],
	"description": "",
	"content": " Investigating security violations in Bridgecrew Providing feedback in IDEs and CI/CD pipelines provides valuable insights into the posture of your code. Bridgecrew provides a centralized view for tracking misconfigurations across your code scans and runtime environments. We’ll start with the view across code scans.\nNavigate to the Projects tab in the Bridgecrew platform. Here you can see the results of your GitHub scan, as well as any other code scan that includes a repository ID and your Bridgecrew API.\nThis page comes packed with information and navigation tools for misconfigurations identified.\n Use the filters on the left to narrow down violations, or the top to narrow down to previous git modifiers. Search for code snippets or tags in the top. See dependent resources and audit histories on the right side.  Hit next to learn how to create a pull request with automatic fixes!\n"
},
{
	"uri": "/aws/30_module_three/3002_bridgecrew_automate_integrate_github.html",
	"title": "GitHub integration",
	"tags": [],
	"description": "",
	"content": " Integrating Bridgecrew with GitHub By adding another Bridgecrew integration, you can generate and push automated pull requests (PRs) back into your GitHub repository to update your CloudFormation code and fix security issues, as well as gain automated scanning of incoming community pull requests.\nHead back to the Bridgecrew Integrations tab and select GitHub under the Source Control section.\nJust like we did for the AWS CodePipeline GitHub authorization, choose which accounts and repositories to grant the Bridgecrew github integration access too.\nOnce you’ve connected Bridgecrew to your CfnGoat demo repository, Bridgecrew will scan your CloudFormation code directly from GitHub again and bring the results into Bridgecrew.\nTo see all issues across your two scanning sources— your bridgecrew-tutorial CodePipeline and your newly integrated GitHub repository—you may need to check your filters on the Incidents page.\nYou will now see the same violation alerting from two sources. Although this may seem redundant, it’s actually an important feature for tracking security posture at multiple steps in the DevOps lifecycle.\n"
},
{
	"uri": "/terraform/50_module_three/3002_bridgecrew_pull_request_fix.html",
	"title": "Pull request fixes",
	"tags": [],
	"description": "",
	"content": " Automating fixes through pull requests Now that you’ve pulled in multiple infrastructure sources, you may get overwhelmed at the prospect of fixing the several dozen issues Bridgecrew has identified. To help us implement fixes as fast as possible, Bridgecrew generates and pushes fix pull requests back into your GitHub repository.\nLet’s walk through the process with one of the policies you looked at earlier, \u0026ldquo;S3 Bucket has an ACL defined which allows public READ access.\u0026rdquo;\nThe lightbulb icon takes you to the Bridgecrew docs for more information about the violation. We can also suppress that check for this specific resource. Finally, in the middle is the Fix button. This enables you to automatically create a pull request with the diff shown. In this case, it will remove the acl with public-read access and force_destroy setting.\nYou can include other fixes, but for the sake of this workshop, we’ll just do the one. Select Submit.\nThat created a pull request, but you’ll need to approve the patch to make the changes in your repository. Over in your TerraGoat repository in GitHub, you’ll see a new PR under the “Pull requests” tab, which is ready for review:\nBecause of the scans from previous steps, the Merge button won’t be highlighted. Merge the patch anyway. You’ll receive a confirmation that the PR was merged and closed.\nMake sure to pull the origin locally to update your local copy of TerraGoat with the patch.\nCongratulations!\nYou’ve built an automated IaC scanning workflow in a live environment and automated the fixing of an exposed S3 bucket!\n"
},
{
	"uri": "/terraform/50_module_three/3003_bridgecrew_automate_add_runtime.html",
	"title": "AWS runtime scanning",
	"tags": [],
	"description": "",
	"content": " Scanning runtime resources for vulnerable infrastructure Let’s switch gears to address infrastructure that wasn\u0026rsquo;t deployed by Terraform.\nGreenfield infrastructure as code deployments are a luxury not many of us have. In reality, our AWS accounts have objects that were created manually for one reason or another. Transitioning to IaC is rarely a one-and-done affair, so you may have objects in your AWS accounts that are managed by a team that has not yet made the switch.\nThat’s why it’s important to scan objects directly in your AWS environment in addition to scanning your Terraform templates in git or as part of the CI/CD pipeline, as we’ve already shown.\nBridgecrew provides runtime scanning via an AWS integration, allowing full coverage of infrastructure security both before and after deployment.\nAWS runtime integration To enable runtime scanning of your AWS account, go to the Integrations Tab and select AWS Read Only under the Cloud Providers section.\nRead-only access is scoped as minimally as possible in order to give Bridgecrew only the necessary access to scan your AWS accounts.  Click Add Account, then Launch Stack to enable the integration:\nYou will be taken to your AWS account to authorize the integration:\nCheck the checkbox to approve the IAM permission creations via our Terraform stack, and click Create Stack:\nYou can track the progress of the stack creation within your AWS account. Once completed, you\u0026rsquo;ll see the integration turn green in the Bridgecrew dashboard:\nSuccessful integration: That’s all it takes to connect your AWS account to Bridgecrew for continuous cloud security monitoring and compliance benchmarking.\nExploring runtime violations With the runtime AWS account connected, let’s edit our filters on the Incidents page to show only the AWS source. In the filters option pane, select your AWS account ID that should now show up alongside your other integrations from the earlier modules.\nUnlike the rest of this workshop, the information displayed in your Bridgecrew Dashboard may differ from the images below, as no two AWS accounts will have the same content.  After setting our filter, we can browse through all the security and compliance violations detected in our live AWS account,\nIn the example below, we can see an S3 bucket is not encrypted at rest. Selecting a resource from the group of resources on the right-hand side will display much more information, including a Terraform representation of the AWS object in question:\nFurther context on the issue and remediation options is also available in the Guidelines tab.\nBridgecrew also alerts on account-wide settings such as user password policies and informational best practices, such as tagging each resource with ownership or purpose information:\nUntagged items in account: Weak account password policy: Identity and Access Management (IAM) Insights Bridgecrew also analyzes AWS IAM roles, permissions, groups, and policies to identify unused and overly-permissive configurations.\nYou can use the filter pane to only show Insights, highlighting IAM specific issues:\nIAM Insights will even provide a re-written, rightsized IAM policy document with only the permissions your applications are requesting of the role or policy. This helps you build and maintain least-privilege IAM and reduces the scope of abuse from a misconfigured or exploited application.\nNext we\u0026rsquo;ll create some fixes in production.\n"
},
{
	"uri": "/aws/30_module_three/3003_bridgecrew_automate_pr_remediation.html",
	"title": "Pull request fixes",
	"tags": [],
	"description": "",
	"content": " Automating fixes through pull requests Now that you’ve pulled in multiple infrastructure sources, you might be getting overwhelmed at the prospect of fixing the several dozen issues Bridgecrew has identified. To help you implement fixes as fast as possible, Bridgecrew generates and pushes fix pull requests back into your GitHub repository.\nLet’s walk through the process with one of the policies we looked at earlier, Ensure S3 bucket has ‘restrict_public_bucket’ enabled:\nWhen we click on one of the GitHub-integrated violations, \u0026lt;yourgithubusername\u0026gt;/cfngoat: Bucket.FinancialsBucket, for example, we’ll see the platform recommending an automated fix in the form of a code diff:\nCheck out the Guidelines tab for more information on the policy and if you’are satisfied with the proposed fix, you can tick the box next to the resource name above the diff, and select Remediate.\nThe remediation modal shows there will be a pull request fix raised against your GitHub repository.\nAfter you select Remediate, you’ll be taken back to the Incidents screen with a message confirming the pull request has been successfully raised. You’ll also see the remediation has had the effect of hiding the issue from the Incidents list; other resources are listed, but the one we addressed is gone.\nYou’ll also notice, however, that the issue is still present from our CodePipeline source, so we’re not secure yet!\nOver in our CfnGoat repository in GitHub, we’ll see a new PR under the Pull requests tab, which is ready for review:\nDigging into the changed files, you’ll see the updated code that will soon be merged.\nBringing it all together. Merging our pull request in GitHub triggers our CI/CD deployment in AWS CodePipeline that we previously set up.\nYou may be able to tell where this is going!\nNotice our merged pull request commit has triggered the build:\nOf course, the scan will still fail as there are several other security issues affecting the CfnGoat repository, but if we head back to Bridgecrew, the issue we just fixed is gone:\nNow we know that the issue is not only fixed at source, but also that the fix has also made it through the CI/CD pipeline into production!\nCongratulations! You’ve built an automated IaC scanning workflow in a live environment and automated the fixing of an exposed S3 bucket!\n"
},
{
	"uri": "/terraform/50_module_three/3004_bridgecrew_automate_fix_runtime.html",
	"title": "AWS fixes in runtime",
	"tags": [],
	"description": "",
	"content": " Automating fixes in runtime Similar to what we did with pull request fixes in the previous module, Bridgecrew allows for immediate remediation of issues in runtime by reconfiguring your objects via the AWS APIs.\nImplementing automated remediations does require extra permissions than previously granted with the default AWS Read Only integration. When you attempt a runtime remediation without the correct permissions, you’ll be prompted to configure the AWS Remediation Stack:\nAdding the AWS Remediation stack follows the same workflow as the previous read-only AWS integration:\nSelect Create Stack and return to Bridgecrew, you will now be able to Remediate runtime resources: Fixing an unencrypted S3 bucket Continuing with the example of the unencrypted S3 bucket from the previous page, the Remediate button will now allow runtime changes to the S3 configuration:\nFor the sake of this workshop, we can use the AWS Console to confirm the selected bucket is currently unencrypted:\nBack in Bridgecrew, review the remediation, and select Remediate a final time.\nBridgecrew will now use AWS API\u0026rsquo;s to ensure encryption is turned on for the selected resource:\nChecking the resource once more in the AWS Console, you will see that encryption is now enabled:\nThe violation will also have been marked resolved in the Bridgecrew Incidents page.\nInstead of resolving issues in production, if you follow GitOps best practices, we should prevent changes in production. We\u0026rsquo;ll cover how to handle drift in the next session.\n"
},
{
	"uri": "/aws/30_module_three/3004_bridgecrew_automate_add_runtime.html",
	"title": "AWS runtime scanning",
	"tags": [],
	"description": "",
	"content": " Scanning runtime resources for vulnerable infrastructure Last but definitely not least, let’s switch gears to address infrastructure that wasn\u0026rsquo;t deployed by CloudFormation.\nGreenfield infrastructure as code deployments are a luxury not many of us have. In reality, our AWS accounts have objects that were created manually for one reason or another. Transitioning to IaC is rarely a one-and-done affair, so you may have objects in your AWS accounts that are managed by a team that has not yet made the switch.\nThat’s why it’s important to scan objects directly in your AWS environment in addition to scanning your CloudFormation or Terraform manifests in git or as part of the CI/CD pipeline, as we’ve already shown.\nBridgecrew provides runtime scanning via an AWS integration, allowing full coverage of infrastructure security both before and after deployment.\nAWS Runtime Integration To enable runtime scanning of your AWS account, goto the Integrations Tab and select AWS Read Only under the Cloud Providers section.\nRead-only access is scoped as minimally as possible in order to give Bridgecrew only the necessary access to scan your AWS accounts.  Click Add Account then Launch Stack to enable the integration:\nYou will be taken to your AWS account to authorize the integration:\nCheck the checkbox to approve the IAM permission creations via our CloudFormation stack, and click Create Stack\nYou can track the progress of the stack creation within your AWS account, once completed, you\u0026rsquo;ll see the integration turn green in the Bridgecrew dashboard!\nSucessful Integration: That’s all it takes to connect your AWS account to Bridgecrew for continuous cloud security monitoring and compliance benchmarking.\nExploring runtime violations With the runtime AWS account connected, let’s edit our filters on the Incidents page to show only the AWS source. In the filters option pane, select your AWS account ID that should now show up alongside your CodePipeline and GitHub repositories from the earlier modules.\nUnlike the rest of this workshop, the information displayed in your Bridgecrew Dashboard may differ from the images below, as no two AWS accounts will have the same content.  After setting our filter, we can browse through all the security and compliance violations detected in our live AWS account,\nIn the example below, we can see an S3 bucket is not encrypted at rest. Selecting a resource from the group of resources on the right hand side will display much more information, including a Terraform representation of the AWS object in question:\nFurther context on the issue and remediation options is also available in the Guidelines tab.\nBridgecrew also alerts on account-wide settings such as user password policies and informational best practices, such as tagging each resource with ownership or purpose information:\nUntagged Items in Account Weak Account Password Policy Identity and Access Management (IAM) Insights Bridgecrew also analyzes AWS IAM roles, permissions, groups, and policies to identify unused and overly-permissive configurations.\nYou can use the filter pane to only show Insights, highlighting IAM specific issues:\nIAM Insights will even provide a re-written, rightsized IAM policy document with only the permissions your applications are requesting of the role or policy. This helps you build and maintain least-privilege IAM and reduces the scope of abuse from a misconfigured or exploited application.\n"
},
{
	"uri": "/aws/30_module_three/3005_bridgecrew_automate_fix_runtime.html",
	"title": "AWS fixes in runtime",
	"tags": [],
	"description": "",
	"content": " Automating fixes in runtime Similar to what we did with pull request fixes in the previous module, Bridgecrew allows for immediate remediation of issues in runtime by reconfiguring your objects via the AWS APIs.\nImplementing automated remediations does require extra permissions than previously granted with the default AWS Read Only integration. When you attempt a runtime remediation without the correct permissions, you’ll be prompted to configure the AWS Remediation Stack:\nAdding the AWS Remediation stack follows the same workflow as the previous read-only AWS integration:\nSelect Create Stack and return to Bridgecrew, you will now be able to Remediate runtime resources: Fixing an unencrypted S3 bucket Continuing with the example of the unencrypted S3 bucket from the previous page, the Remediate button will now allow runtime changes to the S3 configuration:\nFor the sake of this workshop, we can use the AWS Console to confirm the selected bucket is currently unencrypted:\nBack in Bridgecrew, review the remediation, and select Remediate a final time.\nBridgecrew will now use AWS API\u0026rsquo;s to ensure encryption is turned on for the selected resource:\nChecking the resource once more in the AWS Console, you will see that encryption is now enabled:\nThe violation will also have been marked resolved in the Bridgecrew Incidents page.\nCongratulations! You\u0026rsquo;ve integrated runtime security alerting and remediation into your DevSecOps automation!\n"
},
{
	"uri": "/terraform/50_module_three/3005_bridgecrew_drift_detections.html",
	"title": "Drift detection",
	"tags": [],
	"description": "",
	"content": " Drift detection between AWS and Terraform Cloud state using Bridgecrew In this final section, you’ll switch gears and detect drift. Drift occurs when the infrastructure deployed in the cloud is different from what was defined in the IaC template. You call what the infrastructure should be the “state” saved in files locally or in Terraform Cloud. For example, if the infrastructure in AWS may have different configurations than the Terraform template defined.\nThis usually occurs during a major incident, where DevOps and SRE teams make manual changes to quickly solve the problem, such as opening up ports to larger CIDR blocks or turning off HTTPS to find the problem. If these aren’t reverted, they present security issues and it weakens the auditability benefit of IaC versioning.\nCreate drift Make sure you\u0026rsquo;ve applied the Terraform resources from the Test Pull Request section.\nConfirm in your AWS console that your new EC2 instance is booting up. Go to the EC2 console and confirm that there is a new t2.micro instance running.\nNext, add another open port to your security group to see what happens. Select the new instance you made and select the security group for that instance.\nSelect “Edit inbound rules” and “Add rule”. Enter a random port \u0026ndash; I used the default port for MongoDB, 27017, and enter the CIDR block 0.0.0.0/0. Select “Save rules”.\nBridgecrew scans your cloud configurations periodically, but to speed up the process, you can use the following API call in your terminal with your Bridgecrew API key from the earlier steps.\ncurl -X POST -H \u0026#34;Authorization: $YOUR_BC_API_KEY\u0026#34; https://www.bridgecrew.cloud/api/v1/scans/integrations That will force start a scan of your environment that will find misconfigurations and identify drift from your Terraform state. After a few moments, head back over to the Incidents section of Bridgecrew. Search for the policy “Ensure provisioned resources are not manually modified” and select the object. Here you can see the difference in AWS versus the state saved in Terraform Cloud.\nYou found drift! From here, you can either run terraform apply to bring your cloud instances back in line with the state saved in Terraform Cloud or make the changes to your Terraform templates to match the changes made in production and update the state in Terraform Cloud.\n"
},
{
	"uri": "/aws/40_conclusion.html",
	"title": "Conclusion",
	"tags": [],
	"description": "",
	"content": " Conclusion In this workshop, you didn’t just learn how to automate security scanning—you learned how to bridge the gap between infrastructure development, DevOps, and cloud security. With these tools and processes at your disposal, you’re equipped to reduce risk by preventing cloud security errors as part of your development lifecycle. We also hope you’ve learned how important and easy it is to make security accessible to your engineering teams.\nFeel free to explore more of the Bridgecrew Dashboard, and try inviting more of your team to view and collaborate on the same security dashboard from the User Management page\nTo continue the conversation, you can find us @bridgecrewio on twitter, or say hi! in our #CodifiedSecurity slack channel, here!\n"
},
{
	"uri": "/terraform/60_conclusion.html",
	"title": "Conclusion",
	"tags": [],
	"description": "",
	"content": " CONCLUSION In this workshop, we didn’t just learn how to identify and automate fixing misconfigurations — we learned how to bridge the gap between infrastructure development, DevOps, and cloud security. We are now equipped with full visibility, guardrails, and remediation capabilities across the development lifecycle. We also learned how important and easy it is to make security accessible to our engineering teams.\nTry more of the integrations with other popular developer and DevOps tools. Share what you’ve found with other members of your team and show how easy it is to incorporate this into their development processes. This will show how we can collaborate on the same security dashboard from the User Management page.\nIf you have any questions or thoughts, find us @bridgecrewio on Twitter, or say hi! in our #CodifiedSecurity Slack channel!\n"
},
{
	"uri": "/aws/100_cleanup.html",
	"title": "Cleanup",
	"tags": [],
	"description": "",
	"content": " AWS Cleanup In order to prevent charges to your account we recommend cleaning up the infrastructure that was created. If you plan to keep things running so you can examine the workshop a bit more please remember to do the cleanup when you are done. It is very easy to leave things running in an AWS account, forget about it, and then accrue charges. CodePipeline In the AWS console, go to AWS CodePipeline, and delete the scan-cfngoat-bridgecrew pipeline we created.\nCodeBuild AWS CodeBuild, and delete the bridgecrew-tutorial project we created.\nIAM Role Finally, remove the IAM role we created: - codebuild-bridgecrew-tutorial-service-role\nBridgecrew Cleanup The Bridgecrew account you created is free to use for up to 100 cloud resources, you can leave your AWS account integrated from the runtime section of this workshop to automatically detect infrastructure security issues in your account. The GitHub integration will also continue to scan pull requests to detect, annotate and prevent new infrastructure as code issues.\nYou may want to check out the following resources:\nIAM Insights: Automated right-sizing with policy-as-code Scanning AWS Cloud Development Kit (CDK) with Bridgecrew Bridgecrew Documentation\nThese integrations can be disabled from the Bridgecrew platform integrations page if need be.\n "
},
{
	"uri": "/terraform/100_cleanup.html",
	"title": "Cleanup",
	"tags": [],
	"description": "",
	"content": " AWS Cleanup In order to prevent charges to your account we recommend cleaning up the infrastructure that was created. If you plan to keep things running so you can examine the workshop a bit more please remember to do the cleanup when you are done. It is very easy to leave things running in an AWS account, forget about it, and then accrue charges. Terraform If you deployed any infrastructure using the Terraform CLI, make sure to run terraform destroy. If you deployed any infrastructure using Terraform Cloud, go into the workspace and select “Settings” -\u0026gt; “Destruction and Deletion” -\u0026gt; “Queue destroy plan”.\nIAM Role Finally, remove the IAM role you created: - codebuild-bridgecrew-tutorial-service-role\nBridgecrew Cleanup The Bridgecrew account you created is free to use for up to 100 cloud resources, you can leave your AWS account integrated from the runtime section of this workshop to automatically detect infrastructure security issues in your account. The GitHub integration will also continue to scan pull requests to detect, annotate and prevent new infrastructure as code issues.\nThese integrations can be disabled from the Bridgecrew platform integrations page if need be.\n"
},
{
	"uri": "/categories.html",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags.html",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]